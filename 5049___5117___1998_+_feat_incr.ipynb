{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5049___5117___1998 + feat_incr.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujanya001/SAKT_Continual-learning/blob/main/5049___5117___1998_%2B_feat_incr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qukSwxqxt3_"
      },
      "source": [
        "#5049 -> 5117 -> 1998"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEy1HmoJMAJz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gc \n",
        "import csv\n",
        "from tqdm import tqdm \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.utils.rnn as rnn_utils \n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "from copy import deepcopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8-ta5l2MW3G"
      },
      "source": [
        "MAX_SEQ = 30\n",
        "epochs = 150\n",
        "MAX_LR = 2e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0olza6BM0jT",
        "outputId": "8fe2cb92-ac62-4189-bb8b-2900b0c11dbf"
      },
      "source": [
        "dtype = {'school_id': 'int32',\n",
        "         'user_id': 'int32',\n",
        "         'question_id': 'int32',\n",
        "         'correct': 'int16'}\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('/content/gdrive/MyDrive/skill_builder_data_corrected_collapsed_org.csv', usecols=[20, 3, 5, 7], dtype=dtype, encoding = \"ISO-8859-1\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schools_5049 = train_df[train_df[\"school_id\"] == 5049]\n",
        "task1_df=pd.DataFrame(schools_5049)\n",
        "task1_uniq = task1_df.drop_duplicates(subset = [\"problem_id\"])\n",
        "schools_1998 = train_df[train_df[\"school_id\"] == 1998]\n",
        "task2_df=pd.DataFrame(schools_1998)\n",
        "task2_uniq = task2_df.drop_duplicates(subset = [\"problem_id\"])\n",
        "schools_5117 = train_df[(train_df[\"school_id\"] == 5117)]\n",
        "task3_df=pd.DataFrame(schools_5117)\n",
        "task3_uniq = task3_df.drop_duplicates(subset = [\"problem_id\"])\n",
        "tasks_df = pd.concat([task1_uniq,task3_uniq,task2_uniq])\n",
        "tasks_uniq = tasks_df.drop_duplicates(subset = [\"problem_id\"])\n",
        "tasks_df.to_csv('out.csv')\n",
        "train_task = pd.read_csv('/content/out.csv')\n",
        "print(len(tasks_uniq), len(task1_uniq),len(task2_uniq),len(task3_uniq))\n",
        "print(train_task[(train_task[\"school_id\"] == 1998) & (train_task[\"school_id\"] != 5049)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqVwhZlZGzwg",
        "outputId": "7c2173ae-c0e4-42ab-870c-333273e652e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11925 7975 3065 2728\n",
            "       Unnamed: 0  user_id  problem_id  correct  school_id\n",
            "10703        1536    80171       51413        1       1998\n",
            "10704        1537    80171       51425        1       1998\n",
            "10705        1538    80172       51471        1       1998\n",
            "10706        1539    80172       51476        1       1998\n",
            "10707        1540    80173       51392        1       1998\n",
            "...           ...      ...         ...      ...        ...\n",
            "13763      324003    85656       46879        1       1998\n",
            "13764      324004    85656       46880        1       1998\n",
            "13765      327720    86229       54032        0       1998\n",
            "13766      327721    86229       54033        1       1998\n",
            "13767      327722    86229       54034        0       1998\n",
            "\n",
            "[3065 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "a = task1_df['problem_id']\n",
        "b = task2_df['problem_id']\n",
        "c = task3_df['problem_id']\n",
        "print(\"Overlap questions between 5049 and 1998:\",len(pd.Series(list(set(a) & set(b)))))\n",
        "print(\"Overlap questions between 1998 and 5117:\",len(pd.Series(list(set(b) & set(c)))))\n",
        "print(\"Overlap questions between 5049 and 5117:\",len(\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2oH-GKubAbq",
        "outputId": "7251ebd4-b31a-49e8-fe58-2af20cd2ee12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = list(train_task[\"problem_id\"].unique())\n",
        "n_questions = len(questions)\n",
        "print(\"Total no of questions:\", n_questions)\n",
        "count = {}\n",
        "print(questions)\n",
        "for i in range(1,len(questions)+1):\n",
        "    count[questions[i-1]]=i\n",
        "print(count)\n",
        "train_task['new_prob_id']=0\n",
        "for i in range(len(train_task['problem_id'])):\n",
        "    train_task['new_prob_id'][i]=count[train_task['problem_id'][i]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYTU8ah3-7O4",
        "outputId": "b5c05906-ccda-4039-d4ef-d92c6b406d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no of questions: 11925\n",
            "[51449, 51406, 51412, 51428, 51476, 51425, 51434, 51405, 51443, 51460, 51397, 51401, 51455, 51451, 51394, 51408, 51424, 51440, 51439, 51471, 51466, 51421, 51473, 51435, 51400, 51409, 51429, 51465, 51422, 135656, 135648, 135637, 135634, 135660, 51407, 51480, 51414, 51467, 51456, 51461, 51415, 51395, 51446, 135649, 135652, 51459, 51431, 51457, 51447, 51469, 51416, 51433, 51454, 51479, 51398, 51423, 135645, 135661, 135647, 51436, 51430, 51450, 51475, 51417, 51413, 135669, 51418, 51404, 51396, 51478, 51463, 51452, 51410, 51477, 135670, 135666, 135636, 135642, 135651, 135665, 135641, 135633, 135658, 135632, 135654, 135662, 51472, 51399, 51438, 135664, 135631, 135635, 135659, 51464, 51411, 135653, 135640, 51392, 51453, 51448, 51445, 51402, 51420, 135657, 51458, 51442, 51474, 51441, 135638, 135663, 135655, 92339, 92318, 92319, 92316, 92354, 92334, 92328, 92351, 92338, 92350, 92331, 92348, 92333, 147976, 147947, 147962, 92345, 92349, 92352, 92347, 147972, 147961, 147938, 147944, 92322, 92346, 147943, 147937, 92332, 92355, 92317, 92325, 92324, 92340, 147945, 147956, 147953, 147968, 92353, 147973, 147957, 147948, 147967, 92327, 147939, 147951, 147958, 56082, 56015, 56014, 56034, 56049, 56177, 56207, 56162, 56160, 56080, 56109, 56040, 56116, 66767, 56158, 66750, 55984, 56117, 56051, 56114, 56173, 56210, 56234, 56269, 56240, 56318, 56100, 56111, 56313, 56278, 56267, 56283, 56310, 56303, 56228, 56281, 56238, 56239, 56230, 56305, 56325, 56299, 56226, 56212, 56028, 56155, 55976, 56193, 56189, 56246, 56195, 56214, 55985, 56027, 66772, 55975, 66769, 56149, 55978, 56243, 56209, 56293, 56306, 56217, 56254, 55973, 66760, 56029, 56181, 56171, 56170, 66758, 56164, 56190, 56157, 56150, 56178, 56282, 56304, 93274, 93268, 93263, 93266, 93298, 93296, 56704, 56695, 56688, 56697, 48818, 48809, 93301, 93277, 56707, 56685, 48807, 48819, 48829, 135564, 135553, 135568, 135560, 135561, 48826, 48813, 48828, 56702, 56682, 56699, 48808, 48810, 48821, 48811, 135570, 135579, 56701, 56705, 56693, 135586, 56687, 48832, 135551, 48823, 56703, 48827, 56694, 56708, 48805, 48816, 135562, 135572, 135557, 135573, 135556, 48825, 56681, 135577, 135550, 135558, 135567, 135588, 48815, 135569, 135589, 56683, 56706, 48831, 56689, 48833, 56696, 48822, 48814, 135581, 135565, 135563, 135554, 135566, 135552, 48806, 56686, 56679, 135575, 135555, 48820, 56691, 56690, 56684, 135574, 135583, 135578, 135580, 48812, 56692, 48834, 58001, 58053, 57933, 58154, 57875, 58057, 58104, 57839, 57949, 57925, 57855, 58129, 58037, 58065, 57819, 57997, 57973, 57859, 58033, 57815, 58085, 58124, 93597, 93573, 93499, 93601, 93581, 93561, 93482, 57989, 57751, 57835, 93475, 93578, 93612, 93495, 93536, 93562, 93593, 93552, 93497, 93483, 135619, 135624, 135597, 135592, 135600, 135612, 135605, 93590, 93580, 93537, 93567, 93547, 93587, 135616, 135601, 135602, 135596, 93480, 93557, 93548, 93563, 135594, 135610, 135603, 135615, 135606, 135608, 93615, 93592, 135618, 135593, 93479, 93534, 93535, 93586, 93533, 93618, 93491, 135604, 135617, 135620, 135613, 135622, 135629, 93589, 93582, 93494, 93531, 93539, 93477, 93569, 135609, 135599, 135590, 93579, 93575, 93489, 135627, 135625, 93538, 93559, 93553, 93613, 93611, 93576, 93500, 93556, 93610, 93607, 93583, 93541, 135628, 135611, 93555, 93546, 93571, 135598, 93478, 93532, 93591, 93619, 93595, 93604, 93620, 93602, 93484, 93609, 135623, 135621, 135614, 135591, 135607, 135595, 56829, 56841, 112920, 112935, 112950, 120468, 120453, 56736, 56832, 56817, 56772, 56871, 56865, 56763, 112930, 56739, 120473, 120483, 56868, 56745, 56874, 56778, 56811, 56733, 112940, 112915, 56856, 56715, 56766, 56760, 56886, 56859, 112910, 56847, 56820, 56754, 56757, 56790, 56880, 56793, 56844, 112955, 120458, 112945, 120488, 112925, 120478, 120463, 120493, 91073, 91083, 91078, 91070, 91074, 91067, 91111, 91527, 91110, 91147, 91540, 91090, 91530, 91154, 91116, 91107, 91529, 92366, 92362, 92356, 92379, 92387, 92389, 92378, 139661, 139623, 139664, 139625, 113334, 139624, 139663, 139635, 113206, 113338, 113226, 113210, 113222, 113314, 113218, 113198, 113346, 139636, 139426, 139423, 139425, 139424, 113194, 113326, 139384, 139383, 139381, 139382, 113342, 113330, 113318, 139379, 139420, 139421, 113214, 113310, 113190, 139385, 113202, 139632, 139658, 113322, 139631, 139380, 139422, 113238, 137990, 138018, 139317, 113266, 113166, 113186, 113162, 113262, 113246, 137966, 139670, 113182, 113230, 113174, 113250, 113154, 113158, 137998, 139672, 139335, 139315, 113150, 138104, 139169, 139557, 139621, 139483, 139575, 138109, 138099, 139491, 139571, 139572, 139573, 139574, 139488, 139502, 139503, 139504, 139532, 139547, 139217, 113242, 113178, 138010, 137982, 137994, 139673, 113170, 113258, 138102, 139492, 139493, 139494, 139615, 139622, 139177, 139225, 137986, 139579, 139580, 139581, 139582, 139448, 139449, 139450, 139451, 139562, 139616, 139468, 139677, 139676, 139313, 138097, 113234, 138095, 139507, 139552, 139480, 139576, 139577, 139578, 139497, 139567, 139452, 139453, 139454, 139455, 139617, 138022, 139469, 139470, 139471, 138098, 138107, 138103, 138101, 138002, 138014, 139675, 139671, 138096, 139508, 139509, 138105, 139498, 139499, 137970, 138108, 139533, 139534, 139568, 139569, 139570, 138106, 138100, 139563, 139564, 138006, 137978, 137974, 139553, 139554, 139548, 139549, 139558, 139559, 113035, 113020, 119311, 119243, 119359, 112968, 112980, 120392, 120401, 120390, 113019, 120395, 120389, 113022, 113027, 113037, 113018, 113023, 119247, 119293, 119377, 119326, 119384, 119250, 119374, 119379, 119376, 119365, 113013, 112996, 120425, 120445, 119363, 119309, 119378, 119303, 113036, 112964, 119268, 119318, 119253, 113028, 113025, 120387, 120421, 120394, 120386, 120429, 120396, 112972, 112960, 113034, 113030, 113024, 113031, 112976, 113021, 113038, 119369, 119255, 119283, 119240, 119334, 119364, 119288, 119375, 119249, 119385, 119338, 119346, 119360, 119256, 119387, 113032, 113039, 119257, 120441, 120399, 119322, 119350, 119278, 119279, 119280, 119281, 119282, 119239, 119342, 113033, 113029, 120398, 120402, 120391, 113026, 119308, 119273, 119354, 119242, 120413, 113015, 113016, 113010, 113014, 119298, 119358, 113011, 112988, 112992, 119381, 119241, 120433, 120400, 120384, 120437, 120449, 119299, 119300, 119301, 119302, 119370, 119383, 119248, 119238, 119245, 119380, 119366, 119382, 120383, 120417, 120393, 120385, 119372, 119246, 119373, 119252, 119361, 119367, 119251, 119244, 119330, 120397, 119386, 119310, 119258, 119362, 119263, 119368, 119254, 89074, 89175, 89068, 89101, 89124, 89174, 89091, 89185, 89186, 89082, 89083, 89071, 89111, 89127, 89177, 89181, 89067, 89114, 89112, 89089, 89183, 89084, 89110, 89118, 89136, 89168, 89137, 89146, 89139, 89149, 89145, 89152, 89155, 89144, 89170, 89166, 89143, 89167, 71769, 71788, 71773, 71771, 71781, 88964, 71790, 71770, 71779, 88963, 71782, 71775, 71796, 71691, 88914, 89033, 88864, 71642, 71649, 71677, 71679, 71708, 89032, 88895, 71661, 71646, 71729, 71650, 71726, 71670, 71706, 71652, 71716, 71721, 71715, 88874, 89041, 88883, 89027, 71688, 71709, 71727, 71719, 71699, 71643, 88913, 71703, 88943, 88938, 88942, 88944, 88936, 88925, 79350, 79377, 80240, 79833, 81160, 81210, 79368, 79374, 79566, 79356, 81132, 80260, 80070, 80045, 79575, 79563, 79359, 81169, 79854, 79830, 80192, 80228, 79572, 79587, 79860, 81147, 80204, 80041, 80010, 80040, 80049, 80043, 80268, 79569, 79560, 81126, 81135, 81151, 81144, 79845, 80244, 81189, 79362, 79929, 79857, 81141, 79920, 79932, 81175, 80160, 80184, 80168, 80256, 80176, 80264, 80015, 80012, 80048, 80014, 80019, 81183, 81195, 80044, 80013, 80047, 79578, 79581, 79839, 80276, 80236, 80180, 80252, 80208, 80046, 81198, 81201, 81154, 81163, 79926, 81129, 79365, 79848, 81138, 79371, 79941, 81120, 80164, 80220, 80011, 80200, 80196, 81186, 81204, 80017, 80018, 75679, 75686, 75692, 75691, 75693, 75669, 75685, 75634, 75639, 75705, 75647, 75694, 75717, 75516, 75622, 75604, 75624, 75612, 75605, 75615, 75623, 75629, 75589, 75625, 75613, 75606, 75611, 75620, 75627, 75626, 75618, 75510, 75524, 75602, 75610, 75621, 75592, 75614, 75619, 75617, 75630, 75609, 80212, 80213, 80224, 80225, 80226, 80227, 80214, 80215, 61111, 61115, 61098, 61116, 61102, 61099, 61112, 61100, 61104, 61108, 61106, 61097, 61107, 61117, 61105, 61095, 61114, 61094, 61093, 61096, 61091, 61103, 61109, 61110, 61089, 61118, 61092, 61090, 61101, 61113, 84977, 84921, 84978, 84936, 84938, 84961, 84780, 84919, 84943, 84880, 84831, 84964, 84941, 84884, 84932, 84965, 84973, 84974, 84724, 84741, 84739, 84967, 84720, 84975, 84886, 84885, 84937, 84782, 84918, 84837, 84944, 148065, 148136, 148072, 84962, 84721, 84883, 84939, 84749, 84960, 84744, 148146, 148149, 148155, 148094, 148137, 148162, 148113, 148151, 148099, 148062, 148120, 84956, 84779, 84785, 84949, 84728, 84976, 148083, 148075, 148103, 148100, 148175, 148092, 84751, 84879, 84951, 84933, 84920, 148069, 148125, 148105, 84888, 84833, 84969, 84946, 148173, 148135, 148060, 148109, 148078, 84745, 84726, 84952, 84915, 148143, 148164, 148087, 148145, 148131, 148126, 148115, 85864, 85812, 85813, 85845, 85890, 85891, 85843, 85874, 85861, 85834, 85817, 85811, 85858, 85836, 85826, 85882, 85816, 52873, 66356, 66151, 66145, 53005, 66526, 62682, 52960, 66400, 65281, 52824, 66560, 101006, 99008, 99025, 65287, 65323, 52948, 66554, 65359, 65263, 65347, 62544, 98975, 101770, 66372, 66073, 62564, 101812, 100774, 100732, 65995, 53011, 66351, 52957, 52927, 52839, 52830, 62634, 66500, 66402, 66450, 66350, 100654, 101666, 98997, 99338, 62646, 66513, 66456, 66549, 66540, 99647, 100671, 66109, 65245, 66163, 52999, 66357, 62591, 52975, 66392, 101861, 100952, 99305, 66121, 62712, 62562, 66025, 62706, 52820, 66555, 66001, 66103, 66097, 65305, 66157, 65299, 52954, 66524, 100999, 99636, 62576, 66531, 62724, 52882, 66541, 66409, 52823, 62628, 65989, 66133, 52915, 52996, 52891, 66444, 100791, 101947, 100821, 65293, 66067, 65329, 98986, 65269, 100896, 100910, 62538, 66043, 62622, 62532, 65335, 65275, 62652, 62640, 62508, 62550, 66019, 65251, 98964, 100868, 98942, 66013, 66169, 102018, 101056, 99272, 62574, 99481, 99658, 99449, 101721, 101619, 99360, 99415, 100835, 66384, 66394, 66367, 66380, 66499, 66352, 66435, 66521, 66539, 66481, 66399, 66378, 66337, 66326, 66467, 66414, 66344, 66331, 66325, 66543, 66491, 66329, 66486, 66480, 66415, 66338, 97864, 65621, 97828, 66320, 65833, 97912, 66207, 97820, 97788, 97856, 97844, 97832, 97868, 97880, 66282, 66255, 65785, 66201, 97824, 97804, 66284, 97904, 97896, 97816, 66196, 66301, 97924, 97916, 97772, 97920, 66263, 97900, 97884, 97800, 65874, 66225, 65869, 66319, 65855, 97784, 66230, 97908, 97888, 65677, 97776, 97852, 97928, 97876, 65741, 97796, 97836, 66273, 97780, 66317, 66189, 97860, 97792, 97892, 97840, 97848, 97808, 53276, 66669, 79070, 53294, 66635, 79035, 79062, 78942, 78915, 53335, 66682, 78925, 53344, 66694, 79043, 78878, 78881, 79059, 78903, 78951, 78864, 66566, 53305, 53341, 66652, 78961, 53279, 66628, 79068, 78914, 78905, 78924, 53349, 66676, 78983, 53346, 66617, 53291, 66588, 78916, 53290, 66658, 78949, 78937, 79032, 79057, 66670, 78927, 53267, 66697, 66684, 53329, 78956, 78923, 78867, 78906, 79002, 78869, 79019, 78861, 53287, 66632, 78877, 79058, 78952, 78938, 78945, 78858, 79026, 79045, 78975, 78874, 78997, 79039, 79011, 78972, 78959, 78882, 78876, 78957, 79029, 79071, 79080, 78928, 79004, 78871, 78966, 78885, 79076, 78993, 79013, 79028, 78979, 79048, 78982, 78860, 78865, 78940, 79020, 78947, 78902, 78879, 79016, 78976, 78886, 79044, 78931, 78917, 78968, 78863, 79065, 78868, 78977, 60017, 60003, 60034, 59984, 59997, 60028, 60025, 60032, 60005, 60036, 59982, 59991, 60018, 60019, 59981, 60029, 60023, 60006, 49276, 49274, 49268, 49264, 49287, 49277, 49271, 49275, 49272, 53553, 49290, 53545, 49281, 49286, 49263, 49289, 49269, 49273, 49279, 49262, 53533, 53589, 49261, 49266, 53625, 49267, 49282, 49285, 53609, 49284, 49278, 49280, 49265, 49288, 53537, 53673, 49283, 53613, 53541, 53581, 53569, 53557, 53573, 53577, 53605, 53597, 53649, 53585, 53621, 53617, 53601, 53645, 53637, 53641, 53693, 53561, 53697, 85354, 85399, 85366, 85415, 84793, 49270, 84801, 85378, 84805, 147491, 147554, 147519, 147576, 147510, 87037, 87091, 87024, 87064, 87074, 87045, 87120, 87040, 8463, 87036, 87084, 87034, 87058, 87088, 87125, 87078, 87054, 87105, 87082, 87113, 87117, 147508, 147562, 147514, 147485, 147552, 147501, 87033, 87053, 87032, 87119, 87068, 87028, 87085, 87062, 87083, 87132, 87056, 87123, 87133, 87039, 87089, 87025, 87072, 87108, 87071, 87090, 87129, 87029, 87114, 87043, 87049, 87035, 87073, 87079, 147530, 147504, 147502, 147523, 147488, 147483, 147547, 147566, 147478, 147482, 147537, 87130, 87106, 87127, 147553, 147520, 147517, 147573, 147549, 87046, 87055, 147512, 147528, 147480, 147481, 147551, 87128, 87081, 147567, 147569, 147524, 147511, 147522, 147558, 147540, 147543, 147531, 147544, 87065, 87050, 87052, 87069, 147526, 147495, 147498, 147486, 147515, 147542, 87059, 87086, 87109, 87116, 87087, 87051, 87026, 147550, 147560, 147546, 147564, 87047, 147513, 147555, 147499, 147574, 147563, 147557, 147570, 147516, 147541, 147561, 147575, 147503, 147548, 147497, 147568, 147500, 147577, 147489, 147532, 147490, 147506, 147572, 147509, 147521, 147533, 147518, 147494, 147525, 147492, 147487, 87070, 87112, 87104, 87061, 87131, 87030, 87066, 87060, 87042, 80658, 80520, 80496, 80622, 80526, 80628, 80352, 80664, 80376, 80340, 80418, 80592, 80616, 80424, 80538, 80640, 80580, 80544, 80508, 80550, 80604, 80586, 80502, 80598, 80466, 80454, 80382, 80412, 80448, 80364, 80574, 80406, 80568, 80442, 80370, 80310, 80394, 80328, 80472, 80358, 80322, 80430, 80346, 80436, 80610, 80388, 80484, 80562, 80334, 80490, 80532, 80556, 80652, 80634, 80646, 54115, 54151, 54125, 54150, 54103, 54142, 54113, 54117, 54158, 54120, 54114, 54106, 54137, 54145, 54111, 54138, 54144, 54146, 54148, 54132, 147606, 54121, 54109, 54107, 54122, 54130, 86787, 86890, 86887, 86876, 86853, 86798, 86796, 86783, 86773, 86784, 86799, 86790, 86842, 86795, 86852, 86900, 86881, 86857, 86797, 86903, 86895, 86840, 86782, 86894, 147605, 147660, 147612, 147630, 147654, 147602, 147589, 147651, 147635, 147664, 147615, 147652, 147593, 147648, 147617, 147644, 147614, 147642, 86884, 86785, 86880, 86886, 86777, 86802, 86836, 86877, 86879, 86775, 86891, 86793, 86855, 86893, 86849, 86841, 86904, 86860, 147599, 147665, 147585, 147625, 147583, 147632, 147584, 147647, 147638, 147656, 147613, 147655, 147668, 86800, 86892, 86835, 147620, 147662, 147591, 147603, 147666, 147649, 147633, 147657, 147663, 147643, 86778, 86885, 147622, 147616, 147636, 147669, 147594, 147670, 147634, 147646, 147631, 147604, 86834, 86908, 86794, 147611, 147592, 86889, 86901, 86792, 86845, 147629, 147597, 147600, 147608, 147586, 147645, 147671, 86848, 86851, 86882, 86774, 86902, 147667, 147609, 147639, 147641, 147610, 147619, 147640, 86888, 147628, 147626, 86907, 86905, 86779, 86909, 147623, 147598, 147658, 147601, 86801, 86847, 86883, 86844, 86786, 86789, 86856, 86837, 86838, 86843, 86906, 54161, 54127, 54131, 54105, 54160, 54136, 54139, 54126, 71349, 71342, 71347, 71340, 71361, 71357, 71359, 71346, 71343, 71355, 71345, 71362, 71363, 71354, 71339, 71358, 71368, 71353, 71341, 71365, 71360, 71351, 71344, 71352, 71350, 71356, 94877, 94868, 94865, 94866, 94885, 94894, 94876, 148009, 147993, 148013, 148015, 94899, 94869, 94897, 94902, 94903, 94881, 94896, 94878, 94886, 94872, 94867, 94892, 148011, 147977, 148008, 147985, 148004, 94890, 94898, 94889, 147986, 148010, 147984, 147980, 94888, 94871, 94891, 94874, 148000, 147997, 148012, 148007, 148002, 94879, 94882, 94904, 94895, 94887, 148014, 147994, 94875, 147999, 147988, 148006, 148001, 84700, 84628, 86124, 86096, 86122, 86104, 85102, 85099, 85103, 84705, 85684, 84704, 85106, 84620, 85685, 84624, 85094, 84708, 85683, 85650, 86101, 86102, 85682, 53689, 53741, 53757, 53665, 53657, 53745, 53765, 53761, 53681, 53729, 53769, 53661, 53721, 53653, 53737, 53709, 53669, 53753, 53713, 53705, 53733, 53677, 53717, 53685, 85316, 85328, 85462, 85286, 85274, 85313, 84764, 85478, 85510, 85298, 85295, 84758, 85277, 85518, 85502, 80890, 80814, 80702, 80738, 80794, 80826, 80694, 80898, 80722, 80822, 80798, 80714, 80690, 80834, 80710, 80790, 80742, 80866, 80838, 80818, 80874, 80670, 80810, 80894, 89616, 89641, 80806, 80786, 80718, 80730, 80674, 80726, 89606, 89682, 89677, 80882, 80802, 80682, 80850, 89673, 89694, 89626, 89653, 80830, 80734, 89637, 80858, 80842, 80906, 89603, 89678, 89619, 89672, 89600, 89647, 80846, 89675, 80698, 89615, 80686, 80886, 80854, 80878, 89594, 89609, 80706, 80678, 89610, 60117, 60084, 60066, 60150, 60083, 60047, 60136, 60109, 60086, 60124, 60123, 60111, 60071, 60098, 60070, 60120, 60058, 60139, 60113, 60099, 60040, 60038, 60051, 60119, 60054, 60093, 60080, 60097, 60073, 60152, 60076, 60129, 60045, 60079, 60147, 60042, 60050, 60048, 60151, 60069, 60091, 60141, 60046, 60127, 60102, 60145, 60126, 60156, 60148, 60089, 60037, 60128, 60135, 60154, 60055, 60096, 60039, 60104, 60056, 60105, 60078, 60138, 60121, 60132, 60067, 60142, 60115, 60049, 60101, 60057, 60131, 60062, 60082, 60107, 60063, 60118, 60114, 60125, 60052, 60110, 60153, 60149, 60060, 60044, 60072, 60155, 60068, 60053, 60133, 60043, 60090, 60094, 60112, 60100, 60146, 60088, 60059, 60108, 60106, 60081, 60064, 60095, 60140, 60116, 60065, 60134, 60144, 60092, 60103, 60077, 60130, 60041, 60085, 60137, 59913, 59898, 108993, 108984, 108978, 108972, 108990, 108939, 108945, 108909, 108963, 108957, 59874, 59939, 59860, 59941, 108936, 108924, 108903, 59926, 59887, 59899, 59962, 59970, 59975, 59930, 59905, 59885, 59864, 108921, 108912, 108969, 59932, 59924, 59963, 59917, 109002, 59889, 59943, 59903, 59969, 108930, 59960, 108897, 109014, 109005, 108996, 108906, 109008, 108987, 59912, 59878, 59922, 59895, 109011, 108948, 108954, 108915, 108960, 108951, 108918, 108966, 108942, 108927, 85241, 85057, 84673, 85011, 84663, 108999, 85018, 85216, 84662, 108933, 108900, 85017, 85015, 85240, 85014, 85054, 85217, 84669, 85246, 91670, 85010, 91672, 85244, 84676, 85012, 85242, 85053, 108975, 84678, 147894, 147887, 147881, 147909, 148021, 147907, 147917, 148051, 148036, 84677, 85211, 85060, 85213, 85212, 91668, 84670, 84659, 147920, 147918, 147878, 147915, 147899, 147884, 85050, 85061, 147886, 147882, 147888, 147912, 148018, 148052, 147933, 147934, 148022, 148044, 148027, 148054, 147906, 148026, 148041, 148037, 148032, 148047, 148053, 148035, 148023, 84665, 85055, 85215, 85009, 85210, 84660, 84661, 91673, 85051, 91669, 147898, 147889, 148024, 148050, 148020, 147923, 148025, 148029, 84674, 147929, 147897, 147877, 84666, 147930, 148034, 148033, 147926, 147924, 147916, 148017, 148028, 148030, 147908, 147902, 147914, 147935, 147885, 58668, 71387, 58711, 71380, 71394, 71373, 58699, 58686, 58673, 58697, 58687, 71383, 58681, 58693, 71389, 58718, 58698, 58721, 58671, 58666, 58677, 58713, 58682, 58725, 58675, 58670, 58706, 58689, 71369, 58709, 58683, 58723, 58720, 71376, 58707, 58704, 58667, 58715, 58672, 71378, 58702, 58676, 58714, 58684, 58712, 58708, 58695, 58688, 58719, 58690, 58705, 58717, 58691, 58716, 71382, 58710, 71385, 58703, 58700, 71396, 71392, 58701, 58722, 71390, 71388, 71395, 71377, 58679, 71384, 71372, 71397, 58694, 71375, 71379, 71386, 58724, 58678, 58669, 71398, 71391, 71381, 58692, 58674, 71370, 58696, 147828, 147839, 147865, 147829, 147850, 147841, 147874, 147847, 147817, 147837, 147866, 147836, 147856, 147827, 147852, 147830, 147867, 147823, 147868, 58680, 147869, 147855, 147862, 147843, 147857, 147871, 147838, 147834, 147820, 147861, 147835, 147831, 147818, 147844, 147863, 147851, 147822, 147849, 147858, 147842, 147848, 147859, 147819, 147825, 147870, 147833, 147876, 147854, 147824, 147840, 147845, 147875, 147873, 147821, 147864, 86373, 86379, 86261, 86264, 86277, 86258, 86239, 86377, 86259, 86274, 86375, 86248, 86305, 86387, 86252, 86268, 86386, 86285, 86271, 86298, 86307, 86291, 86367, 86244, 86393, 86247, 86301, 86371, 86266, 86390, 86279, 86294, 61496, 61655, 61616, 61703, 61484, 61565, 61595, 61643, 61640, 61661, 61634, 61682, 61568, 61625, 61532, 61622, 61499, 61526, 61649, 61583, 61520, 61673, 61562, 61592, 61691, 61544, 61694, 61460, 61607, 61631, 61610, 61493, 61580, 61664, 61469, 61517, 61589, 61535, 61652, 61451, 61448, 61529, 61466, 61658, 61628, 61547, 61541, 61598, 61577, 61601, 61685, 61553, 61487, 61559, 120305, 120289, 120285, 120309, 120188, 120224, 120333, 120329, 120277, 120293, 120261, 120281, 120269, 120196, 120164, 120156, 120232, 120204, 120172, 120200, 120208, 120176, 120301, 120273, 120313, 120317, 120212, 120228, 120297, 120257, 120321, 120265, 120216, 120325, 120192, 120180, 120220, 120168, 120160, 120184, 85273, 85265, 85268, 85343, 84731, 85264, 84736, 85272, 85335, 58790, 51595, 58773, 58779, 58768, 51621, 58775, 51574, 58791, 51628, 51591, 51576, 58771, 51597, 51589, 51613, 51572, 51616, 51601, 51629, 51592, 58780, 58777, 51636, 51598, 58774, 58796, 51625, 58778, 58784, 51580, 58770, 51615, 51634, 51620, 51579, 58769, 51577, 58788, 51600, 58794, 51588, 51596, 51618, 51639, 51594, 51590, 58793, 58782, 51619, 58776, 51626, 58787, 51617, 51638, 51614, 51642, 51582, 51593, 51640, 51637, 51623, 51573, 51627, 51586, 58792, 58795, 58772, 51578, 51622, 51599, 51635, 51581, 58781, 51632, 51575, 51585, 51633, 51630, 51583, 90691, 90969, 90999, 91039, 90981, 90993, 90975, 90976, 91022, 91042, 91036, 91019, 91032, 91031, 91040, 90987, 91011, 90968, 91017, 91579, 91028, 91600, 91581, 91035, 91043, 91009, 91599, 90974, 90989, 91594, 90973, 90986, 90972, 90990, 91024, 91595, 91010, 91596, 91001, 91580, 91033, 90996, 91572, 91038, 91027, 91012, 91573, 91598, 90967, 90991, 91025, 91575, 90992, 91601, 91002, 91026, 90984, 91003, 90985, 91015, 91578, 91020, 90995, 91007, 90982, 91018, 90980, 90998, 91034, 91045, 90970, 90983, 91023, 91013, 91044, 90988, 91030, 91014, 91006, 91602, 90952, 90863, 90910, 90957, 91627, 90852, 90912, 91622, 91610, 90922, 91637, 90950, 90941, 91621, 90947, 90913, 90965, 91618, 90959, 90955, 90861, 90936, 90864, 90926, 91603, 90920, 91620, 90843, 91604, 59674, 59677, 59714, 59717, 59676, 59716, 107965, 93328, 93315, 93307, 93324, 93316, 93309, 93314, 59675, 59715, 166545, 166552, 166548, 166547, 166550, 166386, 166551, 166554, 166380, 166387, 166385, 166553, 166384, 166382, 166383, 166389, 166381, 166549, 166388, 147408, 147394, 147434, 147400, 147378, 147465, 147453, 147447, 147462, 147398, 147448, 147382, 147388, 147456, 147436, 88558, 88610, 88508, 88531, 88521, 88541, 88624, 147432, 147429, 147433, 147439, 147430, 147471, 147454, 147380, 147435, 147466, 147440, 147475, 88594, 147442, 147474, 147391, 147427, 147407, 147387, 147410, 147385, 147399, 147463, 147426, 147459, 147383, 147441, 147464, 147445, 147419, 147392, 147414, 147401, 147473, 147384, 147457, 147425, 147431, 147469, 88520, 88544, 88625, 88533, 147406, 147403, 88609, 88603, 88509, 88553, 88524, 88550, 88530, 88598, 88612, 88500, 88511, 88512, 88617, 88537, 88599, 147420, 147428, 147449, 147377, 147393, 88526, 88615, 88620, 88534, 88611, 88522, 88555, 88503, 147422, 147455, 147467, 147452, 147458, 147405, 147390, 147443, 147470, 88505, 88497, 147461, 147411, 147376, 147468, 147421, 88626, 88527, 88543, 88546, 88600, 88557, 88510, 147437, 147472, 147451, 88535, 88623, 88504, 53931, 53841, 53843, 53865, 53875, 53897, 53911, 53878, 53837, 53925, 53880, 53900, 53962, 53850, 53966, 53893, 53866, 53927, 53845, 53963, 89717, 53940, 89711, 53898, 84894, 53906, 89742, 84906, 89724, 89703, 89715, 84900, 89725, 89663, 89707, 89756, 89702, 89752, 89666, 53907, 84889, 84891, 53863, 89946, 89736, 53899, 53965, 53901, 53960, 84908, 89716, 53967, 54031, 54087, 54067, 53991, 53995, 54027, 54043, 54011, 54063, 54071, 54035, 54015, 54059, 54099, 53999, 54083, 54095, 54091, 54075, 54003, 54023, 53983, 54019, 54039, 147288, 147297, 147283, 147286, 147303, 147304, 147298, 147308, 147285, 53987, 147309, 147301, 147282, 147281, 147291, 147306, 147296, 147302, 147300, 147280, 147307, 147295, 147293, 147287, 147284, 147289, 147290, 147292, 54055, 147299, 147294, 54047, 147305, 54454, 54541, 54517, 54590, 54574, 54592, 54370, 54578, 54223, 54455, 54608, 54567, 54505, 54427, 54457, 54566, 54456, 54453, 54459, 54451, 54609, 54458, 54449, 54450, 54460, 54462, 54452, 54508, 54277, 54496, 54319, 54196, 54202, 54235, 54603, 54169, 54588, 54199, 54445, 54523, 54259, 54448, 54461, 54447, 54433, 54559, 54352, 54575, 54283, 54444, 54502, 54406, 54424, 54446, 54598, 54262, 54481, 54232, 54520, 54564, 54271, 54295, 54385, 54596, 54529, 54304, 54612, 54604, 54584, 54561, 54388, 54526, 54358, 54553, 54265, 54600, 54563, 54597, 54292, 54591, 54430, 54490, 54514, 54572, 54585, 54250, 54247, 54583, 54568, 54562, 54582, 54289, 54586, 54569, 54511, 54208, 54349, 54211, 54193, 54334, 54217, 54560, 54175, 54579, 54499, 54538, 54268, 54475, 54593, 54570, 54605, 54412, 90664, 90010, 90232, 90172, 90040, 90371, 90359, 90183, 90362, 90234, 54409, 90058, 90443, 90347, 54610, 90173, 90575, 54313, 54421, 90186, 90470, 54310, 54382, 90380, 90046, 54577, 90239, 90703, 54397, 54205, 90498, 90231, 53801, 58814, 53785, 53775, 53792, 53791, 53786, 53789, 58822, 53774, 58821, 58800, 58812, 53790, 53777, 58804, 58823, 53779, 58805, 53794, 58818, 53788, 58815, 53776, 53795, 147337, 147360, 147345, 147352, 147331, 147346, 147354, 147340, 147350, 147330, 147359, 147343, 147356, 147365, 58808, 58827, 53799, 53784, 147368, 147341, 147353, 147313, 147324, 147348, 58820, 147326, 147325, 147312, 147364, 147367, 147344, 58816, 147339, 147363, 147315, 147355, 147336, 147370, 147320, 147329, 147351, 147333, 147347, 147318, 53802, 147332, 147317, 147366, 147342, 147334, 58807, 53797, 147369, 147358, 147327, 147322, 147319, 58809, 147361, 147338, 147314, 147323, 147362, 147328, 147349, 147321, 147371, 53783, 53782, 53778, 58819, 58826, 58803, 58813, 58801, 86528, 86727, 86452, 86535, 86359, 86550, 86543, 86527, 86554, 86544, 86729, 86605, 86611, 86546, 86728, 86312, 86330, 86750, 86311, 86662, 86579, 86648, 86608, 86746, 86725, 86745, 86670, 86548, 86741, 86627, 86513, 86540, 86360, 86326, 86751, 86754, 86455, 86577, 77544, 77545, 77546, 77547, 77548, 77549, 77550, 77551, 77444, 77472, 77473, 77474, 77475, 77445, 77446, 77447, 77480, 77481, 77482, 77483, 77512, 77513, 77514, 77515, 77532, 77533, 77534, 77535, 77484, 77485, 77486, 77487, 77520, 77521, 77522, 77523, 77528, 77529, 77530, 77531, 77440, 77441, 77442, 77443, 77524, 77525, 77526, 77527, 76203, 76204, 76205, 76206, 76207, 76208, 76209, 76210, 76339, 76340, 76341, 76342, 76343, 76344, 76346, 76349, 76243, 76244, 76245, 76246, 76247, 76248, 76249, 76250, 76387, 76388, 76389, 76390, 76391, 76392, 76393, 76396, 76374, 76375, 76377, 76380, 76382, 76384, 76385, 76386, 76219, 76220, 76221, 76222, 76223, 76224, 76225, 76226, 76275, 76276, 76277, 76278, 76279, 76280, 76281, 76282, 76315, 76316, 76317, 76318, 76319, 76320, 76321, 76322, 76235, 76236, 76237, 76238, 76239, 76240, 76241, 76242, 75332, 75309, 90209, 75335, 75318, 75313, 75330, 75326, 75315, 75325, 75322, 75319, 75314, 75333, 75334, 75337, 75316, 51213, 51183, 66855, 66804, 66805, 66806, 66822, 66823, 66824, 51171, 66840, 66841, 66842, 51177, 66849, 66828, 66792, 66846, 66798, 66825, 66826, 66827, 51138, 51156, 66858, 66859, 66860, 66837, 66838, 66839, 51189, 66864, 66865, 66866, 66786, 66787, 66788, 51192, 66831, 66819, 51198, 66820, 51153, 66847, 66848, 66807, 51150, 51180, 51210, 66795, 66796, 66797, 66799, 66800, 51162, 51132, 51135, 51186, 84614, 84615, 66793, 66794, 66783, 51195, 84597, 84598, 84594, 84616, 51219, 66870, 85112, 84980, 84996, 84613, 66829, 66830, 66801, 66861, 84601, 84610, 66813, 66852, 51141, 85113, 84981, 84988, 66862, 66863, 51201, 66843, 66844, 66845, 51165, 84618, 84589, 66871, 66872, 66834, 66835, 66836, 66789, 66790, 66791, 51147, 66810, 66811, 66812, 66821, 51168, 66802, 66803, 51159, 66832, 66833, 66856, 66857, 66867, 66868, 66869, 51144, 66850, 66851, 66808, 66809, 51204, 51174, 51216, 66816, 66784, 66785, 66853, 66854, 66814, 66815, 51207, 84987, 84991, 84602, 85117, 84599, 84990, 84617, 66817, 66818, 85118, 84590, 51012, 51005, 51112, 51113, 51114, 51115, 51016, 51124, 51125, 51126, 51127, 51100, 51101, 51102, 51103, 50985, 51007, 50989, 50993, 50994, 50982, 51044, 50997, 50984, 50995, 51064, 51001, 51116, 51117, 51118, 51119, 51084, 51085, 51003, 51086, 51087, 51040, 51076, 51108, 51004, 50990, 51120, 51121, 51122, 51123, 51109, 51110, 51111, 51028, 50986, 50991, 51052, 51053, 51054, 51055, 51104, 51105, 51106, 51107, 51068, 50988, 51011, 50992, 51088, 51089, 51090, 51091, 51065, 51066, 51067, 51024, 51025, 51026, 51027, 51048, 51020, 51000, 50987, 51060, 51009, 50999, 51002, 51045, 51046, 51047, 50983, 50996, 50998, 51010, 51032, 51033, 51034, 51035, 51096, 51061, 51062, 51063, 51077, 51078, 51079, 51072, 51073, 51074, 51075, 51069, 51070, 51071, 51080, 51041, 51042, 51043, 85068, 84638, 85046, 51092, 51006, 51008, 85080, 85086, 85019, 85056, 85028, 85034, 51021, 51022, 51023, 51056, 51057, 51058, 51059, 51128, 84632, 84647, 85043, 85077, 84629, 51036, 85065, 84650, 85074, 51037, 51038, 51039, 84641, 85062, 51029, 51030, 51031, 51093, 51094, 51095, 51081, 51082, 51083, 51097, 51098, 51099, 51049, 51050, 51051, 85025, 84656, 84644, 51129, 51130, 51131, 97575, 97659, 97691, 97723, 97715, 97747, 97607, 97679, 97563, 97564, 97565, 97566, 97655, 97567, 97675, 97603, 97539, 97551, 97671, 97623, 97579, 97719, 97707, 97660, 97661, 97662, 97611, 97663, 97743, 97744, 97745, 97746, 97643, 97595, 97591, 97583, 97650, 97751, 97752, 97753, 97754, 97739, 97763, 97687, 97731, 97724, 97725, 97726, 97540, 97541, 97542, 97619, 97711, 97555, 97767, 97683, 97627, 97695, 97639, 97571, 97572, 97573, 97574, 97631, 97692, 97547, 97548, 97549, 97550, 97535, 97699, 97584, 97585, 97586, 97531, 97580, 97581, 97582, 97667, 87889, 87863, 87885, 87700, 87741, 87809, 88354, 88391, 88344, 88294, 88299, 88341, 88380, 88324, 88367, 88395, 88352, 88331, 88350, 88349, 88387, 88332, 88386, 88301, 88362, 88308, 88293, 88363, 88339, 88321, 88351, 107872, 107873, 87611, 87547, 87491, 87477, 87495, 87578, 87623, 87551, 87476, 87902, 87991, 87916, 88035, 88032, 88109, 88185, 88173, 88097, 88190, 107874, 107875, 107731, 107696, 107700, 107701, 107702, 107745, 107738, 107710, 107865, 107781, 87837, 87990, 88010, 87925, 87958, 87906, 87922, 87572, 87528, 87542, 87490, 87499, 88191, 88140, 88137, 88189, 88143, 88156, 88153, 107844, 107845, 88346, 88359, 88311, 88320, 88333, 87719, 87891, 87701, 87694, 88292, 88318, 88335, 107846, 107847, 107788, 107749, 107750, 107751, 107809, 107830, 107753, 107837, 87764, 87836, 87884, 87816, 87872, 87715, 87839, 87734, 88291, 88390, 88315, 88309, 88368, 87718, 87780, 87766, 87713, 87717, 87803, 87740, 87815, 87698, 87697, 87699, 87838, 87693, 87883, 87739, 87813, 87835, 87886, 87864, 87716, 88394, 88288, 88347, 88323, 107681, 107760, 107667, 107823, 107827, 107828, 107829, 107858, 107782, 107783, 107784, 107767, 107774, 107717, 87508, 87627, 87573, 87506, 87549, 87605, 87624, 88162, 88188, 88106, 88165, 88127, 88141, 88092, 88175, 88187, 87996, 88041, 87946, 87912, 87993, 88029, 87928, 87955, 88100, 88125, 88098, 88147, 88093, 88128, 88119, 88110, 88178, 88180, 88118, 88124, 88182, 88105, 88160, 88120, 88101, 88149, 87812, 87834, 87805, 87768, 88357, 88385, 88295, 88365, 88329, 107724, 87615, 87503, 87498, 87628, 87602, 88103, 88161, 87977, 87935, 87903, 87841, 87833, 87810, 87804, 87822, 87722, 87736, 88302, 88322, 88337, 88306, 87720, 87890, 88340, 88310, 88345, 107816, 107817, 107818, 107819, 107732, 107733, 107734, 107848, 107849, 107850, 107714, 107715, 107716, 107841, 107842, 107843, 107785, 107786, 107787, 107778, 107779, 107780, 107792, 107793, 107794, 107689, 87525, 87530, 87574, 87630, 87485, 87620, 87581, 87553, 87616, 87577, 88117, 88096, 88151, 88018, 87970, 88011, 87473, 87501, 87504, 87509, 87543, 87555, 87507, 87575, 87475, 87603, 87580, 87479, 87478, 87765, 87869, 87866, 88298, 87892, 88305, 88389, 88355, 88366, 88296, 107703, 107704, 107705, 107706, 107810, 107811, 107812, 107728, 107729, 107730, 107795, 107799, 107800, 107801, 107838, 107839, 107840, 107697, 107698, 107699, 87607, 87558, 87621, 88146, 88090, 88133, 88111, 88112, 87926, 87940, 87950, 87951, 87489, 87500, 107802, 107806, 107807, 107808, 107851, 107855, 107856, 107857, 107831, 107832, 107833, 87868, 87820, 88336, 88383, 88319, 88327, 88353, 88334, 107674, 87608, 88134, 88148, 88132, 88183, 87924, 87929, 87943, 88037, 87992, 87818, 88290, 88392, 107721, 107722, 107723, 87556, 87579, 87472, 88176, 88139, 87994, 87927, 87932, 88009, 97735, 87629, 87613, 87763, 87887, 87721, 87807, 88297, 88304, 88384, 88326, 88388, 88313, 88369, 88300, 88289, 107852, 107853, 107854, 107859, 107860, 107861, 107876, 107877, 107878, 107768, 107769, 107770, 87510, 87523, 87492, 87526, 107675, 107676, 107677, 107824, 107825, 107826, 107668, 107669, 107670, 107739, 107740, 107741, 88138, 88154, 88123, 87945, 87907, 87941, 107685, 107686, 107687, 107761, 107762, 107763, 88356, 88328, 88343, 88314, 88393, 88370, 87502, 87480, 88099, 88113, 87937, 87978, 88107, 108127, 107990, 108102, 107985, 121931, 121976, 121951, 122001, 121928, 121936, 121943, 121939, 121917, 121964, 121966, 121967, 167341, 167369, 167326, 167331, 167307, 167302, 167335, 167330, 167349, 167329, 167371, 167350, 167340, 167325, 167356, 167292, 167306, 167320, 167367, 167332, 167377, 167372, 167316, 167324, 167309, 167321, 167299, 167293, 167315, 167295, 167381, 167319, 167366, 167344, 167328, 167312, 167378, 167355, 167357, 167297, 167313, 167327, 167311, 167336, 167294, 167362, 167380, 167310, 167353, 167347, 167314, 167375, 167317, 167376, 167305, 167379, 167345, 167360, 167298, 167342, 167308, 167354, 167346, 167301, 167374, 167359, 167351, 167352, 167361, 167364, 167304, 167339, 167334, 167370, 167333, 167373, 167338, 167300, 167363, 167337, 167358, 167322, 167343, 167318, 167303, 59638, 59639, 59686, 59687, 59646, 59647, 59688, 59689, 59794, 59795, 59796, 59797, 59730, 59731, 59732, 59733, 59766, 59767, 59768, 59769, 59762, 59763, 59764, 59765, 59806, 59807, 59648, 59649, 59726, 59727, 59728, 59729, 59682, 59683, 59684, 59685, 59798, 59799, 59800, 59801, 59610, 59611, 59612, 59613, 59602, 59603, 59604, 59605, 59718, 59719, 59720, 59721, 59770, 59771, 59606, 59607, 59808, 59809, 59608, 59609, 59598, 59599, 59600, 59601, 59802, 59803, 59804, 59805, 59642, 59643, 59594, 59595, 59596, 59597, 59722, 59723, 59724, 59725, 59644, 59645, 59640, 59641, 59650, 59651, 59652, 59653, 59678, 59679, 59680, 59681, 59758, 59759, 59760, 59761, 59690, 59691, 59692, 59693, 59634, 59754, 59772, 59773, 59635, 59636, 59637, 59755, 59756, 59757, 134702, 134794, 134787, 134719, 134714, 134708, 134744, 134722, 134791, 134704, 134805, 134721, 134788, 134703, 134701, 134698, 134736, 134726, 134793, 134800, 134700, 134706, 134799, 134739, 134734, 134724, 134733, 134696, 134720, 134713, 160149, 160150, 160151, 160152, 160153, 160154, 160155, 160156, 160157, 160158, 160159, 160160, 160161, 160162, 160163, 160164, 160165, 160166, 160167, 160168, 160169, 160170, 160171, 160172, 160173, 160174, 160175, 160176, 160177, 160178, 160179, 160180, 160181, 160182, 160183, 134712, 134732, 134699, 161473, 161474, 161475, 161476, 161477, 161478, 161479, 161480, 161481, 161482, 161483, 161484, 161485, 161486, 161487, 161488, 161489, 161490, 161491, 161492, 161493, 160359, 160184, 160185, 160186, 160187, 160188, 160189, 160190, 160191, 160192, 160193, 160194, 160195, 160196, 160197, 160198, 160199, 160200, 160201, 160202, 160203, 160204, 160205, 160206, 160207, 160208, 160209, 160210, 134796, 134707, 134786, 160211, 160212, 160213, 160214, 160215, 160216, 160217, 160218, 160219, 160220, 160221, 160222, 160223, 160224, 134742, 161494, 160225, 160226, 160227, 160228, 160229, 160230, 160231, 160232, 160233, 160234, 160235, 160236, 160237, 160238, 160239, 160240, 160241, 160242, 160243, 160244, 160360, 160361, 160362, 160363, 160364, 160365, 160366, 160367, 160368, 160369, 160370, 160371, 160372, 160373, 160374, 160375, 160376, 160377, 160378, 160379, 160380, 134717, 134735, 134731, 134804, 134716, 134740, 134801, 134715, 134802, 134737, 128458, 128476, 128437, 128474, 128462, 128463, 128472, 128297, 128271, 128272, 128269, 128302, 128270, 128257, 128258, 128276, 128293, 128235, 128236, 128294, 128225, 128226, 128288, 128305, 128223, 128224, 128295, 128298, 128283, 128300, 128452, 128454, 128451, 128445, 128447, 128460, 128466, 128470, 128229, 128230, 128263, 128264, 128287, 128281, 128284, 128304, 128250, 128251, 128278, 128279, 128285, 128440, 128449, 128441, 128439, 128243, 128299, 128252, 128241, 128242, 128245, 128289, 128464, 128291, 128292, 128233, 128234, 128303, 128275, 128227, 128228, 128248, 128282, 113520, 113521, 113522, 113523, 113524, 113697, 113515, 113516, 113517, 113518, 113519, 113550, 113781, 113782, 113783, 113784, 113785, 113786, 113500, 113745, 113575, 113545, 113546, 113547, 113548, 113549, 113415, 113416, 113417, 113418, 113419, 113365, 113366, 113367, 113368, 113369, 113370, 113371, 113372, 113373, 113374, 113420, 113421, 113422, 113423, 113424, 113360, 113361, 113733, 113734, 113735, 113736, 113737, 113738, 113727, 113763, 113400, 113793, 113794, 113795, 113796, 113797, 113721, 113722, 113723, 113724, 113725, 113726, 113535, 113536, 113537, 113538, 113539, 113580, 113817, 113691, 113380, 113381, 113530, 113531, 113532, 113533, 113534, 113585, 113586, 113587, 113588, 113589, 113435, 113895, 113896, 113897, 113898, 113899, 113900, 113642, 113465, 113466, 113467, 113468, 113469, 113739, 113430, 113570, 113679, 113680, 113681, 113682, 113683, 113764, 113765, 113766, 113767, 113768, 113470, 113471, 113472, 113473, 113474, 113847, 113848, 113849, 113850, 113851, 113852, 113385, 113618, 113619, 113620, 113621, 113622, 113623, 113495, 113555, 113630, 113581, 113582, 113583, 113584, 113877, 113871, 113872, 113873, 113874, 113875, 113876, 113835, 113709, 113710, 113711, 113712, 113713, 113714, 113450, 113451, 113452, 113453, 113454, 113798, 113440, 113441, 113442, 113443, 113444, 113480, 113565, 113566, 113567, 113568, 113569, 113460, 113455, 113811, 113812, 113813, 113814, 113815, 113816, 113636, 113637, 113638, 113639, 113640, 113641, 113405, 113406, 113407, 113408, 113409, 113445, 113661, 113654, 113655, 113656, 113657, 113658, 113659, 113551, 113552, 113553, 113554, 113624, 113625, 113626, 113627, 113628, 113629, 113805, 113769, 113770, 113771, 113772, 113773, 113774, 113571, 113572, 113573, 113574, 113787, 113788, 113789, 113790, 113791, 113792, 113525, 113425, 113715, 113716, 113717, 113718, 113719, 113720, 113505, 113506, 113507, 113508, 113509, 113806, 113807, 113808, 113809, 113810, 113818, 113819, 113820, 113821, 113822, 113386, 113387, 113388, 113389, 113703, 113775, 113776, 113777, 113778, 113779, 113780, 113390, 113836, 113837, 113838, 113839, 113840, 113490, 113853, 113481, 113482, 113483, 113484, 113426, 113427, 113428, 113429, 113883, 113884, 113885, 113886, 113887, 113888, 113841, 113859, 55166, 55041, 55179, 55301, 55070, 55068, 55065, 55153, 55284, 57284, 55096, 55303, 55309, 55197, 55266, 55169, 55336, 55194, 55253, 55136, 55183, 55307, 55286, 55182, 55081, 149062, 149066, 149028, 148989, 149156, 149161, 149138, 148552, 148539, 148519, 148584, 149183, 149034, 149030, 149047, 149036, 149147, 149130, 149119, 148556, 148561, 148540, 148555, 148533, 148562, 148544, 149184, 149185, 149186, 149187, 149188, 149189, 149190, 149191, 149192, 149193, 149008, 149069, 149003, 149000, 149061, 149048, 149033, 149109, 149104, 149105, 148521, 148573, 148578, 148588, 149194, 149195, 149196, 149197, 149198, 149199, 149200, 149201, 149202, 149203, 149204, 149205, 149206, 149024, 149037, 149046, 148987, 149139, 149168, 149088, 149158, 149150, 149084, 148523, 148550, 148551, 148554, 148579, 149012, 149071, 149075, 149123, 149141, 149126, 148571, 128455, 128465, 128419, 128420, 128448, 128425, 128426, 128407, 128408, 128421, 128422, 128459, 128461, 128446, 128457, 128442, 128411, 128412, 128431, 128432, 128467, 128401, 128402, 128443, 128453, 128438, 128469, 128444, 128450, 128471, 128423, 128424, 128413, 128414, 128403, 128404, 128429, 128430, 128435, 128436, 128397, 128398, 128473, 128456, 128405, 128406, 128475, 128468, 128417, 128418, 128399, 128400, 128427, 128428, 128433, 128434, 128415, 128416, 128409, 128410, 54542, 54543, 61497, 61498, 61617, 113046, 113239, 113240, 113241, 61704, 61705, 61485, 61486, 61566, 61567, 128363, 128364, 128371, 128395, 128385, 128369, 128370, 128379, 135061, 135069, 135051, 135102, 135087, 135100, 135095, 135082, 135118, 135144, 135196, 135132, 135199, 135139, 135116, 135160, 135941, 135949, 135954, 136020, 135983, 136022, 135984, 136053, 136082, 136062, 136054, 136051, 136040, 137884, 137869, 137872, 137873, 137879, 137789, 137790, 137791, 137809, 137844, 137779, 139654, 139657, 139293, 139310, 139318, 139289, 139303, 139301, 108995, 108980, 108973, 108992, 53742, 53743, 53744, 80497, 80498, 80499, 80500, 80501, 80527, 80528, 80529, 80530, 80531, 80629, 80630, 80631, 80632, 80633, 61644, 61645, 61641, 61642, 61662, 61663, 61683, 61684, 58002, 58003, 58004, 57934, 57935, 57936, 58155, 58156, 58157, 58158, 57876, 57877, 57878, 113335, 113336, 113337, 120404, 120378, 120403, 128319, 128320, 128383, 53996, 53997, 53998, 113045, 113267, 113269, 113135, 120376, 120371, 120366, 128351, 128352, 128378, 128357, 128358, 128335, 128336, 128373, 128349, 128350, 128345, 128355, 128356, 128359, 128360, 54012, 54013, 54014, 113187, 113188, 113189, 134919, 134924, 134941, 134928, 134931, 134948, 134983, 134972, 134960, 134977, 135019, 135034, 135029, 135002, 135781, 135730, 135731, 135732, 135802, 135697, 135739, 135850, 135862, 135851, 135828, 135849, 135836, 135865, 135843, 135819, 54036, 54037, 54038, 108965, 61618, 56833, 56834, 56773, 56774, 56866, 58105, 58106, 58107, 56867, 113003, 113002, 113298, 114032, 114066, 114053, 114022, 128365, 128366, 128361, 128362, 128368, 128374, 128372, 128325, 128326, 128321, 128322, 128387, 135071, 135048, 135072, 135090, 135108, 135097, 135120, 135123, 135964, 135962, 135951, 135972, 135952, 135956, 136026, 136008, 135980, 136090, 136075, 136046, 54060, 54061, 54062, 54320, 54321, 65288, 65289, 65290, 65291, 65292, 65324, 65325, 65326, 65327, 65328, 97847, 80341, 80342, 80343, 80344, 80345, 80593, 80594, 80595, 80596, 80597, 61533, 61534, 65264, 65265, 65266, 65267, 65268, 57840, 57841, 57842, 113040, 113263, 113264, 113265, 113278, 113090, 114025, 114061, 114036, 114050, 114069, 114034, 128347, 128348, 128331, 128332, 128342, 134951, 134944, 134964, 134990, 134974, 134987, 135012, 135032, 135023, 135014, 135003, 135751, 135763, 135790, 135829, 135824, 135928, 135933, 135911, 135889, 135891, 135892, 128546, 128497, 128498, 128522, 128549, 128493, 128494, 128542, 128489, 128490, 128553, 128554, 128491, 128492, 128501, 128502, 128495, 128496, 128477, 128478, 128511, 128512, 128518, 128521, 128532, 128520, 128533, 128536, 128524, 128531, 128534, 128555, 128538, 128556, 128543, 128544, 128541, 128540, 128547, 128552, 128548, 120355, 120375, 137810, 137811, 137804, 137864, 137867, 137868, 137899, 137902, 137903, 137834, 137837, 137838, 137764, 137889, 138026, 138027, 138028, 138029, 138078, 139651, 139645, 54096, 54097, 54098, 53766, 53767, 53768, 53534, 53535, 53536, 66074, 66075, 66076, 66077, 66078, 108938, 80695, 80696, 80697, 113130, 113133, 113134, 113282, 114054, 114029, 114068, 114059, 114040, 114038, 114055, 114060, 114067, 120380, 120251, 120240, 120243, 120144, 120142, 120154, 128327, 128328, 128396, 61623, 61624, 54032, 54033, 54034, 54076, 54077, 54078, 52958, 52959, 62635, 62636, 62637, 62638, 62639, 80715, 80716, 80717, 61500, 61501, 61527, 61528, 61650, 61651, 56869, 56870, 56746, 56747, 58130, 58131, 58132, 58133, 113001, 113085, 113086, 113087, 113227, 113228, 113229, 113183, 113184, 113185, 113211, 113212, 113213, 113070, 113071, 113072, 113167, 113168, 113169, 113223, 97926, 97919, 97829, 100655, 114047, 114046, 114027, 113224, 113225, 100658, 100660, 100663, 100667, 99003, 99004, 99005, 99006, 99007, 120412, 120367, 120365, 128367, 128317, 128318, 128329, 128330, 128343, 128333, 128334, 128380, 128388, 134949, 128513, 128514, 128505, 128506, 128515, 128516, 134937, 134971, 134969, 134999, 135004, 135024, 135805, 135806, 135807, 135706, 135703, 120381, 120364, 120368, 120408, 137937, 108922, 112921, 112922, 112923, 112924, 113009, 113219, 113220, 113221, 113339, 113340, 113315, 113317, 51013, 51014, 51015, 57820, 57821, 57822, 113060, 113061, 113062, 113306, 114048, 114042, 114057, 114044, 66110, 66111, 66112, 66113, 66114, 112973, 112974, 112975, 113175, 113177, 113138, 113139, 113251, 113252, 113253, 65996, 80823, 61593, 113047, 112951, 112952, 112953, 112954, 113006, 113341, 113065, 113066, 113067, 80509, 80510, 80511, 80512, 80513, 61692, 61693, 61545, 61546, 61461, 61462, 61608, 61609, 56857, 56858, 113007, 112977, 112978, 112979, 112965, 112966, 112967, 113041, 113095, 113096, 113097, 113105, 113108, 113109, 113159, 113160, 113161, 113247, 113248, 113249, 113302, 114064, 114071, 119335, 119336, 119337, 135038, 135046, 135054, 135049, 135110, 135103, 135135, 135161, 135122, 135121, 135939, 135953, 135965, 135991, 137829, 138062, 135989, 136025, 135993, 135981, 136011, 135977, 135978, 136006, 136073, 136067, 136058, 136057, 136069, 136071, 139646, 139655, 139336, 139316, 139290, 139414, 139408, 139431, 139428, 128376, 53984, 53985, 53986, 66122, 66123, 66124, 66125, 66126, 62563, 62565, 62567, 62570, 62572, 80867, 80868, 80869, 80587, 80588, 80589, 80590, 80591, 80503, 80504, 80505, 80506, 80507, 80467, 80468, 80469, 80470, 80471, 80455, 80456, 80457, 80458, 80459, 61632, 61633, 61611, 61612, 66002, 66003, 66004, 66005, 66006, 66104, 66105, 66106, 66107, 66108, 65306, 65307, 65308, 65309, 65310, 56887, 56888, 112913, 113152, 97882, 97929, 97879, 61581, 61582, 61665, 61666, 61470, 61471, 97807, 56848, 113048, 113270, 113327, 113328, 113329, 113286, 113145, 114063, 114043, 114065, 114031, 101000, 101001, 101003, 101004, 101005, 134942, 134933, 134917, 134963, 134957, 134959, 135008, 135026, 135018, 135020, 135712, 135754, 135755, 135756, 135787, 135870, 135818, 135835, 135842, 135814, 135853, 135867, 135866, 135907, 135922, 120382, 120379, 137961, 137951, 138120, 139265, 139266, 139170, 139171, 139172, 139173, 139174, 128528, 139393, 139389, 139349, 139395, 139376, 139343, 139175, 139176, 139279, 128545, 135826, 135868, 135852, 135856, 135813, 135812, 135821, 135825, 108904, 56821, 108899, 109015, 109006, 108998, 56822, 56755, 56756, 56842, 56843, 134922, 113343, 113344, 113345, 113151, 113153, 113055, 113056, 113057, 113331, 113332, 113333, 114070, 114024, 120249, 120253, 120255, 120256, 120374, 137947, 137956, 137941, 137959, 137965, 137953, 166478, 166500, 137784, 137785, 137786, 53722, 53723, 53724, 54272, 54273, 80671, 80672, 80673, 80835, 80836, 80837, 80413, 80414, 80415, 80416, 80417, 80581, 80582, 80583, 80584, 80585, 80365, 80366, 80367, 80368, 80369, 80407, 80408, 80409, 80410, 80411, 80569, 80570, 80571, 80572, 80573, 80443, 80444, 80445, 80446, 80447, 80521, 80522, 80523, 80524, 80525, 80371, 80372, 80373, 80374, 80375, 61518, 61519, 109010, 108932, 108979, 108946, 108989, 80329, 80330, 80331, 80332, 80333, 80359, 80360, 80361, 80362, 80363, 61590, 61591, 56791, 56792, 57990, 57991, 57992, 113294, 113295, 113296, 113297, 113319, 113320, 113321, 114051, 114035, 134923, 134939, 134930, 134973, 134989, 135022, 135009, 135028, 135694, 135700, 135815, 135887, 120369, 137957, 138110, 138113, 138114, 138112, 139221, 139222, 139223, 139224, 139278, 139277, 139274, 139346, 139388, 139377, 139378, 128509, 128510, 128551, 128535, 128487, 128488, 128483, 128484, 128479, 128480, 128485, 128486, 128481, 128482, 128499, 128500, 128523, 61536, 61537, 61653, 61654, 61452, 61453, 61449, 61450, 53662, 53663, 53664, 62629, 62630, 62631, 62632, 62633, 65990, 65991, 65992, 65993, 65994, 62713, 62714, 62715, 62716, 62717, 52916, 52917, 52892, 52893, 80723, 80724, 80725, 113000, 113303, 113304, 113305, 113243, 113244, 113245, 113347, 113349, 113115, 113118, 113119, 113080, 57752, 57753, 57754, 128384, 128391, 128394, 128392, 135057, 135052, 135070, 135094, 135091, 135174, 135125, 135117, 135157, 135992, 135986, 135975, 135996, 136032, 136007, 136000, 136005, 136077, 136039, 136050, 136064, 136059, 119327, 119328, 119329, 137769, 137770, 137771, 137849, 137874, 137839, 138011, 138012, 138013, 138046, 139649, 139656, 139437, 139405, 139427, 65294, 65295, 65296, 65297, 65298, 113171, 113172, 113173, 113259, 113261, 120360, 128382, 128375, 128390, 128353, 128354, 53738, 53739, 53740, 53582, 53583, 53584, 53570, 53571, 53572, 53710, 53711, 53712, 54506, 54507, 120252, 53714, 53715, 53716, 53598, 53599, 53600, 80241, 81211, 81212, 113008, 113271, 113272, 113273, 53650, 53651, 53652, 108971, 80811, 80812, 80813, 80787, 80788, 80789, 80719, 80720, 80721, 80875, 80876, 80877, 61530, 61531, 120245, 120250, 108898, 108950, 109004, 108959, 113311, 113312, 113313, 120140, 120137, 120136, 120197, 120198, 120199, 120205, 120206, 120207, 120173, 120174, 120175, 120148, 108956, 108917, 109012, 109007, 108925, 108961, 108953, 113316, 113091, 113092, 113195, 113196, 113197, 113075, 113076, 113077, 113050, 113051, 113052, 114023, 80743, 80744, 80745, 61521, 61522, 120147, 120152, 120143, 79369, 79370, 113005, 113274, 113275, 113276, 113277, 113081, 113082, 120238, 120239, 113191, 113192, 113193, 113287, 113288, 113289, 79375, 79376, 120242, 120254, 53758, 53759, 53760, 79834, 53706, 53707, 53708, 108968, 108947, 62539, 62540, 62541, 62542, 62543, 80891, 80892, 80893, 80883, 80884, 80885, 80731, 80732, 80733, 80851, 80852, 80853, 80819, 80820, 80821, 80431, 80432, 80433, 80434, 80435, 113290, 113291, 113292, 113293, 113231, 113233, 80619, 80425, 80426, 80427, 80428, 80429, 80347, 80348, 80349, 80350, 80351, 108943, 108929, 80437, 80438, 80439, 80440, 80441, 120138, 120213, 120214, 120215, 120151, 120201, 120202, 120203, 120150, 120246, 120248, 120247, 120244, 120356, 120409, 120357, 137948, 137964, 137950, 138121, 138117, 138119, 139267, 139181, 139182, 139183, 139386, 139392, 139404, 139184, 139229, 139230, 139231, 139232, 166489, 166494, 166501, 166475, 166473, 166481, 166469, 166498, 166472, 166496, 166529, 166499, 166459, 166503, 166470, 166457, 166485, 166477, 166460, 166461, 166467, 166490, 166528, 166535, 166515, 166520, 166542, 166514, 166603, 166562, 166556, 166597, 166568, 166567, 166557, 166566, 166589, 166558, 166600, 166583, 166572, 166599, 166582, 166581, 166598, 166577, 166578, 166594, 166584, 166569, 166571, 166579, 166586, 166596, 166601, 166561, 166565, 166575, 167397, 167413, 167465, 167474, 167470, 167414, 167457, 167461, 167539, 167528, 167525, 167520, 167550, 167536, 167571, 167551, 167540, 167503, 167492, 167575, 167480, 167542, 167570, 137854, 137857, 137858, 137814, 137859, 137819, 138074, 138054, 138034, 138070, 139226, 139227, 139228, 79357, 79358, 81170, 81171, 80193, 80194, 80195, 53754, 53755, 53756, 109001, 62623, 62624, 62625, 62626, 62627, 80389, 80390, 80391, 80392, 80393, 61659, 61660, 120145, 114033, 54491, 54492, 53678, 53679, 53680, 80205, 80206, 80207, 80269, 54515, 54516, 80859, 80860, 80861, 61629, 61630, 61549, 61599, 61600, 61563, 61564, 112936, 112937, 112938, 112939, 112989, 112990, 112991, 113283, 113284, 113285, 97867, 120146, 120149, 120233, 120234, 120235, 112926, 112927, 112928, 112929, 108926, 108940, 108905, 53602, 53603, 53604, 113203, 113204, 113205, 113140, 113143, 113144, 113179, 113180, 113181, 120153, 79573, 79574, 81127, 81128, 81136, 81137, 80245, 114052, 114062, 108907, 108958, 80335, 80336, 80337, 80338, 80339, 61686, 120139, 120157, 120158, 120159, 120155, 53646, 53647, 53648, 53690, 53691, 53692, 79564, 79565, 79930, 79931, 81142, 81143, 80161, 80162, 80163, 80257, 80258, 80259, 53746, 53747, 53748, 53638, 53639, 53640, 81184, 81185, 81196, 81197, 53718, 53719, 53720, 53682, 53683, 53684, 53578, 53579, 53580, 108997, 62509, 62510, 62511, 62512, 62513, 53554, 53555, 53556, 53694, 53695, 53696, 108919, 80899, 80900, 80901, 80419, 80420, 80421, 80422, 80423, 80485, 80486, 80487, 80488, 80489, 61687, 61554, 61555, 80071, 80072, 80533, 80534, 80535, 80536, 80537, 80557, 80558, 80559, 80560, 80561, 79363, 79364, 79579, 79580, 80277, 80278, 80279, 80229, 80230, 80231, 80181, 80182, 80183, 81199, 81200, 108913, 54209, 54210, 80739, 80740, 80741, 61674, 61675, 113199, 113200, 113201, 113176, 113207, 113208, 113209, 113307, 113308, 113309, 139652, 139302, 139314, 166354, 166340, 167627, 167660, 167631, 167601, 167579, 113125, 113128, 113129, 120241, 120362, 120361, 53658, 53659, 53660, 53618, 53619, 53620, 81202, 81203, 81155, 81156, 79927, 79928, 108920, 54335, 54336, 80791, 80792, 80793, 98970, 98971, 98972, 98973, 98974, 114045, 120407, 120358, 137944, 137962, 137949, 138111, 166462, 166482, 166493, 166484, 166492, 166458, 166537, 166523, 166510, 166563, 79570, 79571, 79561, 79562, 79576, 79577, 81133, 81134, 79849, 79850, 79921, 79922, 81139, 81140, 81164, 81165, 80185, 80186, 80187, 108934, 66146, 66148, 80575, 80576, 80577, 80578, 80579, 113235, 113236, 113237, 114056, 114030, 114058, 97913, 98948, 98949, 98950, 98951, 98952, 101792, 101793, 101795, 101797, 101798, 99026, 109013, 99027, 99028, 99029, 99031, 108935, 120354, 137963, 138124, 138115, 137939, 137952, 137960, 137954, 137938, 120411, 120373, 139218, 139219, 139220, 139350, 139351, 166491, 166488, 166513, 166517, 166522, 166539, 166590, 166574, 167429, 167448, 167459, 167428, 167444, 167411, 167404, 167501, 167489, 167554, 167530, 167477, 167487, 167481, 128527, 128507, 128508, 137820, 138023, 138024, 138025, 138050, 138042, 138066, 137821, 137759, 137794, 166328, 166319, 166350, 166343, 166342, 166345, 166316, 166336, 166317, 166361, 166358, 166365, 166394, 166398, 166445, 166435, 166412, 167432, 167473, 79942, 79943, 80169, 80170, 80171, 108977, 80707, 80708, 80709, 80653, 80654, 80655, 80656, 80657, 80545, 80546, 80547, 80548, 80549, 113323, 113324, 113325, 113110, 113113, 113114, 113215, 113216, 113217, 137946, 137955, 137942, 137945, 167514, 167521, 167522, 167568, 167516, 167453, 167401, 167420, 167471, 167455, 167472, 167406, 167430, 80201, 80202, 80203, 81187, 81188, 81205, 81206, 54476, 54477, 113232, 101745, 101747, 101749, 101752, 101755, 99311, 99312, 99314, 99319, 99321, 99361, 99362, 99363, 99364, 99365, 120237, 114039, 137805, 137806, 137824, 139643, 139644, 139647, 166356, 166446, 167623, 167611, 167662, 139439, 139406, 139407, 108931, 109016, 108908, 120353, 120370, 137958, 137936, 137943, 166455, 166521, 166525, 166538, 166516, 166511, 166533, 166573, 166544, 166518, 166592, 166591, 166564, 166587, 166560, 166576, 166580, 166604, 167452, 167399, 167426, 167405, 167479, 167495, 167491, 167567, 167506, 167566, 167553, 167561, 128529, 128530, 138116, 138118, 108976, 109009, 108994, 108941, 108962, 108988, 108964, 108914, 108985, 108937, 108923, 108910, 166463, 166476, 120141, 166349, 166351, 166339, 166338, 166353, 166335, 166329, 166322, 166321, 166324, 166391, 166362, 166364, 166379, 166439, 166431, 166448, 166330, 166428, 166416, 166443, 166433, 166450, 166411, 166414, 166425, 166440, 167653, 167629, 167642, 167591, 167599, 167649, 167610, 167628, 167651, 167675, 167727, 167734, 167725, 167685, 167669, 167780, 167757, 167762, 167813, 167804, 167810, 167775, 167822, 167753, 167836, 137799, 137800, 137801, 137830, 137831, 166331, 166323, 166326, 166370, 166363, 166403, 166378, 166372, 166438, 166415, 166426, 166430, 166441, 166422, 166413, 167445, 167418, 167435, 167557, 167548, 167534, 167556, 167485, 167552, 167493, 139178, 139179, 139180, 54064, 54065, 54066, 137894, 167639, 167592, 167596, 167588, 167582, 167590, 108967, 120406, 138122, 139347, 139348, 139344, 139345, 166483, 166464, 166474, 166466, 166487, 166471, 166502, 166524, 166526, 166585, 166495, 166486, 166602, 167512, 166559, 166570, 166588, 167572, 167484, 167532, 167537, 167541, 167497, 167510, 167499, 167515, 167546, 166595, 128539, 128525, 137842, 120181, 120182, 120183, 167580, 167586, 167655, 167654, 167598, 167622, 167659, 137795, 137796, 137774, 139433, 139438, 166348, 166369, 166368, 166359, 166396, 166420, 166409, 166449, 167578, 167587, 167646, 167637, 167597, 167595, 167593, 167594, 167644, 167684, 167739, 167674, 167730, 167692, 167699, 167745, 167830, 167777, 167747, 167793, 167779, 167784, 167756, 167819, 167808, 167608, 167635, 167624, 167833, 167801, 167761, 167786, 167811, 167752, 137780, 137781, 137979, 137980, 137981, 137971, 137972, 137973, 138038, 138039, 138040, 138041, 138079, 138080, 138081, 166320, 166357, 166421, 166334, 166352, 166377, 166344, 166337, 166395, 166355, 166374, 166429, 166419, 166410, 166408, 166423, 166407, 166436, 166451, 166447, 167723, 167726, 167683, 167741, 167688, 167717, 167691, 167705, 167788, 167783, 167759, 167764, 167838, 167768, 166434, 167845, 167800, 167824, 167751, 167755, 167749, 167821, 167664, 167617, 137862, 137863, 138051, 138052, 138053, 167438, 167408, 167410, 167440, 167451, 167443, 166325, 166318, 166327, 167531, 167508, 167535, 167574, 167524, 167486, 137847, 137848, 137843, 137904, 166375, 166376, 166399, 167416, 167449, 167403, 167427, 167496, 167488, 167513, 119351, 119352, 119353, 119331, 119332, 119333, 137892, 137893, 166404, 166366, 166400, 166424, 166405, 166417, 167626, 167657, 167583, 167603, 167716, 167678, 167712, 167695, 167689, 167690, 167715, 167754, 167814, 167795, 167769, 167794, 167785, 167802, 167606, 167609, 167645, 167630, 167638, 167658, 167585, 167806, 167789, 167778, 167834, 167750, 167614, 167661, 167581, 167605, 167650, 167619, 167787, 167815, 167809, 167796, 167763, 137940, 108901, 120359, 166504, 166505, 166530, 138075, 138076, 138077, 138030, 166346, 166341, 166367, 167604, 167621, 167589, 167576, 119355, 119356, 119357, 166401, 166432, 166453, 166427, 167600, 137760, 137761, 137897, 137898, 137775, 137776, 137882, 137883, 137987, 137988, 137989, 138082, 166373, 166442, 166444, 166406, 166418, 167549, 167490, 167454, 167462, 167436, 167464, 120377, 138123, 120363, 120372, 166468, 166507, 166593, 167417, 167425, 167475, 167469, 167409, 167560, 167518, 167526, 167509, 167505, 167569, 167529, 167442, 128503, 128504, 128550, 128526, 108928, 108955, 166497, 166532, 166555, 167467, 167441, 167523, 167562, 167511, 128519, 128517, 138067, 138068, 138069, 138043, 138044, 138045, 138058, 166347, 166315, 166390, 166392, 166452, 167437, 166536, 137815, 137816, 137877, 137878, 137765, 137766, 166371, 167415, 167396, 167402, 167533, 167547, 54024, 54025, 54026, 54020, 54021, 54022, 167634, 167648, 167743, 167722, 167687, 167670, 167719, 167731, 167718, 167812, 167766, 167827, 167791, 167760, 167607, 167625, 120405, 166508, 166506, 166527, 166541, 166512, 167412, 167538, 167555, 166360, 167424, 167500, 167502, 138019, 138020, 138021, 166333, 166397, 167577, 166437, 128344, 166393, 166479, 166509, 120225, 120226, 120227, 137887, 137888, 167545, 167543, 108949, 166465, 166543, 120165, 120166, 120167, 138063, 138064, 138065, 138015, 138016, 138017, 166454, 167666, 167682, 167707, 167767, 167805, 167798, 167776, 167613, 120189, 120190, 120191, 120221, 120222, 120223, 167665, 137995, 137996, 137997, 167656, 167663, 167742, 167704, 167744, 167686, 167676, 167698, 167774, 167844, 167799, 137852, 137853, 167703, 167733, 167667, 167765, 167816, 167829, 167832, 167640, 167620, 167652, 167835, 167807, 54000, 54001, 54002, 120169, 120170, 120171, 85317, 85318, 85355, 85356, 85357, 85463, 85464, 85465, 85275, 85276, 85367, 85368, 85369, 85314, 85315, 85479, 85480, 85481, 84802, 84803, 84804, 84759, 84760, 85379, 85380, 85381, 85519, 85520, 85521, 92321, 92335, 92329, 92344, 92336, 92342, 92341, 92330, 85885, 85801, 85848, 85814, 85866, 85859, 85798, 85796, 85938, 85953, 85975, 85964, 85955, 85968, 86061, 85904, 85906, 85939, 86052, 86062, 86077, 86046, 85959, 85901, 85940, 85894, 85962, 85870, 85889, 85857, 85804, 85972, 85932, 86067, 85974, 85898, 86079, 86045, 86049, 86048, 86066, 85831, 85876, 85799, 85819, 85895, 85934, 86065, 86068, 85958, 85933, 85926, 85965, 85961, 85942, 86080, 85971, 85956, 86072, 86076, 85875, 85881, 85803, 85832, 85841, 85815, 85805, 85807, 85821, 85842, 85863, 85887, 85835, 85837, 85943, 85893, 85878, 85847, 85865, 85849, 85830, 85838, 85879, 85871, 85844, 85810, 85952, 85909, 85948, 85908, 85951, 85900, 86051, 86075, 86073, 86078, 85886, 85899, 85966, 86050, 86074, 85950, 86047, 85973, 85969, 86064, 85941, 85910, 85854, 86069, 85840, 85829, 85902, 85925, 85927, 85896, 86054, 85892, 86063, 85954, 85960, 85947, 85946, 85936, 85929, 85802, 85868, 85795, 85860, 52906, 52829, 52822, 52835, 66343, 66449, 66438, 66477, 66494, 66336, 66424, 66478, 66437, 66488, 66412, 66528, 66451, 66390, 66440, 66439, 66407, 66472, 85702, 85715, 85696, 85747, 85695, 52846, 53020, 52972, 52981, 52827, 52842, 52815, 85731, 85750, 85729, 85727, 85704, 85733, 66335, 66556, 52841, 52936, 52836, 52855, 52816, 85701, 85738, 52930, 52978, 52837, 52813, 66354, 66410, 66536, 66375, 85717, 85699, 85744, 85694, 85712, 85703, 85709, 85700, 66542, 66377, 66473, 66507, 66364, 66368, 66387, 66514, 85693, 85726, 85734, 85725, 85723, 52843, 52903, 52924, 52825, 53014, 52885, 85692, 85728, 66393, 66385, 66523, 66533, 66484, 66532, 66487, 66564, 52912, 53017, 52990, 52840, 53002, 52987, 52900, 52864, 85714, 85698, 66418, 66518, 66381, 52817, 52867, 85697, 85742, 52939, 52921, 85711, 85706, 66553, 66493, 66328, 66374, 66497, 66492, 66452, 66347, 66443, 85710, 85749, 85720, 85705, 85735, 85708, 85748, 52879, 85716, 85730, 85740, 85707, 52963, 52838, 52821, 52984, 85736, 85713, 66333, 66490, 66483, 66411, 66359, 66421, 66416, 66388, 66423, 85722, 85719, 85751, 85741, 52814, 52870, 52894, 66430, 66471, 66432, 66396, 66474, 66346, 66434, 66498, 66468, 66455, 66545, 66548, 52951, 52819, 52918, 66461, 66537, 66551, 66403, 66525, 52876, 52909, 52818, 85739, 66509, 85718, 66366, 66562, 66389, 52933, 52832, 85691, 52852, 66379, 66534, 66485, 66530, 66464, 66441, 52888, 66506, 66334, 66341, 85724, 85745, 85746, 53008, 52897, 66369, 66466, 52849, 52969, 66546, 66448, 66406, 66370, 52831, 85732, 66245, 66241, 66304, 65661, 65862, 66321, 66251, 66212, 66248, 66214, 66195, 66224, 65665, 65817, 66278, 65765, 65713, 66266, 65701, 66205, 66249, 66222, 66206, 66209, 66203, 66283, 65777, 66242, 66226, 65729, 65717, 66285, 65837, 65872, 66277, 65697, 66194, 66257, 65733, 66323, 66221, 65813, 66293, 65721, 66199, 66219, 66185, 65861, 65769, 66318, 65669, 66237, 65773, 65653, 65873, 66198, 65617, 66176, 66244, 66300, 66279, 66286, 66197, 66292, 65801, 66210, 65809, 66254, 66306, 66187, 66303, 66261, 66296, 66215, 97812, 65599, 66175, 66308, 65805, 65633, 66295, 65761, 66253, 65737, 66275, 66180, 66243, 66240, 66250, 65693, 66262, 66316, 65613, 65868, 65821, 97872, 66287, 66297, 66193, 66291, 65649, 66234, 66289, 66252, 66272, 66238, 65757, 65841, 66231, 66228, 66259, 65749, 66188, 66178, 65705, 66202, 66299, 65845, 65789, 66269, 65863, 66190, 65753, 66235, 65870, 65865, 65625, 65866, 66267, 66223, 66322, 65673, 66281, 65797, 66182, 66227, 66310, 66274, 66298, 66183, 66179, 66204, 66186, 66218, 66229, 66264, 66184, 66311, 65689, 65781, 65858, 66213, 66192, 65629, 66200, 66280, 66312, 66305, 65745, 65825, 53318, 53313, 53281, 53297, 53284, 53316, 53309, 53321, 66651, 66695, 66692, 66575, 66681, 66629, 66708, 66713, 66657, 66621, 53307, 53264, 53319, 53334, 53343, 53308, 53275, 53306, 53336, 66672, 66683, 66609, 66622, 66614, 66574, 53288, 66616, 66606, 66686, 66603, 66709, 66710, 66693, 53330, 53314, 53347, 66660, 66663, 66711, 66655, 66715, 66597, 66595, 66662, 66691, 66612, 66619, 66604, 53269, 53352, 53350, 53289, 66581, 66667, 66659, 53300, 53272, 53292, 66702, 66678, 66570, 53339, 53263, 53304, 53322, 66656, 66583, 66618, 66610, 53312, 53282, 53302, 53323, 66576, 66626, 66589, 66654, 53296, 53327, 66615, 66644, 66647, 53274, 53270, 53337, 66679, 66673, 53311, 66685, 66608, 53340, 66630, 66668, 66675, 66700, 53324, 53320, 66688, 66611, 53332, 53351, 66701, 66642, 66613, 53328, 53333, 66634, 53265, 53299, 66714, 66572, 53310, 53317, 53331, 66671, 53298, 53301, 66704, 66706, 66664, 66653, 66625, 66602, 66707, 66587, 66607, 66568, 53315, 53283, 66689, 66705, 66594, 66573, 66636, 53277, 53295, 53268, 66598, 66620, 66596, 66567, 66690, 66641, 53266, 66599, 53285, 66649, 66569, 53348, 66624, 53273, 53293, 53345, 53326, 66666, 66698, 66590, 53271, 66645, 53338, 66648, 66579, 66643, 66571, 66637, 66623, 66680, 66638, 66605, 66677, 66577, 66640, 66582, 66699, 53342, 66601, 66646, 66593, 66631, 53278, 66592, 66585, 66674, 66661, 53280, 53325, 53303, 66578, 66639, 66687, 66584, 66586, 66633, 66696, 66712, 66703, 66580, 88406, 87027, 87126, 87121, 87107, 87092, 87111, 8462, 87048, 87038, 87041, 87063, 87077, 87057, 87110, 86235, 86149, 86142, 86158, 86166, 86152, 86232, 86144, 86146, 86167, 86140, 86164, 86163, 86157, 86170, 86160, 86138, 86219, 86197, 86228, 86199, 86218, 86192, 86210, 86217, 86215, 86202, 86139, 86141, 86154, 86143, 86162, 86147, 86172, 86153, 86206, 86198, 86225, 86223, 86201, 86187, 86151, 86233, 86156, 86165, 86168, 86196, 86231, 86190, 86234, 86203, 86195, 86216, 86226, 86213, 86145, 86137, 86200, 86150, 86208, 86159, 86155, 86171, 86173, 86193, 86207, 86236, 86209, 86211, 86220, 86222, 86221, 86148, 86169, 86161, 86188, 86191, 86189, 86212, 86205, 86214, 86227, 86224, 86204, 86194, 86229, 86230, 54118, 86850, 86846, 54155, 54133, 54140, 86862, 86839, 54108, 54143, 86791, 54154, 54124, 54149, 54104, 54119, 54153, 86854, 54159, 54112, 86776, 86781, 86861, 54152, 54157, 86780, 86878, 54141, 54128, 54116, 86788, 86859, 54129, 54110, 86858, 54162, 54156, 54123, 71367, 71364, 71348, 94884, 94870, 94893, 71366, 94901, 94883, 60143, 60087, 60122, 60074, 108981, 85013, 85243, 85248, 85247, 84671, 84667, 91671, 85249, 85049, 85218, 84664, 85052, 87557, 87446, 87465, 87518, 87434, 87566, 87432, 87548, 87519, 87443, 87552, 87447, 87532, 87546, 87554, 87600, 87541, 87535, 87517, 87450, 87586, 87440, 87462, 87533, 87540, 87515, 87426, 87448, 87593, 87512, 87433, 87469, 87560, 87539, 87453, 87591, 87460, 87466, 87444, 87428, 87582, 87570, 87564, 87430, 87467, 87435, 87597, 87459, 87521, 87562, 87431, 87544, 87424, 87592, 87470, 87520, 87588, 87595, 87423, 87563, 87456, 87568, 87449, 87587, 87468, 87516, 87445, 87550, 87461, 87441, 87567, 87590, 87442, 87427, 87463, 87571, 87585, 87559, 87437, 87596, 87422, 87561, 87513, 87598, 87436, 87569, 87455, 87458, 87452, 87536, 87589, 87429, 87438, 87538, 87514, 87594, 87565, 87584, 87471, 87537, 87601, 87425, 87464, 87451, 87599, 87439, 88086, 90662, 90701, 90692, 90702, 90659, 88616, 88622, 88501, 88597, 88518, 88621, 88602, 88532, 88539, 88605, 88591, 88525, 88519, 88516, 88619, 88498, 88627, 88613, 88590, 88502, 88549, 88536, 88548, 89670, 89754, 84907, 89823, 89965, 89923, 89968, 89829, 89896, 89960, 89939, 89884, 89893, 53871, 53870, 53894, 53836, 53881, 53968, 53964, 53910, 53953, 53895, 53848, 53935, 84899, 89667, 84898, 89713, 89750, 89718, 84895, 89710, 89755, 89704, 84896, 84901, 89720, 89714, 84897, 89662, 89747, 89827, 89921, 89902, 89950, 89859, 89863, 89934, 89866, 89919, 53874, 53929, 53833, 53969, 53936, 53867, 89706, 84905, 89738, 89759, 89726, 84904, 89757, 89740, 89722, 89745, 89735, 89701, 84893, 89858, 89959, 89857, 89922, 89954, 89924, 89729, 84903, 89727, 89947, 89899, 89851, 89911, 89865, 89920, 89935, 53976, 53928, 89944, 89885, 89719, 84890, 89746, 89741, 89749, 89668, 89732, 89914, 89669, 84892, 89731, 89895, 89852, 89868, 89927, 89967, 84902, 89665, 53864, 53957, 53840, 53923, 53868, 89739, 89709, 89758, 89721, 89748, 89723, 89962, 89928, 89948, 89854, 89953, 89661, 89881, 89969, 89882, 89943, 89743, 89933, 89912, 89890, 89856, 89744, 89733, 89753, 89937, 89958, 89830, 89964, 89951, 89712, 89734, 89862, 89961, 89897, 89903, 89828, 53905, 53938, 53930, 53975, 89870, 89825, 89955, 89909, 89970, 89930, 53839, 53955, 53849, 53941, 89826, 89730, 89918, 89915, 89966, 89916, 53908, 53932, 89708, 89728, 89931, 89664, 89942, 89941, 89907, 89905, 89760, 89888, 89891, 89926, 53876, 89860, 89855, 89824, 89887, 89883, 89898, 53942, 53842, 53852, 53956, 53926, 53902, 53896, 53959, 53851, 53844, 89957, 89956, 53846, 53934, 53847, 89913, 89900, 89910, 53937, 89952, 89901, 89869, 89822, 89908, 89936, 53869, 89886, 89861, 89889, 89892, 89864, 89705, 53961, 53912, 53939, 53924, 89894, 89963, 89938, 89940, 89904, 89821, 53882, 89737, 89853, 89925, 53954, 53879, 89929, 53873, 89949, 53933, 53904, 89917, 89945, 53835, 53834, 89867, 89906, 89932, 53872, 53903, 53877, 53909, 53838, 53958, 54007, 54051, 54079, 54274, 90651, 90335, 90495, 90377, 54394, 54373, 54190, 54418, 54220, 54331, 54238, 90437, 90326, 90543, 90473, 90512, 90368, 90365, 90416, 90452, 90600, 90329, 54307, 54298, 90658, 90332, 90338, 90639, 90698, 90654, 90645, 54400, 54286, 54367, 54376, 90521, 90540, 90350, 90712, 90344, 54391, 54325, 54280, 54172, 54343, 54214, 54178, 90534, 90404, 90320, 90642, 90455, 90572, 90440, 90353, 90314, 90648, 90581, 90709, 90428, 90591, 90524, 54163, 90489, 90688, 90401, 90398, 90389, 90603, 54301, 54361, 54328, 90356, 90633, 90410, 90693, 54316, 90479, 90392, 54403, 54337, 90518, 54181, 90383, 90537, 90374, 54415, 54229, 90323, 90501, 90458, 90422, 90597, 90431, 90636, 54322, 54184, 54355, 90483, 54241, 54244, 54379, 54256, 54226, 90578, 90419, 90486, 54166, 54340, 54187, 90446, 90449, 90425, 54253, 90341, 54364, 90594, 90317, 90531, 54346, 90407, 90706, 90718, 90715, 86343, 86509, 86323, 86325, 86316, 86354, 86348, 86450, 86353, 58810, 86319, 86446, 86324, 86534, 86442, 86350, 86553, 86753, 86602, 86668, 86646, 86624, 86533, 86557, 86344, 86511, 86349, 53773, 58825, 86766, 86736, 86738, 86671, 86757, 86355, 86454, 86529, 86357, 53798, 86650, 86733, 58799, 58824, 86322, 86358, 86549, 86555, 86537, 53787, 58798, 53793, 86352, 86318, 86556, 58817, 58802, 86345, 86552, 86519, 86448, 86539, 86315, 86531, 86530, 86541, 86517, 86542, 86580, 86607, 86731, 86669, 86758, 58811, 86649, 86755, 86551, 86521, 86327, 86332, 86346, 86329, 53780, 86604, 86726, 86665, 86724, 86735, 86313, 86328, 86532, 86356, 53781, 86747, 86740, 86742, 86647, 86444, 86545, 53796, 86576, 86762, 86660, 86347, 86440, 86320, 86523, 86642, 86314, 86456, 86622, 86628, 86630, 86536, 86341, 86538, 86625, 86643, 86664, 86515, 86547, 86581, 86606, 86609, 86574, 86342, 86573, 86572, 86626, 86317, 86631, 86770, 86361, 86749, 86331, 53800, 86722, 86737, 86743, 86575, 86765, 86732, 86763, 140086, 54413, 54414, 54072, 54073, 54074, 53992, 53993, 53994, 54068, 54069, 54070, 54088, 54089, 54090, 54008, 54009, 54010, 54191, 54192, 54332, 54333, 54314, 54315, 90438, 90439, 90499, 90500, 97793, 97903, 97791, 65666, 65667, 65668, 90327, 90328, 90453, 90454, 90601, 90602, 54263, 54264, 54398, 54399, 90640, 90641, 54359, 54360, 54401, 54402, 54287, 54288, 54052, 54053, 54054, 54048, 54049, 54050, 53988, 53989, 53990, 97775, 52847, 52848, 52976, 52977, 108944, 54028, 54029, 54030, 108902, 54040, 54041, 54042, 54044, 54045, 54046, 108952, 108983, 108916, 108970, 54392, 54393, 54221, 54222, 54281, 54282, 54269, 54270, 54016, 54017, 54018, 54080, 54081, 54082, 54092, 54093, 54094, 97777, 97795, 90417, 90418, 90535, 90536, 90405, 90406, 90321, 90322, 90351, 90352, 90643, 90644, 90456, 90457, 90441, 90442, 90381, 90382, 90592, 90593, 90526, 90528, 90330, 90331, 54084, 54085, 54086, 54056, 54057, 54058, 54004, 54005, 54006, 109003, 108974, 108911, 65786, 65787, 65788, 65734, 65735, 65736, 97839, 97911, 97806, 97907, 65670, 65671, 65672, 65774, 65775, 65776, 97887, 97918, 97833, 53018, 53019, 52991, 52992, 52988, 52989, 52874, 52875, 52949, 52950, 54293, 54294, 54206, 54207, 54100, 54101, 54102, 54407, 90354, 90355, 54408, 54431, 54323, 54324, 65766, 65767, 65768, 65810, 65811, 65812, 53021, 53022, 54248, 54249, 97855, 97898, 97786, 97923, 97894, 97865, 97799, 97814, 97915, 97857, 65806, 65807, 65808, 54224, 54225, 54404, 54405, 54380, 54381, 54257, 54258, 54194, 54195, 54302, 54303, 54308, 54309, 54260, 54261, 54386, 54387, 54383, 54384, 54203, 54204, 52952, 52953, 54419, 54420, 54311, 54312, 54290, 54291, 97797, 97889, 97825, 97837, 65678, 65679, 65680, 65706, 65707, 65708, 108991, 97811, 90652, 90653, 97891, 97866, 97782, 90487, 90488, 97854, 97823, 97794, 97779, 97781, 97925, 97873, 54251, 54252, 90393, 90394, 90595, 90596, 54317, 54318, 97843, 97875, 54170, 54171, 90459, 90460, 90324, 90325, 97877, 97773, 97849, 97818, 54179, 54180, 97930, 97851, 97895, 97870, 54305, 54306, 54197, 54198, 97902, 97802, 97831, 54389, 54390, 54227, 54228, 90372, 90373, 90522, 90523, 90390, 90391, 90318, 90319, 90429, 90430, 90369, 90370, 97890, 54326, 54327, 54173, 54174, 90357, 90358, 54236, 54237, 90582, 90583, 97853, 97859, 97830, 65690, 65691, 65692, 65746, 65747, 65748, 52937, 52938, 52886, 52887, 51437, 51470, 51427, 51419, 57716, 57701, 57662, 58569, 57707, 57686, 58542, 92326, 57692, 57689, 57683, 47046, 47078, 47044, 47141, 47069, 58548, 57680, 58554, 58536, 58551, 57644, 57704, 47132, 47051, 57665, 57671, 92323, 58527, 57677, 58590, 58521, 58512, 58533, 57719, 57668, 58593, 57713, 58530, 58539, 58557, 57695, 57647, 58560, 58596, 47056, 47040, 47067, 57641, 47129, 47049, 47099, 47060, 47084, 57725, 57653, 57698, 58572, 51388, 51342, 57133, 51335, 51353, 51358, 51375, 51378, 51374, 51384, 51325, 51377, 51355, 51332, 51334, 51312, 51343, 51386, 51344, 51354, 57132, 48830, 48824, 58199, 57823, 57981, 57887, 58094, 58229, 57779, 57929, 57985, 58164, 58179, 57731, 57961, 58184, 57795, 58045, 57771, 58073, 57945, 57891, 57957, 58114, 58239, 58119, 57867, 58109, 57735, 58081, 58214, 58009, 58025, 58041, 57913, 57921, 58077, 58209, 57743, 58174, 58099, 58089, 57767, 57747, 57787, 57883, 58061, 57763, 57863, 58149, 57807, 57953, 58219, 57965, 57791, 57917, 57827, 58169, 57993, 58234, 58189, 57969, 57937, 57907, 57783, 57941, 58194, 57759, 57903, 57799, 58005, 58029, 58224, 58017, 57843, 57899, 47836, 47804, 47824, 47788, 47784, 47792, 58462, 47856, 47828, 47816, 47860, 47832, 47896, 47872, 48118, 48066, 48170, 58487, 47800, 47812, 47868, 47892, 47864, 58432, 58412, 47844, 47876, 48114, 48158, 47900, 47796, 47880, 58447, 48070, 47888, 48122, 47848, 46821, 46860, 46866, 46863, 57461, 57485, 57542, 57503, 57632, 57536, 57521, 57563, 57539, 57572, 57620, 57626, 57599, 46800, 46809, 46812, 46797, 57500, 57524, 57482, 46869, 46875, 46842, 46830, 46833, 46803, 46857, 57515, 57545, 46839, 46845, 57638, 57587, 57497, 57548, 57494, 57491, 57467, 57533, 57509, 57512, 57551, 46872, 57488, 57470, 57518, 57593, 46848, 57590, 57617, 57635, 57605, 57464, 57602, 46851, 57614, 57473, 57608, 57557, 57560, 46836, 46854, 46794, 57506, 57527, 57623, 57554, 57530, 57581, 46806, 46881, 57566, 57629, 57479, 57476, 46878, 57578, 91519, 91520, 91512, 91084, 91064, 91072, 91063, 91058, 91517, 91065, 91062, 91075, 91059, 91068, 91056, 91071, 91113, 91153, 91115, 91537, 91099, 91118, 91534, 91535, 91131, 91094, 91089, 91129, 91128, 91143, 91098, 91145, 91141, 91132, 91151, 91139, 91087, 91124, 91104, 91101, 91086, 91112, 91120, 92374, 92380, 92375, 92390, 92364, 92360, 92391, 92377, 92359, 92367, 92386, 92395, 92382, 92385, 92384, 92369, 74482, 74420, 74527, 74542, 74452, 74477, 74517, 74457, 74462, 74532, 74428, 74512, 74507, 74432, 74467, 74412, 74424, 74416, 74502, 74492, 74472, 74562, 74561, 74557, 74574, 74554, 74558, 74581, 74570, 74566, 74578, 74552, 74575, 74560, 74577, 74580, 74576, 74567, 74404, 74403, 74407, 69214, 68586, 68818, 69006, 74821, 69038, 69070, 74881, 68570, 74789, 68814, 68950, 74817, 74829, 69122, 69130, 68582, 68798, 69218, 69022, 74877, 68862, 74809, 74801, 69146, 68918, 74797, 69094, 74845, 69182, 69050, 68626, 68926, 74853, 68786, 68858, 68902, 68610, 74885, 68822, 68874, 68898, 68650, 68630, 68618, 68974, 69010, 68954, 68986, 68810, 69186, 69026, 69154, 68930, 68602, 69206, 68882, 68958, 74785, 68838, 68566, 68878, 68578, 74893, 69054, 69098, 69110, 68638, 68622, 69118, 69058, 68938, 68834, 68554, 68982, 68538, 68546, 68806, 68558, 69142, 68802, 69166, 69086, 69106, 69126, 69198, 68854, 69222, 74837, 68542, 68543, 68594, 74781, 68634, 69162, 69250, 69246, 68886, 69150, 69018, 68850, 69194, 69078, 74889, 68962, 68870, 88954, 71787, 88960, 71784, 71774, 71785, 71780, 71768, 71772, 71795, 88946, 71789, 88951, 71767, 71776, 88956, 71777, 71783, 88957, 71794, 71778, 88945, 71701, 71651, 71683, 71698, 71722, 88866, 71680, 88869, 71647, 88918, 71694, 71717, 71689, 71728, 71695, 71704, 71673, 88885, 71690, 89029, 71681, 88867, 71685, 71662, 71710, 71724, 71675, 88899, 71686, 71640, 71655, 71725, 71668, 71682, 71672, 88877, 71693, 71696, 71674, 71718, 71707, 71705, 71700, 89022, 88876, 88907, 71645, 71714, 71692, 71653, 71671, 88911, 71656, 71664, 71713, 71660, 71676, 88879, 71697, 89025, 71659, 71684, 71712, 71666, 71648, 71641, 89024, 88920, 71663, 88921, 88889, 71687, 89039, 88878, 88923, 89038, 88910, 89026, 88902, 88882, 89030, 89037, 88868, 71667, 88940, 88933, 88931, 88927, 88935, 88926, 89419, 89422, 89451, 89425, 89434, 89390, 89411, 89384, 75716, 89393, 89375, 89409, 89461, 89385, 89366, 89431, 89417, 75700, 75684, 89396, 89439, 89399, 89391, 89383, 89442, 89369, 75699, 75664, 75698, 75651, 89413, 89360, 89420, 89382, 89450, 89357, 75637, 89441, 75653, 89460, 75683, 75632, 75689, 75662, 75707, 89436, 89379, 89408, 75663, 75641, 75648, 75642, 75644, 75636, 75678, 75652, 75711, 75646, 75718, 89447, 75676, 89438, 89388, 89394, 89351, 75695, 89368, 89378, 89401, 89389, 89403, 89466, 89437, 75712, 75645, 75670, 75719, 89532, 75497, 75593, 75568, 75600, 75479, 75487, 75573, 75608, 89521, 89482, 89488, 89516, 89589, 89561, 89533, 89563, 89582, 89523, 89540, 89526, 89527, 75526, 75603, 75495, 89485, 89507, 89473, 89489, 75473, 75616, 75607, 89551, 89553, 89486, 89541, 75584, 75490, 75509, 75559, 71496, 71215, 71262, 71201, 71234, 71122, 71466, 71576, 71470, 71449, 71458, 71325, 71549, 71241, 71290, 71182, 71485, 71161, 71451, 71436, 71443, 71429, 71532, 71431, 71276, 71157, 71213, 71535, 84887, 84958, 84723, 84954, 84835, 84935, 84934, 84911, 84830, 84784, 84912, 84914, 84931, 84927, 84930, 84836, 84722, 84922, 84928, 84910, 84925, 84963, 61263, 61303, 61301, 61270, 61331, 60211, 61391, 61387, 60193, 60313, 60319, 61319, 60241, 60325, 60004, 59978, 59995, 60035, 60024, 60011, 60012, 60022, 59987, 59996, 60010, 60015, 59983, 60002, 59986, 60026, 60020, 59988, 59992, 60021, 60000, 59993, 60033, 59980, 59977, 60027, 59979, 59990, 59998, 60016, 60014, 60031, 60013, 53565, 85411, 85419, 53701, 85362, 84821, 85382, 85390, 85358, 84755, 85466, 85322, 85301, 53725, 85283, 85446, 53749, 85470, 84776, 84747, 80902, 80862, 80895, 80896, 80897, 80870, 61198, 61159, 61124, 61146, 61127, 61176, 60061, 61209, 61156, 61154, 61197, 61174, 61138, 61237, 61214, 48078, 61140, 61167, 61231, 61188, 61219, 61207, 61232, 61201, 61220, 59954, 59929, 59857, 59867, 59935, 59893, 84668, 59927, 59919, 59952, 59886, 85214, 59925, 59870, 59901, 84675, 59900, 59911, 59959, 59868, 59863, 59892, 71371, 71374, 71393, 86280, 86282, 86278, 86262, 86286, 86383, 86283, 86391, 86240, 86382, 86372, 86287, 86374, 86297, 86281, 86306, 86300, 86242, 86269, 86293, 86289, 86370, 86243, 61514, 61706, 61637, 61505, 61679, 61676, 61613, 61490, 61475, 61445, 61478, 61472, 61700, 61439, 61511, 61502, 61574, 61697, 61457, 61571, 61442, 61670, 61523, 85578, 85538, 85562, 85559, 85577, 85567, 85565, 85568, 85545, 85602, 85540, 85542, 85571, 85600, 85603, 85605, 85608, 85583, 85591, 85572, 85582, 85610, 85611, 85619, 85530, 85622, 85548, 85595, 85564, 85576, 85573, 85534, 85579, 85552, 85574, 85533, 85546, 85597, 85594, 85561, 85588, 85560, 85627, 85620, 85616, 85589, 85580, 85585, 85563, 85531, 85541, 85575, 85529, 85621, 85615, 85535, 85544, 85539, 85557, 85613, 85618, 85625, 85549, 85609, 85598, 85570, 85547, 85624, 85626, 85558, 85569, 85584, 85586, 85526, 85592, 85527, 85555, 85604, 85528, 85581, 85599, 85607, 84738, 85341, 84730, 84734, 84735, 85271, 85338, 85269, 90940, 90919, 90945, 90923, 90848, 90837, 91625, 90842, 91636, 90960, 90931, 90844, 90949, 90917, 90918, 91635, 91611, 90858, 90930, 91630, 90916, 90840, 91631, 90927, 90915, 91606, 90948, 90946, 54981, 54535, 54573, 54581, 54589, 54544, 54571, 54555, 54606, 54601, 54463, 54469, 75323, 75336, 75328, 75327, 75308, 75331, 75329, 75321, 75311, 75310, 75324, 75317, 107682, 107683, 107684, 107796, 107797, 107798, 107789, 107790, 107791, 107746, 107747, 107748, 107869, 107870, 107871, 107820, 107821, 107822, 107757, 107758, 107759, 107771, 107772, 107773, 107813, 107814, 107815, 107775, 107776, 107777, 107671, 107672, 107673, 107718, 107719, 107720, 107866, 107867, 107868, 107803, 107804, 107805, 107678, 107679, 107680, 55011, 55027, 55038, 55028, 55035, 55025, 55023, 55039, 55029, 55019, 55017, 55040, 55034, 55036, 55015, 55022, 55013, 55037, 55016, 55031, 55026, 55012, 69215, 69216, 69217, 68587, 68588, 68589, 55009, 69039, 54996, 69071, 69072, 69073, 74882, 74883, 74884, 74818, 74819, 74820, 54982, 54995, 55004, 55001, 55000, 74830, 74831, 74832, 55005, 68583, 68584, 68585, 74878, 74879, 74880, 74802, 74803, 74804, 69147, 69148, 69149, 68919, 68920, 68921, 74798, 74799, 74800, 69095, 69096, 69097, 74846, 74847, 74848, 69183, 69184, 69185, 69051, 69052, 69053, 68927, 68928, 68929, 68611, 68612, 68613, 68823, 68824, 68825, 54999, 54992, 55007, 54993, 54989, 55006, 54990, 54984, 55010, 68815, 68816, 68817, 68651, 68652, 68653, 68631, 68632, 68633, 54985, 69011, 69012, 69013, 68987, 68988, 68989, 54991, 54994, 69027, 69028, 69029, 69155, 69156, 69157, 68931, 68932, 68933, 68603, 68604, 68605, 68863, 68864, 68865, 69207, 69208, 69209, 68883, 68884, 68885, 68959, 68960, 68961, 74786, 74787, 74788, 68619, 68620, 68621, 69007, 69008, 69009, 68579, 68580, 68581, 74894, 74895, 74896, 69055, 69056, 69057, 68639, 68640, 68641, 69119, 69120, 69121, 74822, 74823, 74824, 68939, 68940, 68941, 68835, 68836, 68837, 68555, 68556, 68557, 68547, 68548, 68549, 68807, 68808, 68809, 68559, 68560, 68561, 69143, 69144, 69145, 68803, 68804, 68805, 69167, 69168, 69169, 74790, 74791, 74792, 68799, 68800, 68801, 54998, 68855, 68856, 68857, 55008, 55003, 69223, 69224, 69225, 69187, 69188, 69189, 74838, 74839, 74840, 68875, 68876, 68877, 68544, 68545, 69040, 69041, 68635, 68636, 68637, 69163, 69164, 69165, 69199, 69200, 69201, 55002, 54983, 69251, 69252, 69253, 54986, 69151, 69152, 69153, 69019, 69020, 69021, 68851, 68595, 68596, 68597, 91778, 91779, 58200, 58201, 58202, 58203, 46822, 46823, 57462, 57463, 57486, 57487, 91780, 91781, 91746, 91747, 91748, 91749, 91790, 91750, 91726, 74483, 74484, 74485, 74486, 53566, 53567, 53568, 53734, 53735, 53736, 57717, 57718, 57702, 57703, 57663, 57664, 61707, 61708, 85412, 85413, 85414, 84756, 84757, 91791, 91792, 91793, 58095, 58096, 58097, 58098, 58230, 58231, 58232, 58233, 57780, 57781, 57782, 61638, 61639, 61506, 61507, 71217, 71219, 71221, 71223, 71225, 71226, 91786, 58180, 58181, 58182, 58183, 57540, 57541, 57573, 57574, 46801, 46802, 46867, 46868, 46810, 46811, 47825, 47826, 47827, 47789, 47790, 47791, 47785, 47786, 47787, 46870, 46871, 47793, 47794, 47795, 46843, 46844, 46831, 46832, 74421, 74422, 74423, 53574, 53575, 53576, 47857, 47858, 47859, 71263, 71264, 71265, 71266, 71267, 71268, 58463, 53674, 53675, 53676, 58185, 58186, 58187, 58188, 91774, 80843, 80844, 80845, 47805, 47806, 47807, 47897, 47898, 47899, 47837, 47838, 46840, 46841, 48119, 48120, 48121, 58543, 74528, 74529, 74530, 74531, 47839, 47801, 47802, 47803, 47813, 47814, 61680, 61681, 61488, 61489, 61614, 61615, 71123, 71124, 71125, 71126, 71127, 61491, 61492, 47815, 71204, 57693, 85511, 85512, 85513, 85420, 85421, 85422, 85467, 85468, 85469, 85278, 85279, 57694, 57684, 57690, 57691, 57685, 47142, 47143, 47070, 58544, 57681, 57682, 58555, 58556, 58537, 58538, 58552, 80699, 80700, 80701, 46804, 57498, 57499, 57549, 57550, 57468, 57469, 46805, 46864, 46865, 53702, 53703, 53704, 53666, 53667, 53668, 74543, 74544, 74545, 74546, 74453, 74454, 74455, 74456, 57546, 57547, 46813, 46814, 46858, 46859, 46873, 58115, 58116, 58117, 58118, 58240, 58241, 58242, 58243, 58120, 58121, 58122, 58123, 91718, 91719, 91720, 91721, 91782, 91738, 57736, 57737, 57738, 57594, 57595, 57537, 57538, 57501, 57502, 46849, 46850, 53698, 53699, 53700, 57591, 57592, 57513, 57514, 61446, 61447, 61479, 61480, 61473, 61474, 61701, 61702, 61440, 61441, 61635, 71242, 71243, 71244, 71245, 71246, 71247, 61636, 71202, 71206, 71208, 60316, 74458, 74459, 74460, 74461, 74518, 74519, 74520, 74521, 74463, 74464, 74465, 74466, 80827, 80828, 91742, 58215, 58216, 58217, 58218, 57588, 57589, 53622, 53623, 53624, 57914, 57915, 57916, 57516, 57517, 57615, 57616, 57474, 57475, 91739, 91740, 91741, 91722, 91723, 91724, 91725, 91770, 80839, 80840, 91771, 91772, 91773, 91754, 57525, 57526, 91751, 91752, 91753, 80841, 80815, 80816, 80817, 80803, 80804, 80805, 47865, 47866, 47867, 47833, 47834, 47835, 47877, 47878, 47879, 47861, 47862, 47863, 47829, 47830, 47831, 47797, 47798, 47799, 71183, 71186, 71188, 71192, 71196, 71198, 74429, 74430, 74431, 54545, 54546, 61656, 54509, 54510, 58528, 58529, 57678, 57679, 61392, 61393, 61394, 74513, 74514, 74515, 74516, 58591, 58592, 61657, 61512, 61513, 61575, 61576, 58522, 58523, 58513, 58514, 58534, 58535, 57720, 57721, 57669, 57670, 53606, 53607, 53608, 85363, 85364, 85365, 85416, 85417, 85418, 85391, 85392, 85393, 57666, 57667, 58594, 58595, 85447, 85448, 85449, 57600, 57601, 57534, 57535, 57558, 57559, 46837, 46838, 57639, 57640, 71162, 71165, 71168, 71171, 71174, 71176, 74433, 74434, 74435, 74468, 74469, 74470, 74471, 57714, 57715, 61698, 61699, 74425, 74426, 74427, 74417, 74418, 74419, 58531, 58532, 58540, 58541, 58558, 58559, 57648, 57649, 57672, 57673, 61458, 61459, 69195, 69196, 69197, 68623, 68624, 68625, 74890, 74891, 74892, 47130, 47131, 57726, 57727, 91734, 91762, 91763, 91764, 91765, 91755, 91756, 91757, 58100, 58101, 58102, 58103, 57748, 57749, 57750, 57555, 57556, 46795, 46796, 57504, 57505, 58062, 58063, 58064, 58034, 58035, 58036, 58038, 58039, 58040, 57884, 57885, 57886, 58150, 58151, 58152, 58153, 57808, 57809, 57810, 47889, 47890, 80735, 80736, 80737, 91766, 57483, 57484, 47893, 47894, 47895, 91730, 91731, 91732, 91733, 91783, 91784, 91785, 57918, 57919, 57920, 58170, 58171, 58172, 58173, 58235, 58236, 58237, 58238, 46852, 46853, 58190, 58191, 58192, 58193, 71277, 71278, 71279, 71280, 71281, 71282, 91767, 91768, 91769, 91758, 91759, 91760, 91761, 91735, 91736, 91737, 57630, 57631, 57480, 57481, 58195, 58196, 58197, 58198, 57609, 57610, 47849, 47850, 47851, 69099, 60212, 60214, 60217, 60219, 60221, 61443, 61444, 58553, 53762, 53763, 53764, 74473, 74474, 74475, 74476, 85302, 85303, 91714, 91715, 58006, 58007, 58008, 57624, 57625, 57552, 57553, 58175, 58176, 58177, 58178, 47881, 47882, 47883, 58030, 58031, 58032, 57954, 57955, 57956, 58018, 58019, 58020, 91743, 91744, 91745, 61548, 61671, 61672, 61503, 61504, 61524, 61525, 80703, 80704, 80705, 80687, 80688, 80689, 80887, 80888, 80889, 91787, 91788, 91789, 80847, 80848, 80849, 80831, 80832, 80833, 80879, 80880, 80881, 80795, 80796, 80797, 80829, 80727, 80728, 80729, 80907, 80908, 80909, 108986, 57627, 57628, 46807, 46808, 57699, 57700, 58573, 58086, 58087, 58088, 80711, 80712, 80713, 80863, 80864, 80865, 53558, 53559, 53560, 58074, 80799, 80800, 80801, 80675, 80676, 80677, 84777, 84778, 54521, 54522, 54464, 54465, 54470, 54471, 57696, 57697, 46879, 46880]\n",
            "{51449: 1, 51406: 2, 51412: 3, 51428: 4, 51476: 5, 51425: 6, 51434: 7, 51405: 8, 51443: 9, 51460: 10, 51397: 11, 51401: 12, 51455: 13, 51451: 14, 51394: 15, 51408: 16, 51424: 17, 51440: 18, 51439: 19, 51471: 20, 51466: 21, 51421: 22, 51473: 23, 51435: 24, 51400: 25, 51409: 26, 51429: 27, 51465: 28, 51422: 29, 135656: 30, 135648: 31, 135637: 32, 135634: 33, 135660: 34, 51407: 35, 51480: 36, 51414: 37, 51467: 38, 51456: 39, 51461: 40, 51415: 41, 51395: 42, 51446: 43, 135649: 44, 135652: 45, 51459: 46, 51431: 47, 51457: 48, 51447: 49, 51469: 50, 51416: 51, 51433: 52, 51454: 53, 51479: 54, 51398: 55, 51423: 56, 135645: 57, 135661: 58, 135647: 59, 51436: 60, 51430: 61, 51450: 62, 51475: 63, 51417: 64, 51413: 65, 135669: 66, 51418: 67, 51404: 68, 51396: 69, 51478: 70, 51463: 71, 51452: 72, 51410: 73, 51477: 74, 135670: 75, 135666: 76, 135636: 77, 135642: 78, 135651: 79, 135665: 80, 135641: 81, 135633: 82, 135658: 83, 135632: 84, 135654: 85, 135662: 86, 51472: 87, 51399: 88, 51438: 89, 135664: 90, 135631: 91, 135635: 92, 135659: 93, 51464: 94, 51411: 95, 135653: 96, 135640: 97, 51392: 98, 51453: 99, 51448: 100, 51445: 101, 51402: 102, 51420: 103, 135657: 104, 51458: 105, 51442: 106, 51474: 107, 51441: 108, 135638: 109, 135663: 110, 135655: 111, 92339: 112, 92318: 113, 92319: 114, 92316: 115, 92354: 116, 92334: 117, 92328: 118, 92351: 119, 92338: 120, 92350: 121, 92331: 122, 92348: 123, 92333: 124, 147976: 125, 147947: 126, 147962: 127, 92345: 128, 92349: 129, 92352: 130, 92347: 131, 147972: 132, 147961: 133, 147938: 134, 147944: 135, 92322: 136, 92346: 137, 147943: 138, 147937: 139, 92332: 140, 92355: 141, 92317: 142, 92325: 143, 92324: 144, 92340: 145, 147945: 146, 147956: 147, 147953: 148, 147968: 149, 92353: 150, 147973: 151, 147957: 152, 147948: 153, 147967: 154, 92327: 155, 147939: 156, 147951: 157, 147958: 158, 56082: 159, 56015: 160, 56014: 161, 56034: 162, 56049: 163, 56177: 164, 56207: 165, 56162: 166, 56160: 167, 56080: 168, 56109: 169, 56040: 170, 56116: 171, 66767: 172, 56158: 173, 66750: 174, 55984: 175, 56117: 176, 56051: 177, 56114: 178, 56173: 179, 56210: 180, 56234: 181, 56269: 182, 56240: 183, 56318: 184, 56100: 185, 56111: 186, 56313: 187, 56278: 188, 56267: 189, 56283: 190, 56310: 191, 56303: 192, 56228: 193, 56281: 194, 56238: 195, 56239: 196, 56230: 197, 56305: 198, 56325: 199, 56299: 200, 56226: 201, 56212: 202, 56028: 203, 56155: 204, 55976: 205, 56193: 206, 56189: 207, 56246: 208, 56195: 209, 56214: 210, 55985: 211, 56027: 212, 66772: 213, 55975: 214, 66769: 215, 56149: 216, 55978: 217, 56243: 218, 56209: 219, 56293: 220, 56306: 221, 56217: 222, 56254: 223, 55973: 224, 66760: 225, 56029: 226, 56181: 227, 56171: 228, 56170: 229, 66758: 230, 56164: 231, 56190: 232, 56157: 233, 56150: 234, 56178: 235, 56282: 236, 56304: 237, 93274: 238, 93268: 239, 93263: 240, 93266: 241, 93298: 242, 93296: 243, 56704: 244, 56695: 245, 56688: 246, 56697: 247, 48818: 248, 48809: 249, 93301: 250, 93277: 251, 56707: 252, 56685: 253, 48807: 254, 48819: 255, 48829: 256, 135564: 257, 135553: 258, 135568: 259, 135560: 260, 135561: 261, 48826: 262, 48813: 263, 48828: 264, 56702: 265, 56682: 266, 56699: 267, 48808: 268, 48810: 269, 48821: 270, 48811: 271, 135570: 272, 135579: 273, 56701: 274, 56705: 275, 56693: 276, 135586: 277, 56687: 278, 48832: 279, 135551: 280, 48823: 281, 56703: 282, 48827: 283, 56694: 284, 56708: 285, 48805: 286, 48816: 287, 135562: 288, 135572: 289, 135557: 290, 135573: 291, 135556: 292, 48825: 293, 56681: 294, 135577: 295, 135550: 296, 135558: 297, 135567: 298, 135588: 299, 48815: 300, 135569: 301, 135589: 302, 56683: 303, 56706: 304, 48831: 305, 56689: 306, 48833: 307, 56696: 308, 48822: 309, 48814: 310, 135581: 311, 135565: 312, 135563: 313, 135554: 314, 135566: 315, 135552: 316, 48806: 317, 56686: 318, 56679: 319, 135575: 320, 135555: 321, 48820: 322, 56691: 323, 56690: 324, 56684: 325, 135574: 326, 135583: 327, 135578: 328, 135580: 329, 48812: 330, 56692: 331, 48834: 332, 58001: 333, 58053: 334, 57933: 335, 58154: 336, 57875: 337, 58057: 338, 58104: 339, 57839: 340, 57949: 341, 57925: 342, 57855: 343, 58129: 344, 58037: 345, 58065: 346, 57819: 347, 57997: 348, 57973: 349, 57859: 350, 58033: 351, 57815: 352, 58085: 353, 58124: 354, 93597: 355, 93573: 356, 93499: 357, 93601: 358, 93581: 359, 93561: 360, 93482: 361, 57989: 362, 57751: 363, 57835: 364, 93475: 365, 93578: 366, 93612: 367, 93495: 368, 93536: 369, 93562: 370, 93593: 371, 93552: 372, 93497: 373, 93483: 374, 135619: 375, 135624: 376, 135597: 377, 135592: 378, 135600: 379, 135612: 380, 135605: 381, 93590: 382, 93580: 383, 93537: 384, 93567: 385, 93547: 386, 93587: 387, 135616: 388, 135601: 389, 135602: 390, 135596: 391, 93480: 392, 93557: 393, 93548: 394, 93563: 395, 135594: 396, 135610: 397, 135603: 398, 135615: 399, 135606: 400, 135608: 401, 93615: 402, 93592: 403, 135618: 404, 135593: 405, 93479: 406, 93534: 407, 93535: 408, 93586: 409, 93533: 410, 93618: 411, 93491: 412, 135604: 413, 135617: 414, 135620: 415, 135613: 416, 135622: 417, 135629: 418, 93589: 419, 93582: 420, 93494: 421, 93531: 422, 93539: 423, 93477: 424, 93569: 425, 135609: 426, 135599: 427, 135590: 428, 93579: 429, 93575: 430, 93489: 431, 135627: 432, 135625: 433, 93538: 434, 93559: 435, 93553: 436, 93613: 437, 93611: 438, 93576: 439, 93500: 440, 93556: 441, 93610: 442, 93607: 443, 93583: 444, 93541: 445, 135628: 446, 135611: 447, 93555: 448, 93546: 449, 93571: 450, 135598: 451, 93478: 452, 93532: 453, 93591: 454, 93619: 455, 93595: 456, 93604: 457, 93620: 458, 93602: 459, 93484: 460, 93609: 461, 135623: 462, 135621: 463, 135614: 464, 135591: 465, 135607: 466, 135595: 467, 56829: 468, 56841: 469, 112920: 470, 112935: 471, 112950: 472, 120468: 473, 120453: 474, 56736: 475, 56832: 476, 56817: 477, 56772: 478, 56871: 479, 56865: 480, 56763: 481, 112930: 482, 56739: 483, 120473: 484, 120483: 485, 56868: 486, 56745: 487, 56874: 488, 56778: 489, 56811: 490, 56733: 491, 112940: 492, 112915: 493, 56856: 494, 56715: 495, 56766: 496, 56760: 497, 56886: 498, 56859: 499, 112910: 500, 56847: 501, 56820: 502, 56754: 503, 56757: 504, 56790: 505, 56880: 506, 56793: 507, 56844: 508, 112955: 509, 120458: 510, 112945: 511, 120488: 512, 112925: 513, 120478: 514, 120463: 515, 120493: 516, 91073: 517, 91083: 518, 91078: 519, 91070: 520, 91074: 521, 91067: 522, 91111: 523, 91527: 524, 91110: 525, 91147: 526, 91540: 527, 91090: 528, 91530: 529, 91154: 530, 91116: 531, 91107: 532, 91529: 533, 92366: 534, 92362: 535, 92356: 536, 92379: 537, 92387: 538, 92389: 539, 92378: 540, 139661: 541, 139623: 542, 139664: 543, 139625: 544, 113334: 545, 139624: 546, 139663: 547, 139635: 548, 113206: 549, 113338: 550, 113226: 551, 113210: 552, 113222: 553, 113314: 554, 113218: 555, 113198: 556, 113346: 557, 139636: 558, 139426: 559, 139423: 560, 139425: 561, 139424: 562, 113194: 563, 113326: 564, 139384: 565, 139383: 566, 139381: 567, 139382: 568, 113342: 569, 113330: 570, 113318: 571, 139379: 572, 139420: 573, 139421: 574, 113214: 575, 113310: 576, 113190: 577, 139385: 578, 113202: 579, 139632: 580, 139658: 581, 113322: 582, 139631: 583, 139380: 584, 139422: 585, 113238: 586, 137990: 587, 138018: 588, 139317: 589, 113266: 590, 113166: 591, 113186: 592, 113162: 593, 113262: 594, 113246: 595, 137966: 596, 139670: 597, 113182: 598, 113230: 599, 113174: 600, 113250: 601, 113154: 602, 113158: 603, 137998: 604, 139672: 605, 139335: 606, 139315: 607, 113150: 608, 138104: 609, 139169: 610, 139557: 611, 139621: 612, 139483: 613, 139575: 614, 138109: 615, 138099: 616, 139491: 617, 139571: 618, 139572: 619, 139573: 620, 139574: 621, 139488: 622, 139502: 623, 139503: 624, 139504: 625, 139532: 626, 139547: 627, 139217: 628, 113242: 629, 113178: 630, 138010: 631, 137982: 632, 137994: 633, 139673: 634, 113170: 635, 113258: 636, 138102: 637, 139492: 638, 139493: 639, 139494: 640, 139615: 641, 139622: 642, 139177: 643, 139225: 644, 137986: 645, 139579: 646, 139580: 647, 139581: 648, 139582: 649, 139448: 650, 139449: 651, 139450: 652, 139451: 653, 139562: 654, 139616: 655, 139468: 656, 139677: 657, 139676: 658, 139313: 659, 138097: 660, 113234: 661, 138095: 662, 139507: 663, 139552: 664, 139480: 665, 139576: 666, 139577: 667, 139578: 668, 139497: 669, 139567: 670, 139452: 671, 139453: 672, 139454: 673, 139455: 674, 139617: 675, 138022: 676, 139469: 677, 139470: 678, 139471: 679, 138098: 680, 138107: 681, 138103: 682, 138101: 683, 138002: 684, 138014: 685, 139675: 686, 139671: 687, 138096: 688, 139508: 689, 139509: 690, 138105: 691, 139498: 692, 139499: 693, 137970: 694, 138108: 695, 139533: 696, 139534: 697, 139568: 698, 139569: 699, 139570: 700, 138106: 701, 138100: 702, 139563: 703, 139564: 704, 138006: 705, 137978: 706, 137974: 707, 139553: 708, 139554: 709, 139548: 710, 139549: 711, 139558: 712, 139559: 713, 113035: 714, 113020: 715, 119311: 716, 119243: 717, 119359: 718, 112968: 719, 112980: 720, 120392: 721, 120401: 722, 120390: 723, 113019: 724, 120395: 725, 120389: 726, 113022: 727, 113027: 728, 113037: 729, 113018: 730, 113023: 731, 119247: 732, 119293: 733, 119377: 734, 119326: 735, 119384: 736, 119250: 737, 119374: 738, 119379: 739, 119376: 740, 119365: 741, 113013: 742, 112996: 743, 120425: 744, 120445: 745, 119363: 746, 119309: 747, 119378: 748, 119303: 749, 113036: 750, 112964: 751, 119268: 752, 119318: 753, 119253: 754, 113028: 755, 113025: 756, 120387: 757, 120421: 758, 120394: 759, 120386: 760, 120429: 761, 120396: 762, 112972: 763, 112960: 764, 113034: 765, 113030: 766, 113024: 767, 113031: 768, 112976: 769, 113021: 770, 113038: 771, 119369: 772, 119255: 773, 119283: 774, 119240: 775, 119334: 776, 119364: 777, 119288: 778, 119375: 779, 119249: 780, 119385: 781, 119338: 782, 119346: 783, 119360: 784, 119256: 785, 119387: 786, 113032: 787, 113039: 788, 119257: 789, 120441: 790, 120399: 791, 119322: 792, 119350: 793, 119278: 794, 119279: 795, 119280: 796, 119281: 797, 119282: 798, 119239: 799, 119342: 800, 113033: 801, 113029: 802, 120398: 803, 120402: 804, 120391: 805, 113026: 806, 119308: 807, 119273: 808, 119354: 809, 119242: 810, 120413: 811, 113015: 812, 113016: 813, 113010: 814, 113014: 815, 119298: 816, 119358: 817, 113011: 818, 112988: 819, 112992: 820, 119381: 821, 119241: 822, 120433: 823, 120400: 824, 120384: 825, 120437: 826, 120449: 827, 119299: 828, 119300: 829, 119301: 830, 119302: 831, 119370: 832, 119383: 833, 119248: 834, 119238: 835, 119245: 836, 119380: 837, 119366: 838, 119382: 839, 120383: 840, 120417: 841, 120393: 842, 120385: 843, 119372: 844, 119246: 845, 119373: 846, 119252: 847, 119361: 848, 119367: 849, 119251: 850, 119244: 851, 119330: 852, 120397: 853, 119386: 854, 119310: 855, 119258: 856, 119362: 857, 119263: 858, 119368: 859, 119254: 860, 89074: 861, 89175: 862, 89068: 863, 89101: 864, 89124: 865, 89174: 866, 89091: 867, 89185: 868, 89186: 869, 89082: 870, 89083: 871, 89071: 872, 89111: 873, 89127: 874, 89177: 875, 89181: 876, 89067: 877, 89114: 878, 89112: 879, 89089: 880, 89183: 881, 89084: 882, 89110: 883, 89118: 884, 89136: 885, 89168: 886, 89137: 887, 89146: 888, 89139: 889, 89149: 890, 89145: 891, 89152: 892, 89155: 893, 89144: 894, 89170: 895, 89166: 896, 89143: 897, 89167: 898, 71769: 899, 71788: 900, 71773: 901, 71771: 902, 71781: 903, 88964: 904, 71790: 905, 71770: 906, 71779: 907, 88963: 908, 71782: 909, 71775: 910, 71796: 911, 71691: 912, 88914: 913, 89033: 914, 88864: 915, 71642: 916, 71649: 917, 71677: 918, 71679: 919, 71708: 920, 89032: 921, 88895: 922, 71661: 923, 71646: 924, 71729: 925, 71650: 926, 71726: 927, 71670: 928, 71706: 929, 71652: 930, 71716: 931, 71721: 932, 71715: 933, 88874: 934, 89041: 935, 88883: 936, 89027: 937, 71688: 938, 71709: 939, 71727: 940, 71719: 941, 71699: 942, 71643: 943, 88913: 944, 71703: 945, 88943: 946, 88938: 947, 88942: 948, 88944: 949, 88936: 950, 88925: 951, 79350: 952, 79377: 953, 80240: 954, 79833: 955, 81160: 956, 81210: 957, 79368: 958, 79374: 959, 79566: 960, 79356: 961, 81132: 962, 80260: 963, 80070: 964, 80045: 965, 79575: 966, 79563: 967, 79359: 968, 81169: 969, 79854: 970, 79830: 971, 80192: 972, 80228: 973, 79572: 974, 79587: 975, 79860: 976, 81147: 977, 80204: 978, 80041: 979, 80010: 980, 80040: 981, 80049: 982, 80043: 983, 80268: 984, 79569: 985, 79560: 986, 81126: 987, 81135: 988, 81151: 989, 81144: 990, 79845: 991, 80244: 992, 81189: 993, 79362: 994, 79929: 995, 79857: 996, 81141: 997, 79920: 998, 79932: 999, 81175: 1000, 80160: 1001, 80184: 1002, 80168: 1003, 80256: 1004, 80176: 1005, 80264: 1006, 80015: 1007, 80012: 1008, 80048: 1009, 80014: 1010, 80019: 1011, 81183: 1012, 81195: 1013, 80044: 1014, 80013: 1015, 80047: 1016, 79578: 1017, 79581: 1018, 79839: 1019, 80276: 1020, 80236: 1021, 80180: 1022, 80252: 1023, 80208: 1024, 80046: 1025, 81198: 1026, 81201: 1027, 81154: 1028, 81163: 1029, 79926: 1030, 81129: 1031, 79365: 1032, 79848: 1033, 81138: 1034, 79371: 1035, 79941: 1036, 81120: 1037, 80164: 1038, 80220: 1039, 80011: 1040, 80200: 1041, 80196: 1042, 81186: 1043, 81204: 1044, 80017: 1045, 80018: 1046, 75679: 1047, 75686: 1048, 75692: 1049, 75691: 1050, 75693: 1051, 75669: 1052, 75685: 1053, 75634: 1054, 75639: 1055, 75705: 1056, 75647: 1057, 75694: 1058, 75717: 1059, 75516: 1060, 75622: 1061, 75604: 1062, 75624: 1063, 75612: 1064, 75605: 1065, 75615: 1066, 75623: 1067, 75629: 1068, 75589: 1069, 75625: 1070, 75613: 1071, 75606: 1072, 75611: 1073, 75620: 1074, 75627: 1075, 75626: 1076, 75618: 1077, 75510: 1078, 75524: 1079, 75602: 1080, 75610: 1081, 75621: 1082, 75592: 1083, 75614: 1084, 75619: 1085, 75617: 1086, 75630: 1087, 75609: 1088, 80212: 1089, 80213: 1090, 80224: 1091, 80225: 1092, 80226: 1093, 80227: 1094, 80214: 1095, 80215: 1096, 61111: 1097, 61115: 1098, 61098: 1099, 61116: 1100, 61102: 1101, 61099: 1102, 61112: 1103, 61100: 1104, 61104: 1105, 61108: 1106, 61106: 1107, 61097: 1108, 61107: 1109, 61117: 1110, 61105: 1111, 61095: 1112, 61114: 1113, 61094: 1114, 61093: 1115, 61096: 1116, 61091: 1117, 61103: 1118, 61109: 1119, 61110: 1120, 61089: 1121, 61118: 1122, 61092: 1123, 61090: 1124, 61101: 1125, 61113: 1126, 84977: 1127, 84921: 1128, 84978: 1129, 84936: 1130, 84938: 1131, 84961: 1132, 84780: 1133, 84919: 1134, 84943: 1135, 84880: 1136, 84831: 1137, 84964: 1138, 84941: 1139, 84884: 1140, 84932: 1141, 84965: 1142, 84973: 1143, 84974: 1144, 84724: 1145, 84741: 1146, 84739: 1147, 84967: 1148, 84720: 1149, 84975: 1150, 84886: 1151, 84885: 1152, 84937: 1153, 84782: 1154, 84918: 1155, 84837: 1156, 84944: 1157, 148065: 1158, 148136: 1159, 148072: 1160, 84962: 1161, 84721: 1162, 84883: 1163, 84939: 1164, 84749: 1165, 84960: 1166, 84744: 1167, 148146: 1168, 148149: 1169, 148155: 1170, 148094: 1171, 148137: 1172, 148162: 1173, 148113: 1174, 148151: 1175, 148099: 1176, 148062: 1177, 148120: 1178, 84956: 1179, 84779: 1180, 84785: 1181, 84949: 1182, 84728: 1183, 84976: 1184, 148083: 1185, 148075: 1186, 148103: 1187, 148100: 1188, 148175: 1189, 148092: 1190, 84751: 1191, 84879: 1192, 84951: 1193, 84933: 1194, 84920: 1195, 148069: 1196, 148125: 1197, 148105: 1198, 84888: 1199, 84833: 1200, 84969: 1201, 84946: 1202, 148173: 1203, 148135: 1204, 148060: 1205, 148109: 1206, 148078: 1207, 84745: 1208, 84726: 1209, 84952: 1210, 84915: 1211, 148143: 1212, 148164: 1213, 148087: 1214, 148145: 1215, 148131: 1216, 148126: 1217, 148115: 1218, 85864: 1219, 85812: 1220, 85813: 1221, 85845: 1222, 85890: 1223, 85891: 1224, 85843: 1225, 85874: 1226, 85861: 1227, 85834: 1228, 85817: 1229, 85811: 1230, 85858: 1231, 85836: 1232, 85826: 1233, 85882: 1234, 85816: 1235, 52873: 1236, 66356: 1237, 66151: 1238, 66145: 1239, 53005: 1240, 66526: 1241, 62682: 1242, 52960: 1243, 66400: 1244, 65281: 1245, 52824: 1246, 66560: 1247, 101006: 1248, 99008: 1249, 99025: 1250, 65287: 1251, 65323: 1252, 52948: 1253, 66554: 1254, 65359: 1255, 65263: 1256, 65347: 1257, 62544: 1258, 98975: 1259, 101770: 1260, 66372: 1261, 66073: 1262, 62564: 1263, 101812: 1264, 100774: 1265, 100732: 1266, 65995: 1267, 53011: 1268, 66351: 1269, 52957: 1270, 52927: 1271, 52839: 1272, 52830: 1273, 62634: 1274, 66500: 1275, 66402: 1276, 66450: 1277, 66350: 1278, 100654: 1279, 101666: 1280, 98997: 1281, 99338: 1282, 62646: 1283, 66513: 1284, 66456: 1285, 66549: 1286, 66540: 1287, 99647: 1288, 100671: 1289, 66109: 1290, 65245: 1291, 66163: 1292, 52999: 1293, 66357: 1294, 62591: 1295, 52975: 1296, 66392: 1297, 101861: 1298, 100952: 1299, 99305: 1300, 66121: 1301, 62712: 1302, 62562: 1303, 66025: 1304, 62706: 1305, 52820: 1306, 66555: 1307, 66001: 1308, 66103: 1309, 66097: 1310, 65305: 1311, 66157: 1312, 65299: 1313, 52954: 1314, 66524: 1315, 100999: 1316, 99636: 1317, 62576: 1318, 66531: 1319, 62724: 1320, 52882: 1321, 66541: 1322, 66409: 1323, 52823: 1324, 62628: 1325, 65989: 1326, 66133: 1327, 52915: 1328, 52996: 1329, 52891: 1330, 66444: 1331, 100791: 1332, 101947: 1333, 100821: 1334, 65293: 1335, 66067: 1336, 65329: 1337, 98986: 1338, 65269: 1339, 100896: 1340, 100910: 1341, 62538: 1342, 66043: 1343, 62622: 1344, 62532: 1345, 65335: 1346, 65275: 1347, 62652: 1348, 62640: 1349, 62508: 1350, 62550: 1351, 66019: 1352, 65251: 1353, 98964: 1354, 100868: 1355, 98942: 1356, 66013: 1357, 66169: 1358, 102018: 1359, 101056: 1360, 99272: 1361, 62574: 1362, 99481: 1363, 99658: 1364, 99449: 1365, 101721: 1366, 101619: 1367, 99360: 1368, 99415: 1369, 100835: 1370, 66384: 1371, 66394: 1372, 66367: 1373, 66380: 1374, 66499: 1375, 66352: 1376, 66435: 1377, 66521: 1378, 66539: 1379, 66481: 1380, 66399: 1381, 66378: 1382, 66337: 1383, 66326: 1384, 66467: 1385, 66414: 1386, 66344: 1387, 66331: 1388, 66325: 1389, 66543: 1390, 66491: 1391, 66329: 1392, 66486: 1393, 66480: 1394, 66415: 1395, 66338: 1396, 97864: 1397, 65621: 1398, 97828: 1399, 66320: 1400, 65833: 1401, 97912: 1402, 66207: 1403, 97820: 1404, 97788: 1405, 97856: 1406, 97844: 1407, 97832: 1408, 97868: 1409, 97880: 1410, 66282: 1411, 66255: 1412, 65785: 1413, 66201: 1414, 97824: 1415, 97804: 1416, 66284: 1417, 97904: 1418, 97896: 1419, 97816: 1420, 66196: 1421, 66301: 1422, 97924: 1423, 97916: 1424, 97772: 1425, 97920: 1426, 66263: 1427, 97900: 1428, 97884: 1429, 97800: 1430, 65874: 1431, 66225: 1432, 65869: 1433, 66319: 1434, 65855: 1435, 97784: 1436, 66230: 1437, 97908: 1438, 97888: 1439, 65677: 1440, 97776: 1441, 97852: 1442, 97928: 1443, 97876: 1444, 65741: 1445, 97796: 1446, 97836: 1447, 66273: 1448, 97780: 1449, 66317: 1450, 66189: 1451, 97860: 1452, 97792: 1453, 97892: 1454, 97840: 1455, 97848: 1456, 97808: 1457, 53276: 1458, 66669: 1459, 79070: 1460, 53294: 1461, 66635: 1462, 79035: 1463, 79062: 1464, 78942: 1465, 78915: 1466, 53335: 1467, 66682: 1468, 78925: 1469, 53344: 1470, 66694: 1471, 79043: 1472, 78878: 1473, 78881: 1474, 79059: 1475, 78903: 1476, 78951: 1477, 78864: 1478, 66566: 1479, 53305: 1480, 53341: 1481, 66652: 1482, 78961: 1483, 53279: 1484, 66628: 1485, 79068: 1486, 78914: 1487, 78905: 1488, 78924: 1489, 53349: 1490, 66676: 1491, 78983: 1492, 53346: 1493, 66617: 1494, 53291: 1495, 66588: 1496, 78916: 1497, 53290: 1498, 66658: 1499, 78949: 1500, 78937: 1501, 79032: 1502, 79057: 1503, 66670: 1504, 78927: 1505, 53267: 1506, 66697: 1507, 66684: 1508, 53329: 1509, 78956: 1510, 78923: 1511, 78867: 1512, 78906: 1513, 79002: 1514, 78869: 1515, 79019: 1516, 78861: 1517, 53287: 1518, 66632: 1519, 78877: 1520, 79058: 1521, 78952: 1522, 78938: 1523, 78945: 1524, 78858: 1525, 79026: 1526, 79045: 1527, 78975: 1528, 78874: 1529, 78997: 1530, 79039: 1531, 79011: 1532, 78972: 1533, 78959: 1534, 78882: 1535, 78876: 1536, 78957: 1537, 79029: 1538, 79071: 1539, 79080: 1540, 78928: 1541, 79004: 1542, 78871: 1543, 78966: 1544, 78885: 1545, 79076: 1546, 78993: 1547, 79013: 1548, 79028: 1549, 78979: 1550, 79048: 1551, 78982: 1552, 78860: 1553, 78865: 1554, 78940: 1555, 79020: 1556, 78947: 1557, 78902: 1558, 78879: 1559, 79016: 1560, 78976: 1561, 78886: 1562, 79044: 1563, 78931: 1564, 78917: 1565, 78968: 1566, 78863: 1567, 79065: 1568, 78868: 1569, 78977: 1570, 60017: 1571, 60003: 1572, 60034: 1573, 59984: 1574, 59997: 1575, 60028: 1576, 60025: 1577, 60032: 1578, 60005: 1579, 60036: 1580, 59982: 1581, 59991: 1582, 60018: 1583, 60019: 1584, 59981: 1585, 60029: 1586, 60023: 1587, 60006: 1588, 49276: 1589, 49274: 1590, 49268: 1591, 49264: 1592, 49287: 1593, 49277: 1594, 49271: 1595, 49275: 1596, 49272: 1597, 53553: 1598, 49290: 1599, 53545: 1600, 49281: 1601, 49286: 1602, 49263: 1603, 49289: 1604, 49269: 1605, 49273: 1606, 49279: 1607, 49262: 1608, 53533: 1609, 53589: 1610, 49261: 1611, 49266: 1612, 53625: 1613, 49267: 1614, 49282: 1615, 49285: 1616, 53609: 1617, 49284: 1618, 49278: 1619, 49280: 1620, 49265: 1621, 49288: 1622, 53537: 1623, 53673: 1624, 49283: 1625, 53613: 1626, 53541: 1627, 53581: 1628, 53569: 1629, 53557: 1630, 53573: 1631, 53577: 1632, 53605: 1633, 53597: 1634, 53649: 1635, 53585: 1636, 53621: 1637, 53617: 1638, 53601: 1639, 53645: 1640, 53637: 1641, 53641: 1642, 53693: 1643, 53561: 1644, 53697: 1645, 85354: 1646, 85399: 1647, 85366: 1648, 85415: 1649, 84793: 1650, 49270: 1651, 84801: 1652, 85378: 1653, 84805: 1654, 147491: 1655, 147554: 1656, 147519: 1657, 147576: 1658, 147510: 1659, 87037: 1660, 87091: 1661, 87024: 1662, 87064: 1663, 87074: 1664, 87045: 1665, 87120: 1666, 87040: 1667, 8463: 1668, 87036: 1669, 87084: 1670, 87034: 1671, 87058: 1672, 87088: 1673, 87125: 1674, 87078: 1675, 87054: 1676, 87105: 1677, 87082: 1678, 87113: 1679, 87117: 1680, 147508: 1681, 147562: 1682, 147514: 1683, 147485: 1684, 147552: 1685, 147501: 1686, 87033: 1687, 87053: 1688, 87032: 1689, 87119: 1690, 87068: 1691, 87028: 1692, 87085: 1693, 87062: 1694, 87083: 1695, 87132: 1696, 87056: 1697, 87123: 1698, 87133: 1699, 87039: 1700, 87089: 1701, 87025: 1702, 87072: 1703, 87108: 1704, 87071: 1705, 87090: 1706, 87129: 1707, 87029: 1708, 87114: 1709, 87043: 1710, 87049: 1711, 87035: 1712, 87073: 1713, 87079: 1714, 147530: 1715, 147504: 1716, 147502: 1717, 147523: 1718, 147488: 1719, 147483: 1720, 147547: 1721, 147566: 1722, 147478: 1723, 147482: 1724, 147537: 1725, 87130: 1726, 87106: 1727, 87127: 1728, 147553: 1729, 147520: 1730, 147517: 1731, 147573: 1732, 147549: 1733, 87046: 1734, 87055: 1735, 147512: 1736, 147528: 1737, 147480: 1738, 147481: 1739, 147551: 1740, 87128: 1741, 87081: 1742, 147567: 1743, 147569: 1744, 147524: 1745, 147511: 1746, 147522: 1747, 147558: 1748, 147540: 1749, 147543: 1750, 147531: 1751, 147544: 1752, 87065: 1753, 87050: 1754, 87052: 1755, 87069: 1756, 147526: 1757, 147495: 1758, 147498: 1759, 147486: 1760, 147515: 1761, 147542: 1762, 87059: 1763, 87086: 1764, 87109: 1765, 87116: 1766, 87087: 1767, 87051: 1768, 87026: 1769, 147550: 1770, 147560: 1771, 147546: 1772, 147564: 1773, 87047: 1774, 147513: 1775, 147555: 1776, 147499: 1777, 147574: 1778, 147563: 1779, 147557: 1780, 147570: 1781, 147516: 1782, 147541: 1783, 147561: 1784, 147575: 1785, 147503: 1786, 147548: 1787, 147497: 1788, 147568: 1789, 147500: 1790, 147577: 1791, 147489: 1792, 147532: 1793, 147490: 1794, 147506: 1795, 147572: 1796, 147509: 1797, 147521: 1798, 147533: 1799, 147518: 1800, 147494: 1801, 147525: 1802, 147492: 1803, 147487: 1804, 87070: 1805, 87112: 1806, 87104: 1807, 87061: 1808, 87131: 1809, 87030: 1810, 87066: 1811, 87060: 1812, 87042: 1813, 80658: 1814, 80520: 1815, 80496: 1816, 80622: 1817, 80526: 1818, 80628: 1819, 80352: 1820, 80664: 1821, 80376: 1822, 80340: 1823, 80418: 1824, 80592: 1825, 80616: 1826, 80424: 1827, 80538: 1828, 80640: 1829, 80580: 1830, 80544: 1831, 80508: 1832, 80550: 1833, 80604: 1834, 80586: 1835, 80502: 1836, 80598: 1837, 80466: 1838, 80454: 1839, 80382: 1840, 80412: 1841, 80448: 1842, 80364: 1843, 80574: 1844, 80406: 1845, 80568: 1846, 80442: 1847, 80370: 1848, 80310: 1849, 80394: 1850, 80328: 1851, 80472: 1852, 80358: 1853, 80322: 1854, 80430: 1855, 80346: 1856, 80436: 1857, 80610: 1858, 80388: 1859, 80484: 1860, 80562: 1861, 80334: 1862, 80490: 1863, 80532: 1864, 80556: 1865, 80652: 1866, 80634: 1867, 80646: 1868, 54115: 1869, 54151: 1870, 54125: 1871, 54150: 1872, 54103: 1873, 54142: 1874, 54113: 1875, 54117: 1876, 54158: 1877, 54120: 1878, 54114: 1879, 54106: 1880, 54137: 1881, 54145: 1882, 54111: 1883, 54138: 1884, 54144: 1885, 54146: 1886, 54148: 1887, 54132: 1888, 147606: 1889, 54121: 1890, 54109: 1891, 54107: 1892, 54122: 1893, 54130: 1894, 86787: 1895, 86890: 1896, 86887: 1897, 86876: 1898, 86853: 1899, 86798: 1900, 86796: 1901, 86783: 1902, 86773: 1903, 86784: 1904, 86799: 1905, 86790: 1906, 86842: 1907, 86795: 1908, 86852: 1909, 86900: 1910, 86881: 1911, 86857: 1912, 86797: 1913, 86903: 1914, 86895: 1915, 86840: 1916, 86782: 1917, 86894: 1918, 147605: 1919, 147660: 1920, 147612: 1921, 147630: 1922, 147654: 1923, 147602: 1924, 147589: 1925, 147651: 1926, 147635: 1927, 147664: 1928, 147615: 1929, 147652: 1930, 147593: 1931, 147648: 1932, 147617: 1933, 147644: 1934, 147614: 1935, 147642: 1936, 86884: 1937, 86785: 1938, 86880: 1939, 86886: 1940, 86777: 1941, 86802: 1942, 86836: 1943, 86877: 1944, 86879: 1945, 86775: 1946, 86891: 1947, 86793: 1948, 86855: 1949, 86893: 1950, 86849: 1951, 86841: 1952, 86904: 1953, 86860: 1954, 147599: 1955, 147665: 1956, 147585: 1957, 147625: 1958, 147583: 1959, 147632: 1960, 147584: 1961, 147647: 1962, 147638: 1963, 147656: 1964, 147613: 1965, 147655: 1966, 147668: 1967, 86800: 1968, 86892: 1969, 86835: 1970, 147620: 1971, 147662: 1972, 147591: 1973, 147603: 1974, 147666: 1975, 147649: 1976, 147633: 1977, 147657: 1978, 147663: 1979, 147643: 1980, 86778: 1981, 86885: 1982, 147622: 1983, 147616: 1984, 147636: 1985, 147669: 1986, 147594: 1987, 147670: 1988, 147634: 1989, 147646: 1990, 147631: 1991, 147604: 1992, 86834: 1993, 86908: 1994, 86794: 1995, 147611: 1996, 147592: 1997, 86889: 1998, 86901: 1999, 86792: 2000, 86845: 2001, 147629: 2002, 147597: 2003, 147600: 2004, 147608: 2005, 147586: 2006, 147645: 2007, 147671: 2008, 86848: 2009, 86851: 2010, 86882: 2011, 86774: 2012, 86902: 2013, 147667: 2014, 147609: 2015, 147639: 2016, 147641: 2017, 147610: 2018, 147619: 2019, 147640: 2020, 86888: 2021, 147628: 2022, 147626: 2023, 86907: 2024, 86905: 2025, 86779: 2026, 86909: 2027, 147623: 2028, 147598: 2029, 147658: 2030, 147601: 2031, 86801: 2032, 86847: 2033, 86883: 2034, 86844: 2035, 86786: 2036, 86789: 2037, 86856: 2038, 86837: 2039, 86838: 2040, 86843: 2041, 86906: 2042, 54161: 2043, 54127: 2044, 54131: 2045, 54105: 2046, 54160: 2047, 54136: 2048, 54139: 2049, 54126: 2050, 71349: 2051, 71342: 2052, 71347: 2053, 71340: 2054, 71361: 2055, 71357: 2056, 71359: 2057, 71346: 2058, 71343: 2059, 71355: 2060, 71345: 2061, 71362: 2062, 71363: 2063, 71354: 2064, 71339: 2065, 71358: 2066, 71368: 2067, 71353: 2068, 71341: 2069, 71365: 2070, 71360: 2071, 71351: 2072, 71344: 2073, 71352: 2074, 71350: 2075, 71356: 2076, 94877: 2077, 94868: 2078, 94865: 2079, 94866: 2080, 94885: 2081, 94894: 2082, 94876: 2083, 148009: 2084, 147993: 2085, 148013: 2086, 148015: 2087, 94899: 2088, 94869: 2089, 94897: 2090, 94902: 2091, 94903: 2092, 94881: 2093, 94896: 2094, 94878: 2095, 94886: 2096, 94872: 2097, 94867: 2098, 94892: 2099, 148011: 2100, 147977: 2101, 148008: 2102, 147985: 2103, 148004: 2104, 94890: 2105, 94898: 2106, 94889: 2107, 147986: 2108, 148010: 2109, 147984: 2110, 147980: 2111, 94888: 2112, 94871: 2113, 94891: 2114, 94874: 2115, 148000: 2116, 147997: 2117, 148012: 2118, 148007: 2119, 148002: 2120, 94879: 2121, 94882: 2122, 94904: 2123, 94895: 2124, 94887: 2125, 148014: 2126, 147994: 2127, 94875: 2128, 147999: 2129, 147988: 2130, 148006: 2131, 148001: 2132, 84700: 2133, 84628: 2134, 86124: 2135, 86096: 2136, 86122: 2137, 86104: 2138, 85102: 2139, 85099: 2140, 85103: 2141, 84705: 2142, 85684: 2143, 84704: 2144, 85106: 2145, 84620: 2146, 85685: 2147, 84624: 2148, 85094: 2149, 84708: 2150, 85683: 2151, 85650: 2152, 86101: 2153, 86102: 2154, 85682: 2155, 53689: 2156, 53741: 2157, 53757: 2158, 53665: 2159, 53657: 2160, 53745: 2161, 53765: 2162, 53761: 2163, 53681: 2164, 53729: 2165, 53769: 2166, 53661: 2167, 53721: 2168, 53653: 2169, 53737: 2170, 53709: 2171, 53669: 2172, 53753: 2173, 53713: 2174, 53705: 2175, 53733: 2176, 53677: 2177, 53717: 2178, 53685: 2179, 85316: 2180, 85328: 2181, 85462: 2182, 85286: 2183, 85274: 2184, 85313: 2185, 84764: 2186, 85478: 2187, 85510: 2188, 85298: 2189, 85295: 2190, 84758: 2191, 85277: 2192, 85518: 2193, 85502: 2194, 80890: 2195, 80814: 2196, 80702: 2197, 80738: 2198, 80794: 2199, 80826: 2200, 80694: 2201, 80898: 2202, 80722: 2203, 80822: 2204, 80798: 2205, 80714: 2206, 80690: 2207, 80834: 2208, 80710: 2209, 80790: 2210, 80742: 2211, 80866: 2212, 80838: 2213, 80818: 2214, 80874: 2215, 80670: 2216, 80810: 2217, 80894: 2218, 89616: 2219, 89641: 2220, 80806: 2221, 80786: 2222, 80718: 2223, 80730: 2224, 80674: 2225, 80726: 2226, 89606: 2227, 89682: 2228, 89677: 2229, 80882: 2230, 80802: 2231, 80682: 2232, 80850: 2233, 89673: 2234, 89694: 2235, 89626: 2236, 89653: 2237, 80830: 2238, 80734: 2239, 89637: 2240, 80858: 2241, 80842: 2242, 80906: 2243, 89603: 2244, 89678: 2245, 89619: 2246, 89672: 2247, 89600: 2248, 89647: 2249, 80846: 2250, 89675: 2251, 80698: 2252, 89615: 2253, 80686: 2254, 80886: 2255, 80854: 2256, 80878: 2257, 89594: 2258, 89609: 2259, 80706: 2260, 80678: 2261, 89610: 2262, 60117: 2263, 60084: 2264, 60066: 2265, 60150: 2266, 60083: 2267, 60047: 2268, 60136: 2269, 60109: 2270, 60086: 2271, 60124: 2272, 60123: 2273, 60111: 2274, 60071: 2275, 60098: 2276, 60070: 2277, 60120: 2278, 60058: 2279, 60139: 2280, 60113: 2281, 60099: 2282, 60040: 2283, 60038: 2284, 60051: 2285, 60119: 2286, 60054: 2287, 60093: 2288, 60080: 2289, 60097: 2290, 60073: 2291, 60152: 2292, 60076: 2293, 60129: 2294, 60045: 2295, 60079: 2296, 60147: 2297, 60042: 2298, 60050: 2299, 60048: 2300, 60151: 2301, 60069: 2302, 60091: 2303, 60141: 2304, 60046: 2305, 60127: 2306, 60102: 2307, 60145: 2308, 60126: 2309, 60156: 2310, 60148: 2311, 60089: 2312, 60037: 2313, 60128: 2314, 60135: 2315, 60154: 2316, 60055: 2317, 60096: 2318, 60039: 2319, 60104: 2320, 60056: 2321, 60105: 2322, 60078: 2323, 60138: 2324, 60121: 2325, 60132: 2326, 60067: 2327, 60142: 2328, 60115: 2329, 60049: 2330, 60101: 2331, 60057: 2332, 60131: 2333, 60062: 2334, 60082: 2335, 60107: 2336, 60063: 2337, 60118: 2338, 60114: 2339, 60125: 2340, 60052: 2341, 60110: 2342, 60153: 2343, 60149: 2344, 60060: 2345, 60044: 2346, 60072: 2347, 60155: 2348, 60068: 2349, 60053: 2350, 60133: 2351, 60043: 2352, 60090: 2353, 60094: 2354, 60112: 2355, 60100: 2356, 60146: 2357, 60088: 2358, 60059: 2359, 60108: 2360, 60106: 2361, 60081: 2362, 60064: 2363, 60095: 2364, 60140: 2365, 60116: 2366, 60065: 2367, 60134: 2368, 60144: 2369, 60092: 2370, 60103: 2371, 60077: 2372, 60130: 2373, 60041: 2374, 60085: 2375, 60137: 2376, 59913: 2377, 59898: 2378, 108993: 2379, 108984: 2380, 108978: 2381, 108972: 2382, 108990: 2383, 108939: 2384, 108945: 2385, 108909: 2386, 108963: 2387, 108957: 2388, 59874: 2389, 59939: 2390, 59860: 2391, 59941: 2392, 108936: 2393, 108924: 2394, 108903: 2395, 59926: 2396, 59887: 2397, 59899: 2398, 59962: 2399, 59970: 2400, 59975: 2401, 59930: 2402, 59905: 2403, 59885: 2404, 59864: 2405, 108921: 2406, 108912: 2407, 108969: 2408, 59932: 2409, 59924: 2410, 59963: 2411, 59917: 2412, 109002: 2413, 59889: 2414, 59943: 2415, 59903: 2416, 59969: 2417, 108930: 2418, 59960: 2419, 108897: 2420, 109014: 2421, 109005: 2422, 108996: 2423, 108906: 2424, 109008: 2425, 108987: 2426, 59912: 2427, 59878: 2428, 59922: 2429, 59895: 2430, 109011: 2431, 108948: 2432, 108954: 2433, 108915: 2434, 108960: 2435, 108951: 2436, 108918: 2437, 108966: 2438, 108942: 2439, 108927: 2440, 85241: 2441, 85057: 2442, 84673: 2443, 85011: 2444, 84663: 2445, 108999: 2446, 85018: 2447, 85216: 2448, 84662: 2449, 108933: 2450, 108900: 2451, 85017: 2452, 85015: 2453, 85240: 2454, 85014: 2455, 85054: 2456, 85217: 2457, 84669: 2458, 85246: 2459, 91670: 2460, 85010: 2461, 91672: 2462, 85244: 2463, 84676: 2464, 85012: 2465, 85242: 2466, 85053: 2467, 108975: 2468, 84678: 2469, 147894: 2470, 147887: 2471, 147881: 2472, 147909: 2473, 148021: 2474, 147907: 2475, 147917: 2476, 148051: 2477, 148036: 2478, 84677: 2479, 85211: 2480, 85060: 2481, 85213: 2482, 85212: 2483, 91668: 2484, 84670: 2485, 84659: 2486, 147920: 2487, 147918: 2488, 147878: 2489, 147915: 2490, 147899: 2491, 147884: 2492, 85050: 2493, 85061: 2494, 147886: 2495, 147882: 2496, 147888: 2497, 147912: 2498, 148018: 2499, 148052: 2500, 147933: 2501, 147934: 2502, 148022: 2503, 148044: 2504, 148027: 2505, 148054: 2506, 147906: 2507, 148026: 2508, 148041: 2509, 148037: 2510, 148032: 2511, 148047: 2512, 148053: 2513, 148035: 2514, 148023: 2515, 84665: 2516, 85055: 2517, 85215: 2518, 85009: 2519, 85210: 2520, 84660: 2521, 84661: 2522, 91673: 2523, 85051: 2524, 91669: 2525, 147898: 2526, 147889: 2527, 148024: 2528, 148050: 2529, 148020: 2530, 147923: 2531, 148025: 2532, 148029: 2533, 84674: 2534, 147929: 2535, 147897: 2536, 147877: 2537, 84666: 2538, 147930: 2539, 148034: 2540, 148033: 2541, 147926: 2542, 147924: 2543, 147916: 2544, 148017: 2545, 148028: 2546, 148030: 2547, 147908: 2548, 147902: 2549, 147914: 2550, 147935: 2551, 147885: 2552, 58668: 2553, 71387: 2554, 58711: 2555, 71380: 2556, 71394: 2557, 71373: 2558, 58699: 2559, 58686: 2560, 58673: 2561, 58697: 2562, 58687: 2563, 71383: 2564, 58681: 2565, 58693: 2566, 71389: 2567, 58718: 2568, 58698: 2569, 58721: 2570, 58671: 2571, 58666: 2572, 58677: 2573, 58713: 2574, 58682: 2575, 58725: 2576, 58675: 2577, 58670: 2578, 58706: 2579, 58689: 2580, 71369: 2581, 58709: 2582, 58683: 2583, 58723: 2584, 58720: 2585, 71376: 2586, 58707: 2587, 58704: 2588, 58667: 2589, 58715: 2590, 58672: 2591, 71378: 2592, 58702: 2593, 58676: 2594, 58714: 2595, 58684: 2596, 58712: 2597, 58708: 2598, 58695: 2599, 58688: 2600, 58719: 2601, 58690: 2602, 58705: 2603, 58717: 2604, 58691: 2605, 58716: 2606, 71382: 2607, 58710: 2608, 71385: 2609, 58703: 2610, 58700: 2611, 71396: 2612, 71392: 2613, 58701: 2614, 58722: 2615, 71390: 2616, 71388: 2617, 71395: 2618, 71377: 2619, 58679: 2620, 71384: 2621, 71372: 2622, 71397: 2623, 58694: 2624, 71375: 2625, 71379: 2626, 71386: 2627, 58724: 2628, 58678: 2629, 58669: 2630, 71398: 2631, 71391: 2632, 71381: 2633, 58692: 2634, 58674: 2635, 71370: 2636, 58696: 2637, 147828: 2638, 147839: 2639, 147865: 2640, 147829: 2641, 147850: 2642, 147841: 2643, 147874: 2644, 147847: 2645, 147817: 2646, 147837: 2647, 147866: 2648, 147836: 2649, 147856: 2650, 147827: 2651, 147852: 2652, 147830: 2653, 147867: 2654, 147823: 2655, 147868: 2656, 58680: 2657, 147869: 2658, 147855: 2659, 147862: 2660, 147843: 2661, 147857: 2662, 147871: 2663, 147838: 2664, 147834: 2665, 147820: 2666, 147861: 2667, 147835: 2668, 147831: 2669, 147818: 2670, 147844: 2671, 147863: 2672, 147851: 2673, 147822: 2674, 147849: 2675, 147858: 2676, 147842: 2677, 147848: 2678, 147859: 2679, 147819: 2680, 147825: 2681, 147870: 2682, 147833: 2683, 147876: 2684, 147854: 2685, 147824: 2686, 147840: 2687, 147845: 2688, 147875: 2689, 147873: 2690, 147821: 2691, 147864: 2692, 86373: 2693, 86379: 2694, 86261: 2695, 86264: 2696, 86277: 2697, 86258: 2698, 86239: 2699, 86377: 2700, 86259: 2701, 86274: 2702, 86375: 2703, 86248: 2704, 86305: 2705, 86387: 2706, 86252: 2707, 86268: 2708, 86386: 2709, 86285: 2710, 86271: 2711, 86298: 2712, 86307: 2713, 86291: 2714, 86367: 2715, 86244: 2716, 86393: 2717, 86247: 2718, 86301: 2719, 86371: 2720, 86266: 2721, 86390: 2722, 86279: 2723, 86294: 2724, 61496: 2725, 61655: 2726, 61616: 2727, 61703: 2728, 61484: 2729, 61565: 2730, 61595: 2731, 61643: 2732, 61640: 2733, 61661: 2734, 61634: 2735, 61682: 2736, 61568: 2737, 61625: 2738, 61532: 2739, 61622: 2740, 61499: 2741, 61526: 2742, 61649: 2743, 61583: 2744, 61520: 2745, 61673: 2746, 61562: 2747, 61592: 2748, 61691: 2749, 61544: 2750, 61694: 2751, 61460: 2752, 61607: 2753, 61631: 2754, 61610: 2755, 61493: 2756, 61580: 2757, 61664: 2758, 61469: 2759, 61517: 2760, 61589: 2761, 61535: 2762, 61652: 2763, 61451: 2764, 61448: 2765, 61529: 2766, 61466: 2767, 61658: 2768, 61628: 2769, 61547: 2770, 61541: 2771, 61598: 2772, 61577: 2773, 61601: 2774, 61685: 2775, 61553: 2776, 61487: 2777, 61559: 2778, 120305: 2779, 120289: 2780, 120285: 2781, 120309: 2782, 120188: 2783, 120224: 2784, 120333: 2785, 120329: 2786, 120277: 2787, 120293: 2788, 120261: 2789, 120281: 2790, 120269: 2791, 120196: 2792, 120164: 2793, 120156: 2794, 120232: 2795, 120204: 2796, 120172: 2797, 120200: 2798, 120208: 2799, 120176: 2800, 120301: 2801, 120273: 2802, 120313: 2803, 120317: 2804, 120212: 2805, 120228: 2806, 120297: 2807, 120257: 2808, 120321: 2809, 120265: 2810, 120216: 2811, 120325: 2812, 120192: 2813, 120180: 2814, 120220: 2815, 120168: 2816, 120160: 2817, 120184: 2818, 85273: 2819, 85265: 2820, 85268: 2821, 85343: 2822, 84731: 2823, 85264: 2824, 84736: 2825, 85272: 2826, 85335: 2827, 58790: 2828, 51595: 2829, 58773: 2830, 58779: 2831, 58768: 2832, 51621: 2833, 58775: 2834, 51574: 2835, 58791: 2836, 51628: 2837, 51591: 2838, 51576: 2839, 58771: 2840, 51597: 2841, 51589: 2842, 51613: 2843, 51572: 2844, 51616: 2845, 51601: 2846, 51629: 2847, 51592: 2848, 58780: 2849, 58777: 2850, 51636: 2851, 51598: 2852, 58774: 2853, 58796: 2854, 51625: 2855, 58778: 2856, 58784: 2857, 51580: 2858, 58770: 2859, 51615: 2860, 51634: 2861, 51620: 2862, 51579: 2863, 58769: 2864, 51577: 2865, 58788: 2866, 51600: 2867, 58794: 2868, 51588: 2869, 51596: 2870, 51618: 2871, 51639: 2872, 51594: 2873, 51590: 2874, 58793: 2875, 58782: 2876, 51619: 2877, 58776: 2878, 51626: 2879, 58787: 2880, 51617: 2881, 51638: 2882, 51614: 2883, 51642: 2884, 51582: 2885, 51593: 2886, 51640: 2887, 51637: 2888, 51623: 2889, 51573: 2890, 51627: 2891, 51586: 2892, 58792: 2893, 58795: 2894, 58772: 2895, 51578: 2896, 51622: 2897, 51599: 2898, 51635: 2899, 51581: 2900, 58781: 2901, 51632: 2902, 51575: 2903, 51585: 2904, 51633: 2905, 51630: 2906, 51583: 2907, 90691: 2908, 90969: 2909, 90999: 2910, 91039: 2911, 90981: 2912, 90993: 2913, 90975: 2914, 90976: 2915, 91022: 2916, 91042: 2917, 91036: 2918, 91019: 2919, 91032: 2920, 91031: 2921, 91040: 2922, 90987: 2923, 91011: 2924, 90968: 2925, 91017: 2926, 91579: 2927, 91028: 2928, 91600: 2929, 91581: 2930, 91035: 2931, 91043: 2932, 91009: 2933, 91599: 2934, 90974: 2935, 90989: 2936, 91594: 2937, 90973: 2938, 90986: 2939, 90972: 2940, 90990: 2941, 91024: 2942, 91595: 2943, 91010: 2944, 91596: 2945, 91001: 2946, 91580: 2947, 91033: 2948, 90996: 2949, 91572: 2950, 91038: 2951, 91027: 2952, 91012: 2953, 91573: 2954, 91598: 2955, 90967: 2956, 90991: 2957, 91025: 2958, 91575: 2959, 90992: 2960, 91601: 2961, 91002: 2962, 91026: 2963, 90984: 2964, 91003: 2965, 90985: 2966, 91015: 2967, 91578: 2968, 91020: 2969, 90995: 2970, 91007: 2971, 90982: 2972, 91018: 2973, 90980: 2974, 90998: 2975, 91034: 2976, 91045: 2977, 90970: 2978, 90983: 2979, 91023: 2980, 91013: 2981, 91044: 2982, 90988: 2983, 91030: 2984, 91014: 2985, 91006: 2986, 91602: 2987, 90952: 2988, 90863: 2989, 90910: 2990, 90957: 2991, 91627: 2992, 90852: 2993, 90912: 2994, 91622: 2995, 91610: 2996, 90922: 2997, 91637: 2998, 90950: 2999, 90941: 3000, 91621: 3001, 90947: 3002, 90913: 3003, 90965: 3004, 91618: 3005, 90959: 3006, 90955: 3007, 90861: 3008, 90936: 3009, 90864: 3010, 90926: 3011, 91603: 3012, 90920: 3013, 91620: 3014, 90843: 3015, 91604: 3016, 59674: 3017, 59677: 3018, 59714: 3019, 59717: 3020, 59676: 3021, 59716: 3022, 107965: 3023, 93328: 3024, 93315: 3025, 93307: 3026, 93324: 3027, 93316: 3028, 93309: 3029, 93314: 3030, 59675: 3031, 59715: 3032, 166545: 3033, 166552: 3034, 166548: 3035, 166547: 3036, 166550: 3037, 166386: 3038, 166551: 3039, 166554: 3040, 166380: 3041, 166387: 3042, 166385: 3043, 166553: 3044, 166384: 3045, 166382: 3046, 166383: 3047, 166389: 3048, 166381: 3049, 166549: 3050, 166388: 3051, 147408: 3052, 147394: 3053, 147434: 3054, 147400: 3055, 147378: 3056, 147465: 3057, 147453: 3058, 147447: 3059, 147462: 3060, 147398: 3061, 147448: 3062, 147382: 3063, 147388: 3064, 147456: 3065, 147436: 3066, 88558: 3067, 88610: 3068, 88508: 3069, 88531: 3070, 88521: 3071, 88541: 3072, 88624: 3073, 147432: 3074, 147429: 3075, 147433: 3076, 147439: 3077, 147430: 3078, 147471: 3079, 147454: 3080, 147380: 3081, 147435: 3082, 147466: 3083, 147440: 3084, 147475: 3085, 88594: 3086, 147442: 3087, 147474: 3088, 147391: 3089, 147427: 3090, 147407: 3091, 147387: 3092, 147410: 3093, 147385: 3094, 147399: 3095, 147463: 3096, 147426: 3097, 147459: 3098, 147383: 3099, 147441: 3100, 147464: 3101, 147445: 3102, 147419: 3103, 147392: 3104, 147414: 3105, 147401: 3106, 147473: 3107, 147384: 3108, 147457: 3109, 147425: 3110, 147431: 3111, 147469: 3112, 88520: 3113, 88544: 3114, 88625: 3115, 88533: 3116, 147406: 3117, 147403: 3118, 88609: 3119, 88603: 3120, 88509: 3121, 88553: 3122, 88524: 3123, 88550: 3124, 88530: 3125, 88598: 3126, 88612: 3127, 88500: 3128, 88511: 3129, 88512: 3130, 88617: 3131, 88537: 3132, 88599: 3133, 147420: 3134, 147428: 3135, 147449: 3136, 147377: 3137, 147393: 3138, 88526: 3139, 88615: 3140, 88620: 3141, 88534: 3142, 88611: 3143, 88522: 3144, 88555: 3145, 88503: 3146, 147422: 3147, 147455: 3148, 147467: 3149, 147452: 3150, 147458: 3151, 147405: 3152, 147390: 3153, 147443: 3154, 147470: 3155, 88505: 3156, 88497: 3157, 147461: 3158, 147411: 3159, 147376: 3160, 147468: 3161, 147421: 3162, 88626: 3163, 88527: 3164, 88543: 3165, 88546: 3166, 88600: 3167, 88557: 3168, 88510: 3169, 147437: 3170, 147472: 3171, 147451: 3172, 88535: 3173, 88623: 3174, 88504: 3175, 53931: 3176, 53841: 3177, 53843: 3178, 53865: 3179, 53875: 3180, 53897: 3181, 53911: 3182, 53878: 3183, 53837: 3184, 53925: 3185, 53880: 3186, 53900: 3187, 53962: 3188, 53850: 3189, 53966: 3190, 53893: 3191, 53866: 3192, 53927: 3193, 53845: 3194, 53963: 3195, 89717: 3196, 53940: 3197, 89711: 3198, 53898: 3199, 84894: 3200, 53906: 3201, 89742: 3202, 84906: 3203, 89724: 3204, 89703: 3205, 89715: 3206, 84900: 3207, 89725: 3208, 89663: 3209, 89707: 3210, 89756: 3211, 89702: 3212, 89752: 3213, 89666: 3214, 53907: 3215, 84889: 3216, 84891: 3217, 53863: 3218, 89946: 3219, 89736: 3220, 53899: 3221, 53965: 3222, 53901: 3223, 53960: 3224, 84908: 3225, 89716: 3226, 53967: 3227, 54031: 3228, 54087: 3229, 54067: 3230, 53991: 3231, 53995: 3232, 54027: 3233, 54043: 3234, 54011: 3235, 54063: 3236, 54071: 3237, 54035: 3238, 54015: 3239, 54059: 3240, 54099: 3241, 53999: 3242, 54083: 3243, 54095: 3244, 54091: 3245, 54075: 3246, 54003: 3247, 54023: 3248, 53983: 3249, 54019: 3250, 54039: 3251, 147288: 3252, 147297: 3253, 147283: 3254, 147286: 3255, 147303: 3256, 147304: 3257, 147298: 3258, 147308: 3259, 147285: 3260, 53987: 3261, 147309: 3262, 147301: 3263, 147282: 3264, 147281: 3265, 147291: 3266, 147306: 3267, 147296: 3268, 147302: 3269, 147300: 3270, 147280: 3271, 147307: 3272, 147295: 3273, 147293: 3274, 147287: 3275, 147284: 3276, 147289: 3277, 147290: 3278, 147292: 3279, 54055: 3280, 147299: 3281, 147294: 3282, 54047: 3283, 147305: 3284, 54454: 3285, 54541: 3286, 54517: 3287, 54590: 3288, 54574: 3289, 54592: 3290, 54370: 3291, 54578: 3292, 54223: 3293, 54455: 3294, 54608: 3295, 54567: 3296, 54505: 3297, 54427: 3298, 54457: 3299, 54566: 3300, 54456: 3301, 54453: 3302, 54459: 3303, 54451: 3304, 54609: 3305, 54458: 3306, 54449: 3307, 54450: 3308, 54460: 3309, 54462: 3310, 54452: 3311, 54508: 3312, 54277: 3313, 54496: 3314, 54319: 3315, 54196: 3316, 54202: 3317, 54235: 3318, 54603: 3319, 54169: 3320, 54588: 3321, 54199: 3322, 54445: 3323, 54523: 3324, 54259: 3325, 54448: 3326, 54461: 3327, 54447: 3328, 54433: 3329, 54559: 3330, 54352: 3331, 54575: 3332, 54283: 3333, 54444: 3334, 54502: 3335, 54406: 3336, 54424: 3337, 54446: 3338, 54598: 3339, 54262: 3340, 54481: 3341, 54232: 3342, 54520: 3343, 54564: 3344, 54271: 3345, 54295: 3346, 54385: 3347, 54596: 3348, 54529: 3349, 54304: 3350, 54612: 3351, 54604: 3352, 54584: 3353, 54561: 3354, 54388: 3355, 54526: 3356, 54358: 3357, 54553: 3358, 54265: 3359, 54600: 3360, 54563: 3361, 54597: 3362, 54292: 3363, 54591: 3364, 54430: 3365, 54490: 3366, 54514: 3367, 54572: 3368, 54585: 3369, 54250: 3370, 54247: 3371, 54583: 3372, 54568: 3373, 54562: 3374, 54582: 3375, 54289: 3376, 54586: 3377, 54569: 3378, 54511: 3379, 54208: 3380, 54349: 3381, 54211: 3382, 54193: 3383, 54334: 3384, 54217: 3385, 54560: 3386, 54175: 3387, 54579: 3388, 54499: 3389, 54538: 3390, 54268: 3391, 54475: 3392, 54593: 3393, 54570: 3394, 54605: 3395, 54412: 3396, 90664: 3397, 90010: 3398, 90232: 3399, 90172: 3400, 90040: 3401, 90371: 3402, 90359: 3403, 90183: 3404, 90362: 3405, 90234: 3406, 54409: 3407, 90058: 3408, 90443: 3409, 90347: 3410, 54610: 3411, 90173: 3412, 90575: 3413, 54313: 3414, 54421: 3415, 90186: 3416, 90470: 3417, 54310: 3418, 54382: 3419, 90380: 3420, 90046: 3421, 54577: 3422, 90239: 3423, 90703: 3424, 54397: 3425, 54205: 3426, 90498: 3427, 90231: 3428, 53801: 3429, 58814: 3430, 53785: 3431, 53775: 3432, 53792: 3433, 53791: 3434, 53786: 3435, 53789: 3436, 58822: 3437, 53774: 3438, 58821: 3439, 58800: 3440, 58812: 3441, 53790: 3442, 53777: 3443, 58804: 3444, 58823: 3445, 53779: 3446, 58805: 3447, 53794: 3448, 58818: 3449, 53788: 3450, 58815: 3451, 53776: 3452, 53795: 3453, 147337: 3454, 147360: 3455, 147345: 3456, 147352: 3457, 147331: 3458, 147346: 3459, 147354: 3460, 147340: 3461, 147350: 3462, 147330: 3463, 147359: 3464, 147343: 3465, 147356: 3466, 147365: 3467, 58808: 3468, 58827: 3469, 53799: 3470, 53784: 3471, 147368: 3472, 147341: 3473, 147353: 3474, 147313: 3475, 147324: 3476, 147348: 3477, 58820: 3478, 147326: 3479, 147325: 3480, 147312: 3481, 147364: 3482, 147367: 3483, 147344: 3484, 58816: 3485, 147339: 3486, 147363: 3487, 147315: 3488, 147355: 3489, 147336: 3490, 147370: 3491, 147320: 3492, 147329: 3493, 147351: 3494, 147333: 3495, 147347: 3496, 147318: 3497, 53802: 3498, 147332: 3499, 147317: 3500, 147366: 3501, 147342: 3502, 147334: 3503, 58807: 3504, 53797: 3505, 147369: 3506, 147358: 3507, 147327: 3508, 147322: 3509, 147319: 3510, 58809: 3511, 147361: 3512, 147338: 3513, 147314: 3514, 147323: 3515, 147362: 3516, 147328: 3517, 147349: 3518, 147321: 3519, 147371: 3520, 53783: 3521, 53782: 3522, 53778: 3523, 58819: 3524, 58826: 3525, 58803: 3526, 58813: 3527, 58801: 3528, 86528: 3529, 86727: 3530, 86452: 3531, 86535: 3532, 86359: 3533, 86550: 3534, 86543: 3535, 86527: 3536, 86554: 3537, 86544: 3538, 86729: 3539, 86605: 3540, 86611: 3541, 86546: 3542, 86728: 3543, 86312: 3544, 86330: 3545, 86750: 3546, 86311: 3547, 86662: 3548, 86579: 3549, 86648: 3550, 86608: 3551, 86746: 3552, 86725: 3553, 86745: 3554, 86670: 3555, 86548: 3556, 86741: 3557, 86627: 3558, 86513: 3559, 86540: 3560, 86360: 3561, 86326: 3562, 86751: 3563, 86754: 3564, 86455: 3565, 86577: 3566, 77544: 3567, 77545: 3568, 77546: 3569, 77547: 3570, 77548: 3571, 77549: 3572, 77550: 3573, 77551: 3574, 77444: 3575, 77472: 3576, 77473: 3577, 77474: 3578, 77475: 3579, 77445: 3580, 77446: 3581, 77447: 3582, 77480: 3583, 77481: 3584, 77482: 3585, 77483: 3586, 77512: 3587, 77513: 3588, 77514: 3589, 77515: 3590, 77532: 3591, 77533: 3592, 77534: 3593, 77535: 3594, 77484: 3595, 77485: 3596, 77486: 3597, 77487: 3598, 77520: 3599, 77521: 3600, 77522: 3601, 77523: 3602, 77528: 3603, 77529: 3604, 77530: 3605, 77531: 3606, 77440: 3607, 77441: 3608, 77442: 3609, 77443: 3610, 77524: 3611, 77525: 3612, 77526: 3613, 77527: 3614, 76203: 3615, 76204: 3616, 76205: 3617, 76206: 3618, 76207: 3619, 76208: 3620, 76209: 3621, 76210: 3622, 76339: 3623, 76340: 3624, 76341: 3625, 76342: 3626, 76343: 3627, 76344: 3628, 76346: 3629, 76349: 3630, 76243: 3631, 76244: 3632, 76245: 3633, 76246: 3634, 76247: 3635, 76248: 3636, 76249: 3637, 76250: 3638, 76387: 3639, 76388: 3640, 76389: 3641, 76390: 3642, 76391: 3643, 76392: 3644, 76393: 3645, 76396: 3646, 76374: 3647, 76375: 3648, 76377: 3649, 76380: 3650, 76382: 3651, 76384: 3652, 76385: 3653, 76386: 3654, 76219: 3655, 76220: 3656, 76221: 3657, 76222: 3658, 76223: 3659, 76224: 3660, 76225: 3661, 76226: 3662, 76275: 3663, 76276: 3664, 76277: 3665, 76278: 3666, 76279: 3667, 76280: 3668, 76281: 3669, 76282: 3670, 76315: 3671, 76316: 3672, 76317: 3673, 76318: 3674, 76319: 3675, 76320: 3676, 76321: 3677, 76322: 3678, 76235: 3679, 76236: 3680, 76237: 3681, 76238: 3682, 76239: 3683, 76240: 3684, 76241: 3685, 76242: 3686, 75332: 3687, 75309: 3688, 90209: 3689, 75335: 3690, 75318: 3691, 75313: 3692, 75330: 3693, 75326: 3694, 75315: 3695, 75325: 3696, 75322: 3697, 75319: 3698, 75314: 3699, 75333: 3700, 75334: 3701, 75337: 3702, 75316: 3703, 51213: 3704, 51183: 3705, 66855: 3706, 66804: 3707, 66805: 3708, 66806: 3709, 66822: 3710, 66823: 3711, 66824: 3712, 51171: 3713, 66840: 3714, 66841: 3715, 66842: 3716, 51177: 3717, 66849: 3718, 66828: 3719, 66792: 3720, 66846: 3721, 66798: 3722, 66825: 3723, 66826: 3724, 66827: 3725, 51138: 3726, 51156: 3727, 66858: 3728, 66859: 3729, 66860: 3730, 66837: 3731, 66838: 3732, 66839: 3733, 51189: 3734, 66864: 3735, 66865: 3736, 66866: 3737, 66786: 3738, 66787: 3739, 66788: 3740, 51192: 3741, 66831: 3742, 66819: 3743, 51198: 3744, 66820: 3745, 51153: 3746, 66847: 3747, 66848: 3748, 66807: 3749, 51150: 3750, 51180: 3751, 51210: 3752, 66795: 3753, 66796: 3754, 66797: 3755, 66799: 3756, 66800: 3757, 51162: 3758, 51132: 3759, 51135: 3760, 51186: 3761, 84614: 3762, 84615: 3763, 66793: 3764, 66794: 3765, 66783: 3766, 51195: 3767, 84597: 3768, 84598: 3769, 84594: 3770, 84616: 3771, 51219: 3772, 66870: 3773, 85112: 3774, 84980: 3775, 84996: 3776, 84613: 3777, 66829: 3778, 66830: 3779, 66801: 3780, 66861: 3781, 84601: 3782, 84610: 3783, 66813: 3784, 66852: 3785, 51141: 3786, 85113: 3787, 84981: 3788, 84988: 3789, 66862: 3790, 66863: 3791, 51201: 3792, 66843: 3793, 66844: 3794, 66845: 3795, 51165: 3796, 84618: 3797, 84589: 3798, 66871: 3799, 66872: 3800, 66834: 3801, 66835: 3802, 66836: 3803, 66789: 3804, 66790: 3805, 66791: 3806, 51147: 3807, 66810: 3808, 66811: 3809, 66812: 3810, 66821: 3811, 51168: 3812, 66802: 3813, 66803: 3814, 51159: 3815, 66832: 3816, 66833: 3817, 66856: 3818, 66857: 3819, 66867: 3820, 66868: 3821, 66869: 3822, 51144: 3823, 66850: 3824, 66851: 3825, 66808: 3826, 66809: 3827, 51204: 3828, 51174: 3829, 51216: 3830, 66816: 3831, 66784: 3832, 66785: 3833, 66853: 3834, 66854: 3835, 66814: 3836, 66815: 3837, 51207: 3838, 84987: 3839, 84991: 3840, 84602: 3841, 85117: 3842, 84599: 3843, 84990: 3844, 84617: 3845, 66817: 3846, 66818: 3847, 85118: 3848, 84590: 3849, 51012: 3850, 51005: 3851, 51112: 3852, 51113: 3853, 51114: 3854, 51115: 3855, 51016: 3856, 51124: 3857, 51125: 3858, 51126: 3859, 51127: 3860, 51100: 3861, 51101: 3862, 51102: 3863, 51103: 3864, 50985: 3865, 51007: 3866, 50989: 3867, 50993: 3868, 50994: 3869, 50982: 3870, 51044: 3871, 50997: 3872, 50984: 3873, 50995: 3874, 51064: 3875, 51001: 3876, 51116: 3877, 51117: 3878, 51118: 3879, 51119: 3880, 51084: 3881, 51085: 3882, 51003: 3883, 51086: 3884, 51087: 3885, 51040: 3886, 51076: 3887, 51108: 3888, 51004: 3889, 50990: 3890, 51120: 3891, 51121: 3892, 51122: 3893, 51123: 3894, 51109: 3895, 51110: 3896, 51111: 3897, 51028: 3898, 50986: 3899, 50991: 3900, 51052: 3901, 51053: 3902, 51054: 3903, 51055: 3904, 51104: 3905, 51105: 3906, 51106: 3907, 51107: 3908, 51068: 3909, 50988: 3910, 51011: 3911, 50992: 3912, 51088: 3913, 51089: 3914, 51090: 3915, 51091: 3916, 51065: 3917, 51066: 3918, 51067: 3919, 51024: 3920, 51025: 3921, 51026: 3922, 51027: 3923, 51048: 3924, 51020: 3925, 51000: 3926, 50987: 3927, 51060: 3928, 51009: 3929, 50999: 3930, 51002: 3931, 51045: 3932, 51046: 3933, 51047: 3934, 50983: 3935, 50996: 3936, 50998: 3937, 51010: 3938, 51032: 3939, 51033: 3940, 51034: 3941, 51035: 3942, 51096: 3943, 51061: 3944, 51062: 3945, 51063: 3946, 51077: 3947, 51078: 3948, 51079: 3949, 51072: 3950, 51073: 3951, 51074: 3952, 51075: 3953, 51069: 3954, 51070: 3955, 51071: 3956, 51080: 3957, 51041: 3958, 51042: 3959, 51043: 3960, 85068: 3961, 84638: 3962, 85046: 3963, 51092: 3964, 51006: 3965, 51008: 3966, 85080: 3967, 85086: 3968, 85019: 3969, 85056: 3970, 85028: 3971, 85034: 3972, 51021: 3973, 51022: 3974, 51023: 3975, 51056: 3976, 51057: 3977, 51058: 3978, 51059: 3979, 51128: 3980, 84632: 3981, 84647: 3982, 85043: 3983, 85077: 3984, 84629: 3985, 51036: 3986, 85065: 3987, 84650: 3988, 85074: 3989, 51037: 3990, 51038: 3991, 51039: 3992, 84641: 3993, 85062: 3994, 51029: 3995, 51030: 3996, 51031: 3997, 51093: 3998, 51094: 3999, 51095: 4000, 51081: 4001, 51082: 4002, 51083: 4003, 51097: 4004, 51098: 4005, 51099: 4006, 51049: 4007, 51050: 4008, 51051: 4009, 85025: 4010, 84656: 4011, 84644: 4012, 51129: 4013, 51130: 4014, 51131: 4015, 97575: 4016, 97659: 4017, 97691: 4018, 97723: 4019, 97715: 4020, 97747: 4021, 97607: 4022, 97679: 4023, 97563: 4024, 97564: 4025, 97565: 4026, 97566: 4027, 97655: 4028, 97567: 4029, 97675: 4030, 97603: 4031, 97539: 4032, 97551: 4033, 97671: 4034, 97623: 4035, 97579: 4036, 97719: 4037, 97707: 4038, 97660: 4039, 97661: 4040, 97662: 4041, 97611: 4042, 97663: 4043, 97743: 4044, 97744: 4045, 97745: 4046, 97746: 4047, 97643: 4048, 97595: 4049, 97591: 4050, 97583: 4051, 97650: 4052, 97751: 4053, 97752: 4054, 97753: 4055, 97754: 4056, 97739: 4057, 97763: 4058, 97687: 4059, 97731: 4060, 97724: 4061, 97725: 4062, 97726: 4063, 97540: 4064, 97541: 4065, 97542: 4066, 97619: 4067, 97711: 4068, 97555: 4069, 97767: 4070, 97683: 4071, 97627: 4072, 97695: 4073, 97639: 4074, 97571: 4075, 97572: 4076, 97573: 4077, 97574: 4078, 97631: 4079, 97692: 4080, 97547: 4081, 97548: 4082, 97549: 4083, 97550: 4084, 97535: 4085, 97699: 4086, 97584: 4087, 97585: 4088, 97586: 4089, 97531: 4090, 97580: 4091, 97581: 4092, 97582: 4093, 97667: 4094, 87889: 4095, 87863: 4096, 87885: 4097, 87700: 4098, 87741: 4099, 87809: 4100, 88354: 4101, 88391: 4102, 88344: 4103, 88294: 4104, 88299: 4105, 88341: 4106, 88380: 4107, 88324: 4108, 88367: 4109, 88395: 4110, 88352: 4111, 88331: 4112, 88350: 4113, 88349: 4114, 88387: 4115, 88332: 4116, 88386: 4117, 88301: 4118, 88362: 4119, 88308: 4120, 88293: 4121, 88363: 4122, 88339: 4123, 88321: 4124, 88351: 4125, 107872: 4126, 107873: 4127, 87611: 4128, 87547: 4129, 87491: 4130, 87477: 4131, 87495: 4132, 87578: 4133, 87623: 4134, 87551: 4135, 87476: 4136, 87902: 4137, 87991: 4138, 87916: 4139, 88035: 4140, 88032: 4141, 88109: 4142, 88185: 4143, 88173: 4144, 88097: 4145, 88190: 4146, 107874: 4147, 107875: 4148, 107731: 4149, 107696: 4150, 107700: 4151, 107701: 4152, 107702: 4153, 107745: 4154, 107738: 4155, 107710: 4156, 107865: 4157, 107781: 4158, 87837: 4159, 87990: 4160, 88010: 4161, 87925: 4162, 87958: 4163, 87906: 4164, 87922: 4165, 87572: 4166, 87528: 4167, 87542: 4168, 87490: 4169, 87499: 4170, 88191: 4171, 88140: 4172, 88137: 4173, 88189: 4174, 88143: 4175, 88156: 4176, 88153: 4177, 107844: 4178, 107845: 4179, 88346: 4180, 88359: 4181, 88311: 4182, 88320: 4183, 88333: 4184, 87719: 4185, 87891: 4186, 87701: 4187, 87694: 4188, 88292: 4189, 88318: 4190, 88335: 4191, 107846: 4192, 107847: 4193, 107788: 4194, 107749: 4195, 107750: 4196, 107751: 4197, 107809: 4198, 107830: 4199, 107753: 4200, 107837: 4201, 87764: 4202, 87836: 4203, 87884: 4204, 87816: 4205, 87872: 4206, 87715: 4207, 87839: 4208, 87734: 4209, 88291: 4210, 88390: 4211, 88315: 4212, 88309: 4213, 88368: 4214, 87718: 4215, 87780: 4216, 87766: 4217, 87713: 4218, 87717: 4219, 87803: 4220, 87740: 4221, 87815: 4222, 87698: 4223, 87697: 4224, 87699: 4225, 87838: 4226, 87693: 4227, 87883: 4228, 87739: 4229, 87813: 4230, 87835: 4231, 87886: 4232, 87864: 4233, 87716: 4234, 88394: 4235, 88288: 4236, 88347: 4237, 88323: 4238, 107681: 4239, 107760: 4240, 107667: 4241, 107823: 4242, 107827: 4243, 107828: 4244, 107829: 4245, 107858: 4246, 107782: 4247, 107783: 4248, 107784: 4249, 107767: 4250, 107774: 4251, 107717: 4252, 87508: 4253, 87627: 4254, 87573: 4255, 87506: 4256, 87549: 4257, 87605: 4258, 87624: 4259, 88162: 4260, 88188: 4261, 88106: 4262, 88165: 4263, 88127: 4264, 88141: 4265, 88092: 4266, 88175: 4267, 88187: 4268, 87996: 4269, 88041: 4270, 87946: 4271, 87912: 4272, 87993: 4273, 88029: 4274, 87928: 4275, 87955: 4276, 88100: 4277, 88125: 4278, 88098: 4279, 88147: 4280, 88093: 4281, 88128: 4282, 88119: 4283, 88110: 4284, 88178: 4285, 88180: 4286, 88118: 4287, 88124: 4288, 88182: 4289, 88105: 4290, 88160: 4291, 88120: 4292, 88101: 4293, 88149: 4294, 87812: 4295, 87834: 4296, 87805: 4297, 87768: 4298, 88357: 4299, 88385: 4300, 88295: 4301, 88365: 4302, 88329: 4303, 107724: 4304, 87615: 4305, 87503: 4306, 87498: 4307, 87628: 4308, 87602: 4309, 88103: 4310, 88161: 4311, 87977: 4312, 87935: 4313, 87903: 4314, 87841: 4315, 87833: 4316, 87810: 4317, 87804: 4318, 87822: 4319, 87722: 4320, 87736: 4321, 88302: 4322, 88322: 4323, 88337: 4324, 88306: 4325, 87720: 4326, 87890: 4327, 88340: 4328, 88310: 4329, 88345: 4330, 107816: 4331, 107817: 4332, 107818: 4333, 107819: 4334, 107732: 4335, 107733: 4336, 107734: 4337, 107848: 4338, 107849: 4339, 107850: 4340, 107714: 4341, 107715: 4342, 107716: 4343, 107841: 4344, 107842: 4345, 107843: 4346, 107785: 4347, 107786: 4348, 107787: 4349, 107778: 4350, 107779: 4351, 107780: 4352, 107792: 4353, 107793: 4354, 107794: 4355, 107689: 4356, 87525: 4357, 87530: 4358, 87574: 4359, 87630: 4360, 87485: 4361, 87620: 4362, 87581: 4363, 87553: 4364, 87616: 4365, 87577: 4366, 88117: 4367, 88096: 4368, 88151: 4369, 88018: 4370, 87970: 4371, 88011: 4372, 87473: 4373, 87501: 4374, 87504: 4375, 87509: 4376, 87543: 4377, 87555: 4378, 87507: 4379, 87575: 4380, 87475: 4381, 87603: 4382, 87580: 4383, 87479: 4384, 87478: 4385, 87765: 4386, 87869: 4387, 87866: 4388, 88298: 4389, 87892: 4390, 88305: 4391, 88389: 4392, 88355: 4393, 88366: 4394, 88296: 4395, 107703: 4396, 107704: 4397, 107705: 4398, 107706: 4399, 107810: 4400, 107811: 4401, 107812: 4402, 107728: 4403, 107729: 4404, 107730: 4405, 107795: 4406, 107799: 4407, 107800: 4408, 107801: 4409, 107838: 4410, 107839: 4411, 107840: 4412, 107697: 4413, 107698: 4414, 107699: 4415, 87607: 4416, 87558: 4417, 87621: 4418, 88146: 4419, 88090: 4420, 88133: 4421, 88111: 4422, 88112: 4423, 87926: 4424, 87940: 4425, 87950: 4426, 87951: 4427, 87489: 4428, 87500: 4429, 107802: 4430, 107806: 4431, 107807: 4432, 107808: 4433, 107851: 4434, 107855: 4435, 107856: 4436, 107857: 4437, 107831: 4438, 107832: 4439, 107833: 4440, 87868: 4441, 87820: 4442, 88336: 4443, 88383: 4444, 88319: 4445, 88327: 4446, 88353: 4447, 88334: 4448, 107674: 4449, 87608: 4450, 88134: 4451, 88148: 4452, 88132: 4453, 88183: 4454, 87924: 4455, 87929: 4456, 87943: 4457, 88037: 4458, 87992: 4459, 87818: 4460, 88290: 4461, 88392: 4462, 107721: 4463, 107722: 4464, 107723: 4465, 87556: 4466, 87579: 4467, 87472: 4468, 88176: 4469, 88139: 4470, 87994: 4471, 87927: 4472, 87932: 4473, 88009: 4474, 97735: 4475, 87629: 4476, 87613: 4477, 87763: 4478, 87887: 4479, 87721: 4480, 87807: 4481, 88297: 4482, 88304: 4483, 88384: 4484, 88326: 4485, 88388: 4486, 88313: 4487, 88369: 4488, 88300: 4489, 88289: 4490, 107852: 4491, 107853: 4492, 107854: 4493, 107859: 4494, 107860: 4495, 107861: 4496, 107876: 4497, 107877: 4498, 107878: 4499, 107768: 4500, 107769: 4501, 107770: 4502, 87510: 4503, 87523: 4504, 87492: 4505, 87526: 4506, 107675: 4507, 107676: 4508, 107677: 4509, 107824: 4510, 107825: 4511, 107826: 4512, 107668: 4513, 107669: 4514, 107670: 4515, 107739: 4516, 107740: 4517, 107741: 4518, 88138: 4519, 88154: 4520, 88123: 4521, 87945: 4522, 87907: 4523, 87941: 4524, 107685: 4525, 107686: 4526, 107687: 4527, 107761: 4528, 107762: 4529, 107763: 4530, 88356: 4531, 88328: 4532, 88343: 4533, 88314: 4534, 88393: 4535, 88370: 4536, 87502: 4537, 87480: 4538, 88099: 4539, 88113: 4540, 87937: 4541, 87978: 4542, 88107: 4543, 108127: 4544, 107990: 4545, 108102: 4546, 107985: 4547, 121931: 4548, 121976: 4549, 121951: 4550, 122001: 4551, 121928: 4552, 121936: 4553, 121943: 4554, 121939: 4555, 121917: 4556, 121964: 4557, 121966: 4558, 121967: 4559, 167341: 4560, 167369: 4561, 167326: 4562, 167331: 4563, 167307: 4564, 167302: 4565, 167335: 4566, 167330: 4567, 167349: 4568, 167329: 4569, 167371: 4570, 167350: 4571, 167340: 4572, 167325: 4573, 167356: 4574, 167292: 4575, 167306: 4576, 167320: 4577, 167367: 4578, 167332: 4579, 167377: 4580, 167372: 4581, 167316: 4582, 167324: 4583, 167309: 4584, 167321: 4585, 167299: 4586, 167293: 4587, 167315: 4588, 167295: 4589, 167381: 4590, 167319: 4591, 167366: 4592, 167344: 4593, 167328: 4594, 167312: 4595, 167378: 4596, 167355: 4597, 167357: 4598, 167297: 4599, 167313: 4600, 167327: 4601, 167311: 4602, 167336: 4603, 167294: 4604, 167362: 4605, 167380: 4606, 167310: 4607, 167353: 4608, 167347: 4609, 167314: 4610, 167375: 4611, 167317: 4612, 167376: 4613, 167305: 4614, 167379: 4615, 167345: 4616, 167360: 4617, 167298: 4618, 167342: 4619, 167308: 4620, 167354: 4621, 167346: 4622, 167301: 4623, 167374: 4624, 167359: 4625, 167351: 4626, 167352: 4627, 167361: 4628, 167364: 4629, 167304: 4630, 167339: 4631, 167334: 4632, 167370: 4633, 167333: 4634, 167373: 4635, 167338: 4636, 167300: 4637, 167363: 4638, 167337: 4639, 167358: 4640, 167322: 4641, 167343: 4642, 167318: 4643, 167303: 4644, 59638: 4645, 59639: 4646, 59686: 4647, 59687: 4648, 59646: 4649, 59647: 4650, 59688: 4651, 59689: 4652, 59794: 4653, 59795: 4654, 59796: 4655, 59797: 4656, 59730: 4657, 59731: 4658, 59732: 4659, 59733: 4660, 59766: 4661, 59767: 4662, 59768: 4663, 59769: 4664, 59762: 4665, 59763: 4666, 59764: 4667, 59765: 4668, 59806: 4669, 59807: 4670, 59648: 4671, 59649: 4672, 59726: 4673, 59727: 4674, 59728: 4675, 59729: 4676, 59682: 4677, 59683: 4678, 59684: 4679, 59685: 4680, 59798: 4681, 59799: 4682, 59800: 4683, 59801: 4684, 59610: 4685, 59611: 4686, 59612: 4687, 59613: 4688, 59602: 4689, 59603: 4690, 59604: 4691, 59605: 4692, 59718: 4693, 59719: 4694, 59720: 4695, 59721: 4696, 59770: 4697, 59771: 4698, 59606: 4699, 59607: 4700, 59808: 4701, 59809: 4702, 59608: 4703, 59609: 4704, 59598: 4705, 59599: 4706, 59600: 4707, 59601: 4708, 59802: 4709, 59803: 4710, 59804: 4711, 59805: 4712, 59642: 4713, 59643: 4714, 59594: 4715, 59595: 4716, 59596: 4717, 59597: 4718, 59722: 4719, 59723: 4720, 59724: 4721, 59725: 4722, 59644: 4723, 59645: 4724, 59640: 4725, 59641: 4726, 59650: 4727, 59651: 4728, 59652: 4729, 59653: 4730, 59678: 4731, 59679: 4732, 59680: 4733, 59681: 4734, 59758: 4735, 59759: 4736, 59760: 4737, 59761: 4738, 59690: 4739, 59691: 4740, 59692: 4741, 59693: 4742, 59634: 4743, 59754: 4744, 59772: 4745, 59773: 4746, 59635: 4747, 59636: 4748, 59637: 4749, 59755: 4750, 59756: 4751, 59757: 4752, 134702: 4753, 134794: 4754, 134787: 4755, 134719: 4756, 134714: 4757, 134708: 4758, 134744: 4759, 134722: 4760, 134791: 4761, 134704: 4762, 134805: 4763, 134721: 4764, 134788: 4765, 134703: 4766, 134701: 4767, 134698: 4768, 134736: 4769, 134726: 4770, 134793: 4771, 134800: 4772, 134700: 4773, 134706: 4774, 134799: 4775, 134739: 4776, 134734: 4777, 134724: 4778, 134733: 4779, 134696: 4780, 134720: 4781, 134713: 4782, 160149: 4783, 160150: 4784, 160151: 4785, 160152: 4786, 160153: 4787, 160154: 4788, 160155: 4789, 160156: 4790, 160157: 4791, 160158: 4792, 160159: 4793, 160160: 4794, 160161: 4795, 160162: 4796, 160163: 4797, 160164: 4798, 160165: 4799, 160166: 4800, 160167: 4801, 160168: 4802, 160169: 4803, 160170: 4804, 160171: 4805, 160172: 4806, 160173: 4807, 160174: 4808, 160175: 4809, 160176: 4810, 160177: 4811, 160178: 4812, 160179: 4813, 160180: 4814, 160181: 4815, 160182: 4816, 160183: 4817, 134712: 4818, 134732: 4819, 134699: 4820, 161473: 4821, 161474: 4822, 161475: 4823, 161476: 4824, 161477: 4825, 161478: 4826, 161479: 4827, 161480: 4828, 161481: 4829, 161482: 4830, 161483: 4831, 161484: 4832, 161485: 4833, 161486: 4834, 161487: 4835, 161488: 4836, 161489: 4837, 161490: 4838, 161491: 4839, 161492: 4840, 161493: 4841, 160359: 4842, 160184: 4843, 160185: 4844, 160186: 4845, 160187: 4846, 160188: 4847, 160189: 4848, 160190: 4849, 160191: 4850, 160192: 4851, 160193: 4852, 160194: 4853, 160195: 4854, 160196: 4855, 160197: 4856, 160198: 4857, 160199: 4858, 160200: 4859, 160201: 4860, 160202: 4861, 160203: 4862, 160204: 4863, 160205: 4864, 160206: 4865, 160207: 4866, 160208: 4867, 160209: 4868, 160210: 4869, 134796: 4870, 134707: 4871, 134786: 4872, 160211: 4873, 160212: 4874, 160213: 4875, 160214: 4876, 160215: 4877, 160216: 4878, 160217: 4879, 160218: 4880, 160219: 4881, 160220: 4882, 160221: 4883, 160222: 4884, 160223: 4885, 160224: 4886, 134742: 4887, 161494: 4888, 160225: 4889, 160226: 4890, 160227: 4891, 160228: 4892, 160229: 4893, 160230: 4894, 160231: 4895, 160232: 4896, 160233: 4897, 160234: 4898, 160235: 4899, 160236: 4900, 160237: 4901, 160238: 4902, 160239: 4903, 160240: 4904, 160241: 4905, 160242: 4906, 160243: 4907, 160244: 4908, 160360: 4909, 160361: 4910, 160362: 4911, 160363: 4912, 160364: 4913, 160365: 4914, 160366: 4915, 160367: 4916, 160368: 4917, 160369: 4918, 160370: 4919, 160371: 4920, 160372: 4921, 160373: 4922, 160374: 4923, 160375: 4924, 160376: 4925, 160377: 4926, 160378: 4927, 160379: 4928, 160380: 4929, 134717: 4930, 134735: 4931, 134731: 4932, 134804: 4933, 134716: 4934, 134740: 4935, 134801: 4936, 134715: 4937, 134802: 4938, 134737: 4939, 128458: 4940, 128476: 4941, 128437: 4942, 128474: 4943, 128462: 4944, 128463: 4945, 128472: 4946, 128297: 4947, 128271: 4948, 128272: 4949, 128269: 4950, 128302: 4951, 128270: 4952, 128257: 4953, 128258: 4954, 128276: 4955, 128293: 4956, 128235: 4957, 128236: 4958, 128294: 4959, 128225: 4960, 128226: 4961, 128288: 4962, 128305: 4963, 128223: 4964, 128224: 4965, 128295: 4966, 128298: 4967, 128283: 4968, 128300: 4969, 128452: 4970, 128454: 4971, 128451: 4972, 128445: 4973, 128447: 4974, 128460: 4975, 128466: 4976, 128470: 4977, 128229: 4978, 128230: 4979, 128263: 4980, 128264: 4981, 128287: 4982, 128281: 4983, 128284: 4984, 128304: 4985, 128250: 4986, 128251: 4987, 128278: 4988, 128279: 4989, 128285: 4990, 128440: 4991, 128449: 4992, 128441: 4993, 128439: 4994, 128243: 4995, 128299: 4996, 128252: 4997, 128241: 4998, 128242: 4999, 128245: 5000, 128289: 5001, 128464: 5002, 128291: 5003, 128292: 5004, 128233: 5005, 128234: 5006, 128303: 5007, 128275: 5008, 128227: 5009, 128228: 5010, 128248: 5011, 128282: 5012, 113520: 5013, 113521: 5014, 113522: 5015, 113523: 5016, 113524: 5017, 113697: 5018, 113515: 5019, 113516: 5020, 113517: 5021, 113518: 5022, 113519: 5023, 113550: 5024, 113781: 5025, 113782: 5026, 113783: 5027, 113784: 5028, 113785: 5029, 113786: 5030, 113500: 5031, 113745: 5032, 113575: 5033, 113545: 5034, 113546: 5035, 113547: 5036, 113548: 5037, 113549: 5038, 113415: 5039, 113416: 5040, 113417: 5041, 113418: 5042, 113419: 5043, 113365: 5044, 113366: 5045, 113367: 5046, 113368: 5047, 113369: 5048, 113370: 5049, 113371: 5050, 113372: 5051, 113373: 5052, 113374: 5053, 113420: 5054, 113421: 5055, 113422: 5056, 113423: 5057, 113424: 5058, 113360: 5059, 113361: 5060, 113733: 5061, 113734: 5062, 113735: 5063, 113736: 5064, 113737: 5065, 113738: 5066, 113727: 5067, 113763: 5068, 113400: 5069, 113793: 5070, 113794: 5071, 113795: 5072, 113796: 5073, 113797: 5074, 113721: 5075, 113722: 5076, 113723: 5077, 113724: 5078, 113725: 5079, 113726: 5080, 113535: 5081, 113536: 5082, 113537: 5083, 113538: 5084, 113539: 5085, 113580: 5086, 113817: 5087, 113691: 5088, 113380: 5089, 113381: 5090, 113530: 5091, 113531: 5092, 113532: 5093, 113533: 5094, 113534: 5095, 113585: 5096, 113586: 5097, 113587: 5098, 113588: 5099, 113589: 5100, 113435: 5101, 113895: 5102, 113896: 5103, 113897: 5104, 113898: 5105, 113899: 5106, 113900: 5107, 113642: 5108, 113465: 5109, 113466: 5110, 113467: 5111, 113468: 5112, 113469: 5113, 113739: 5114, 113430: 5115, 113570: 5116, 113679: 5117, 113680: 5118, 113681: 5119, 113682: 5120, 113683: 5121, 113764: 5122, 113765: 5123, 113766: 5124, 113767: 5125, 113768: 5126, 113470: 5127, 113471: 5128, 113472: 5129, 113473: 5130, 113474: 5131, 113847: 5132, 113848: 5133, 113849: 5134, 113850: 5135, 113851: 5136, 113852: 5137, 113385: 5138, 113618: 5139, 113619: 5140, 113620: 5141, 113621: 5142, 113622: 5143, 113623: 5144, 113495: 5145, 113555: 5146, 113630: 5147, 113581: 5148, 113582: 5149, 113583: 5150, 113584: 5151, 113877: 5152, 113871: 5153, 113872: 5154, 113873: 5155, 113874: 5156, 113875: 5157, 113876: 5158, 113835: 5159, 113709: 5160, 113710: 5161, 113711: 5162, 113712: 5163, 113713: 5164, 113714: 5165, 113450: 5166, 113451: 5167, 113452: 5168, 113453: 5169, 113454: 5170, 113798: 5171, 113440: 5172, 113441: 5173, 113442: 5174, 113443: 5175, 113444: 5176, 113480: 5177, 113565: 5178, 113566: 5179, 113567: 5180, 113568: 5181, 113569: 5182, 113460: 5183, 113455: 5184, 113811: 5185, 113812: 5186, 113813: 5187, 113814: 5188, 113815: 5189, 113816: 5190, 113636: 5191, 113637: 5192, 113638: 5193, 113639: 5194, 113640: 5195, 113641: 5196, 113405: 5197, 113406: 5198, 113407: 5199, 113408: 5200, 113409: 5201, 113445: 5202, 113661: 5203, 113654: 5204, 113655: 5205, 113656: 5206, 113657: 5207, 113658: 5208, 113659: 5209, 113551: 5210, 113552: 5211, 113553: 5212, 113554: 5213, 113624: 5214, 113625: 5215, 113626: 5216, 113627: 5217, 113628: 5218, 113629: 5219, 113805: 5220, 113769: 5221, 113770: 5222, 113771: 5223, 113772: 5224, 113773: 5225, 113774: 5226, 113571: 5227, 113572: 5228, 113573: 5229, 113574: 5230, 113787: 5231, 113788: 5232, 113789: 5233, 113790: 5234, 113791: 5235, 113792: 5236, 113525: 5237, 113425: 5238, 113715: 5239, 113716: 5240, 113717: 5241, 113718: 5242, 113719: 5243, 113720: 5244, 113505: 5245, 113506: 5246, 113507: 5247, 113508: 5248, 113509: 5249, 113806: 5250, 113807: 5251, 113808: 5252, 113809: 5253, 113810: 5254, 113818: 5255, 113819: 5256, 113820: 5257, 113821: 5258, 113822: 5259, 113386: 5260, 113387: 5261, 113388: 5262, 113389: 5263, 113703: 5264, 113775: 5265, 113776: 5266, 113777: 5267, 113778: 5268, 113779: 5269, 113780: 5270, 113390: 5271, 113836: 5272, 113837: 5273, 113838: 5274, 113839: 5275, 113840: 5276, 113490: 5277, 113853: 5278, 113481: 5279, 113482: 5280, 113483: 5281, 113484: 5282, 113426: 5283, 113427: 5284, 113428: 5285, 113429: 5286, 113883: 5287, 113884: 5288, 113885: 5289, 113886: 5290, 113887: 5291, 113888: 5292, 113841: 5293, 113859: 5294, 55166: 5295, 55041: 5296, 55179: 5297, 55301: 5298, 55070: 5299, 55068: 5300, 55065: 5301, 55153: 5302, 55284: 5303, 57284: 5304, 55096: 5305, 55303: 5306, 55309: 5307, 55197: 5308, 55266: 5309, 55169: 5310, 55336: 5311, 55194: 5312, 55253: 5313, 55136: 5314, 55183: 5315, 55307: 5316, 55286: 5317, 55182: 5318, 55081: 5319, 149062: 5320, 149066: 5321, 149028: 5322, 148989: 5323, 149156: 5324, 149161: 5325, 149138: 5326, 148552: 5327, 148539: 5328, 148519: 5329, 148584: 5330, 149183: 5331, 149034: 5332, 149030: 5333, 149047: 5334, 149036: 5335, 149147: 5336, 149130: 5337, 149119: 5338, 148556: 5339, 148561: 5340, 148540: 5341, 148555: 5342, 148533: 5343, 148562: 5344, 148544: 5345, 149184: 5346, 149185: 5347, 149186: 5348, 149187: 5349, 149188: 5350, 149189: 5351, 149190: 5352, 149191: 5353, 149192: 5354, 149193: 5355, 149008: 5356, 149069: 5357, 149003: 5358, 149000: 5359, 149061: 5360, 149048: 5361, 149033: 5362, 149109: 5363, 149104: 5364, 149105: 5365, 148521: 5366, 148573: 5367, 148578: 5368, 148588: 5369, 149194: 5370, 149195: 5371, 149196: 5372, 149197: 5373, 149198: 5374, 149199: 5375, 149200: 5376, 149201: 5377, 149202: 5378, 149203: 5379, 149204: 5380, 149205: 5381, 149206: 5382, 149024: 5383, 149037: 5384, 149046: 5385, 148987: 5386, 149139: 5387, 149168: 5388, 149088: 5389, 149158: 5390, 149150: 5391, 149084: 5392, 148523: 5393, 148550: 5394, 148551: 5395, 148554: 5396, 148579: 5397, 149012: 5398, 149071: 5399, 149075: 5400, 149123: 5401, 149141: 5402, 149126: 5403, 148571: 5404, 128455: 5405, 128465: 5406, 128419: 5407, 128420: 5408, 128448: 5409, 128425: 5410, 128426: 5411, 128407: 5412, 128408: 5413, 128421: 5414, 128422: 5415, 128459: 5416, 128461: 5417, 128446: 5418, 128457: 5419, 128442: 5420, 128411: 5421, 128412: 5422, 128431: 5423, 128432: 5424, 128467: 5425, 128401: 5426, 128402: 5427, 128443: 5428, 128453: 5429, 128438: 5430, 128469: 5431, 128444: 5432, 128450: 5433, 128471: 5434, 128423: 5435, 128424: 5436, 128413: 5437, 128414: 5438, 128403: 5439, 128404: 5440, 128429: 5441, 128430: 5442, 128435: 5443, 128436: 5444, 128397: 5445, 128398: 5446, 128473: 5447, 128456: 5448, 128405: 5449, 128406: 5450, 128475: 5451, 128468: 5452, 128417: 5453, 128418: 5454, 128399: 5455, 128400: 5456, 128427: 5457, 128428: 5458, 128433: 5459, 128434: 5460, 128415: 5461, 128416: 5462, 128409: 5463, 128410: 5464, 54542: 5465, 54543: 5466, 61497: 5467, 61498: 5468, 61617: 5469, 113046: 5470, 113239: 5471, 113240: 5472, 113241: 5473, 61704: 5474, 61705: 5475, 61485: 5476, 61486: 5477, 61566: 5478, 61567: 5479, 128363: 5480, 128364: 5481, 128371: 5482, 128395: 5483, 128385: 5484, 128369: 5485, 128370: 5486, 128379: 5487, 135061: 5488, 135069: 5489, 135051: 5490, 135102: 5491, 135087: 5492, 135100: 5493, 135095: 5494, 135082: 5495, 135118: 5496, 135144: 5497, 135196: 5498, 135132: 5499, 135199: 5500, 135139: 5501, 135116: 5502, 135160: 5503, 135941: 5504, 135949: 5505, 135954: 5506, 136020: 5507, 135983: 5508, 136022: 5509, 135984: 5510, 136053: 5511, 136082: 5512, 136062: 5513, 136054: 5514, 136051: 5515, 136040: 5516, 137884: 5517, 137869: 5518, 137872: 5519, 137873: 5520, 137879: 5521, 137789: 5522, 137790: 5523, 137791: 5524, 137809: 5525, 137844: 5526, 137779: 5527, 139654: 5528, 139657: 5529, 139293: 5530, 139310: 5531, 139318: 5532, 139289: 5533, 139303: 5534, 139301: 5535, 108995: 5536, 108980: 5537, 108973: 5538, 108992: 5539, 53742: 5540, 53743: 5541, 53744: 5542, 80497: 5543, 80498: 5544, 80499: 5545, 80500: 5546, 80501: 5547, 80527: 5548, 80528: 5549, 80529: 5550, 80530: 5551, 80531: 5552, 80629: 5553, 80630: 5554, 80631: 5555, 80632: 5556, 80633: 5557, 61644: 5558, 61645: 5559, 61641: 5560, 61642: 5561, 61662: 5562, 61663: 5563, 61683: 5564, 61684: 5565, 58002: 5566, 58003: 5567, 58004: 5568, 57934: 5569, 57935: 5570, 57936: 5571, 58155: 5572, 58156: 5573, 58157: 5574, 58158: 5575, 57876: 5576, 57877: 5577, 57878: 5578, 113335: 5579, 113336: 5580, 113337: 5581, 120404: 5582, 120378: 5583, 120403: 5584, 128319: 5585, 128320: 5586, 128383: 5587, 53996: 5588, 53997: 5589, 53998: 5590, 113045: 5591, 113267: 5592, 113269: 5593, 113135: 5594, 120376: 5595, 120371: 5596, 120366: 5597, 128351: 5598, 128352: 5599, 128378: 5600, 128357: 5601, 128358: 5602, 128335: 5603, 128336: 5604, 128373: 5605, 128349: 5606, 128350: 5607, 128345: 5608, 128355: 5609, 128356: 5610, 128359: 5611, 128360: 5612, 54012: 5613, 54013: 5614, 54014: 5615, 113187: 5616, 113188: 5617, 113189: 5618, 134919: 5619, 134924: 5620, 134941: 5621, 134928: 5622, 134931: 5623, 134948: 5624, 134983: 5625, 134972: 5626, 134960: 5627, 134977: 5628, 135019: 5629, 135034: 5630, 135029: 5631, 135002: 5632, 135781: 5633, 135730: 5634, 135731: 5635, 135732: 5636, 135802: 5637, 135697: 5638, 135739: 5639, 135850: 5640, 135862: 5641, 135851: 5642, 135828: 5643, 135849: 5644, 135836: 5645, 135865: 5646, 135843: 5647, 135819: 5648, 54036: 5649, 54037: 5650, 54038: 5651, 108965: 5652, 61618: 5653, 56833: 5654, 56834: 5655, 56773: 5656, 56774: 5657, 56866: 5658, 58105: 5659, 58106: 5660, 58107: 5661, 56867: 5662, 113003: 5663, 113002: 5664, 113298: 5665, 114032: 5666, 114066: 5667, 114053: 5668, 114022: 5669, 128365: 5670, 128366: 5671, 128361: 5672, 128362: 5673, 128368: 5674, 128374: 5675, 128372: 5676, 128325: 5677, 128326: 5678, 128321: 5679, 128322: 5680, 128387: 5681, 135071: 5682, 135048: 5683, 135072: 5684, 135090: 5685, 135108: 5686, 135097: 5687, 135120: 5688, 135123: 5689, 135964: 5690, 135962: 5691, 135951: 5692, 135972: 5693, 135952: 5694, 135956: 5695, 136026: 5696, 136008: 5697, 135980: 5698, 136090: 5699, 136075: 5700, 136046: 5701, 54060: 5702, 54061: 5703, 54062: 5704, 54320: 5705, 54321: 5706, 65288: 5707, 65289: 5708, 65290: 5709, 65291: 5710, 65292: 5711, 65324: 5712, 65325: 5713, 65326: 5714, 65327: 5715, 65328: 5716, 97847: 5717, 80341: 5718, 80342: 5719, 80343: 5720, 80344: 5721, 80345: 5722, 80593: 5723, 80594: 5724, 80595: 5725, 80596: 5726, 80597: 5727, 61533: 5728, 61534: 5729, 65264: 5730, 65265: 5731, 65266: 5732, 65267: 5733, 65268: 5734, 57840: 5735, 57841: 5736, 57842: 5737, 113040: 5738, 113263: 5739, 113264: 5740, 113265: 5741, 113278: 5742, 113090: 5743, 114025: 5744, 114061: 5745, 114036: 5746, 114050: 5747, 114069: 5748, 114034: 5749, 128347: 5750, 128348: 5751, 128331: 5752, 128332: 5753, 128342: 5754, 134951: 5755, 134944: 5756, 134964: 5757, 134990: 5758, 134974: 5759, 134987: 5760, 135012: 5761, 135032: 5762, 135023: 5763, 135014: 5764, 135003: 5765, 135751: 5766, 135763: 5767, 135790: 5768, 135829: 5769, 135824: 5770, 135928: 5771, 135933: 5772, 135911: 5773, 135889: 5774, 135891: 5775, 135892: 5776, 128546: 5777, 128497: 5778, 128498: 5779, 128522: 5780, 128549: 5781, 128493: 5782, 128494: 5783, 128542: 5784, 128489: 5785, 128490: 5786, 128553: 5787, 128554: 5788, 128491: 5789, 128492: 5790, 128501: 5791, 128502: 5792, 128495: 5793, 128496: 5794, 128477: 5795, 128478: 5796, 128511: 5797, 128512: 5798, 128518: 5799, 128521: 5800, 128532: 5801, 128520: 5802, 128533: 5803, 128536: 5804, 128524: 5805, 128531: 5806, 128534: 5807, 128555: 5808, 128538: 5809, 128556: 5810, 128543: 5811, 128544: 5812, 128541: 5813, 128540: 5814, 128547: 5815, 128552: 5816, 128548: 5817, 120355: 5818, 120375: 5819, 137810: 5820, 137811: 5821, 137804: 5822, 137864: 5823, 137867: 5824, 137868: 5825, 137899: 5826, 137902: 5827, 137903: 5828, 137834: 5829, 137837: 5830, 137838: 5831, 137764: 5832, 137889: 5833, 138026: 5834, 138027: 5835, 138028: 5836, 138029: 5837, 138078: 5838, 139651: 5839, 139645: 5840, 54096: 5841, 54097: 5842, 54098: 5843, 53766: 5844, 53767: 5845, 53768: 5846, 53534: 5847, 53535: 5848, 53536: 5849, 66074: 5850, 66075: 5851, 66076: 5852, 66077: 5853, 66078: 5854, 108938: 5855, 80695: 5856, 80696: 5857, 80697: 5858, 113130: 5859, 113133: 5860, 113134: 5861, 113282: 5862, 114054: 5863, 114029: 5864, 114068: 5865, 114059: 5866, 114040: 5867, 114038: 5868, 114055: 5869, 114060: 5870, 114067: 5871, 120380: 5872, 120251: 5873, 120240: 5874, 120243: 5875, 120144: 5876, 120142: 5877, 120154: 5878, 128327: 5879, 128328: 5880, 128396: 5881, 61623: 5882, 61624: 5883, 54032: 5884, 54033: 5885, 54034: 5886, 54076: 5887, 54077: 5888, 54078: 5889, 52958: 5890, 52959: 5891, 62635: 5892, 62636: 5893, 62637: 5894, 62638: 5895, 62639: 5896, 80715: 5897, 80716: 5898, 80717: 5899, 61500: 5900, 61501: 5901, 61527: 5902, 61528: 5903, 61650: 5904, 61651: 5905, 56869: 5906, 56870: 5907, 56746: 5908, 56747: 5909, 58130: 5910, 58131: 5911, 58132: 5912, 58133: 5913, 113001: 5914, 113085: 5915, 113086: 5916, 113087: 5917, 113227: 5918, 113228: 5919, 113229: 5920, 113183: 5921, 113184: 5922, 113185: 5923, 113211: 5924, 113212: 5925, 113213: 5926, 113070: 5927, 113071: 5928, 113072: 5929, 113167: 5930, 113168: 5931, 113169: 5932, 113223: 5933, 97926: 5934, 97919: 5935, 97829: 5936, 100655: 5937, 114047: 5938, 114046: 5939, 114027: 5940, 113224: 5941, 113225: 5942, 100658: 5943, 100660: 5944, 100663: 5945, 100667: 5946, 99003: 5947, 99004: 5948, 99005: 5949, 99006: 5950, 99007: 5951, 120412: 5952, 120367: 5953, 120365: 5954, 128367: 5955, 128317: 5956, 128318: 5957, 128329: 5958, 128330: 5959, 128343: 5960, 128333: 5961, 128334: 5962, 128380: 5963, 128388: 5964, 134949: 5965, 128513: 5966, 128514: 5967, 128505: 5968, 128506: 5969, 128515: 5970, 128516: 5971, 134937: 5972, 134971: 5973, 134969: 5974, 134999: 5975, 135004: 5976, 135024: 5977, 135805: 5978, 135806: 5979, 135807: 5980, 135706: 5981, 135703: 5982, 120381: 5983, 120364: 5984, 120368: 5985, 120408: 5986, 137937: 5987, 108922: 5988, 112921: 5989, 112922: 5990, 112923: 5991, 112924: 5992, 113009: 5993, 113219: 5994, 113220: 5995, 113221: 5996, 113339: 5997, 113340: 5998, 113315: 5999, 113317: 6000, 51013: 6001, 51014: 6002, 51015: 6003, 57820: 6004, 57821: 6005, 57822: 6006, 113060: 6007, 113061: 6008, 113062: 6009, 113306: 6010, 114048: 6011, 114042: 6012, 114057: 6013, 114044: 6014, 66110: 6015, 66111: 6016, 66112: 6017, 66113: 6018, 66114: 6019, 112973: 6020, 112974: 6021, 112975: 6022, 113175: 6023, 113177: 6024, 113138: 6025, 113139: 6026, 113251: 6027, 113252: 6028, 113253: 6029, 65996: 6030, 80823: 6031, 61593: 6032, 113047: 6033, 112951: 6034, 112952: 6035, 112953: 6036, 112954: 6037, 113006: 6038, 113341: 6039, 113065: 6040, 113066: 6041, 113067: 6042, 80509: 6043, 80510: 6044, 80511: 6045, 80512: 6046, 80513: 6047, 61692: 6048, 61693: 6049, 61545: 6050, 61546: 6051, 61461: 6052, 61462: 6053, 61608: 6054, 61609: 6055, 56857: 6056, 56858: 6057, 113007: 6058, 112977: 6059, 112978: 6060, 112979: 6061, 112965: 6062, 112966: 6063, 112967: 6064, 113041: 6065, 113095: 6066, 113096: 6067, 113097: 6068, 113105: 6069, 113108: 6070, 113109: 6071, 113159: 6072, 113160: 6073, 113161: 6074, 113247: 6075, 113248: 6076, 113249: 6077, 113302: 6078, 114064: 6079, 114071: 6080, 119335: 6081, 119336: 6082, 119337: 6083, 135038: 6084, 135046: 6085, 135054: 6086, 135049: 6087, 135110: 6088, 135103: 6089, 135135: 6090, 135161: 6091, 135122: 6092, 135121: 6093, 135939: 6094, 135953: 6095, 135965: 6096, 135991: 6097, 137829: 6098, 138062: 6099, 135989: 6100, 136025: 6101, 135993: 6102, 135981: 6103, 136011: 6104, 135977: 6105, 135978: 6106, 136006: 6107, 136073: 6108, 136067: 6109, 136058: 6110, 136057: 6111, 136069: 6112, 136071: 6113, 139646: 6114, 139655: 6115, 139336: 6116, 139316: 6117, 139290: 6118, 139414: 6119, 139408: 6120, 139431: 6121, 139428: 6122, 128376: 6123, 53984: 6124, 53985: 6125, 53986: 6126, 66122: 6127, 66123: 6128, 66124: 6129, 66125: 6130, 66126: 6131, 62563: 6132, 62565: 6133, 62567: 6134, 62570: 6135, 62572: 6136, 80867: 6137, 80868: 6138, 80869: 6139, 80587: 6140, 80588: 6141, 80589: 6142, 80590: 6143, 80591: 6144, 80503: 6145, 80504: 6146, 80505: 6147, 80506: 6148, 80507: 6149, 80467: 6150, 80468: 6151, 80469: 6152, 80470: 6153, 80471: 6154, 80455: 6155, 80456: 6156, 80457: 6157, 80458: 6158, 80459: 6159, 61632: 6160, 61633: 6161, 61611: 6162, 61612: 6163, 66002: 6164, 66003: 6165, 66004: 6166, 66005: 6167, 66006: 6168, 66104: 6169, 66105: 6170, 66106: 6171, 66107: 6172, 66108: 6173, 65306: 6174, 65307: 6175, 65308: 6176, 65309: 6177, 65310: 6178, 56887: 6179, 56888: 6180, 112913: 6181, 113152: 6182, 97882: 6183, 97929: 6184, 97879: 6185, 61581: 6186, 61582: 6187, 61665: 6188, 61666: 6189, 61470: 6190, 61471: 6191, 97807: 6192, 56848: 6193, 113048: 6194, 113270: 6195, 113327: 6196, 113328: 6197, 113329: 6198, 113286: 6199, 113145: 6200, 114063: 6201, 114043: 6202, 114065: 6203, 114031: 6204, 101000: 6205, 101001: 6206, 101003: 6207, 101004: 6208, 101005: 6209, 134942: 6210, 134933: 6211, 134917: 6212, 134963: 6213, 134957: 6214, 134959: 6215, 135008: 6216, 135026: 6217, 135018: 6218, 135020: 6219, 135712: 6220, 135754: 6221, 135755: 6222, 135756: 6223, 135787: 6224, 135870: 6225, 135818: 6226, 135835: 6227, 135842: 6228, 135814: 6229, 135853: 6230, 135867: 6231, 135866: 6232, 135907: 6233, 135922: 6234, 120382: 6235, 120379: 6236, 137961: 6237, 137951: 6238, 138120: 6239, 139265: 6240, 139266: 6241, 139170: 6242, 139171: 6243, 139172: 6244, 139173: 6245, 139174: 6246, 128528: 6247, 139393: 6248, 139389: 6249, 139349: 6250, 139395: 6251, 139376: 6252, 139343: 6253, 139175: 6254, 139176: 6255, 139279: 6256, 128545: 6257, 135826: 6258, 135868: 6259, 135852: 6260, 135856: 6261, 135813: 6262, 135812: 6263, 135821: 6264, 135825: 6265, 108904: 6266, 56821: 6267, 108899: 6268, 109015: 6269, 109006: 6270, 108998: 6271, 56822: 6272, 56755: 6273, 56756: 6274, 56842: 6275, 56843: 6276, 134922: 6277, 113343: 6278, 113344: 6279, 113345: 6280, 113151: 6281, 113153: 6282, 113055: 6283, 113056: 6284, 113057: 6285, 113331: 6286, 113332: 6287, 113333: 6288, 114070: 6289, 114024: 6290, 120249: 6291, 120253: 6292, 120255: 6293, 120256: 6294, 120374: 6295, 137947: 6296, 137956: 6297, 137941: 6298, 137959: 6299, 137965: 6300, 137953: 6301, 166478: 6302, 166500: 6303, 137784: 6304, 137785: 6305, 137786: 6306, 53722: 6307, 53723: 6308, 53724: 6309, 54272: 6310, 54273: 6311, 80671: 6312, 80672: 6313, 80673: 6314, 80835: 6315, 80836: 6316, 80837: 6317, 80413: 6318, 80414: 6319, 80415: 6320, 80416: 6321, 80417: 6322, 80581: 6323, 80582: 6324, 80583: 6325, 80584: 6326, 80585: 6327, 80365: 6328, 80366: 6329, 80367: 6330, 80368: 6331, 80369: 6332, 80407: 6333, 80408: 6334, 80409: 6335, 80410: 6336, 80411: 6337, 80569: 6338, 80570: 6339, 80571: 6340, 80572: 6341, 80573: 6342, 80443: 6343, 80444: 6344, 80445: 6345, 80446: 6346, 80447: 6347, 80521: 6348, 80522: 6349, 80523: 6350, 80524: 6351, 80525: 6352, 80371: 6353, 80372: 6354, 80373: 6355, 80374: 6356, 80375: 6357, 61518: 6358, 61519: 6359, 109010: 6360, 108932: 6361, 108979: 6362, 108946: 6363, 108989: 6364, 80329: 6365, 80330: 6366, 80331: 6367, 80332: 6368, 80333: 6369, 80359: 6370, 80360: 6371, 80361: 6372, 80362: 6373, 80363: 6374, 61590: 6375, 61591: 6376, 56791: 6377, 56792: 6378, 57990: 6379, 57991: 6380, 57992: 6381, 113294: 6382, 113295: 6383, 113296: 6384, 113297: 6385, 113319: 6386, 113320: 6387, 113321: 6388, 114051: 6389, 114035: 6390, 134923: 6391, 134939: 6392, 134930: 6393, 134973: 6394, 134989: 6395, 135022: 6396, 135009: 6397, 135028: 6398, 135694: 6399, 135700: 6400, 135815: 6401, 135887: 6402, 120369: 6403, 137957: 6404, 138110: 6405, 138113: 6406, 138114: 6407, 138112: 6408, 139221: 6409, 139222: 6410, 139223: 6411, 139224: 6412, 139278: 6413, 139277: 6414, 139274: 6415, 139346: 6416, 139388: 6417, 139377: 6418, 139378: 6419, 128509: 6420, 128510: 6421, 128551: 6422, 128535: 6423, 128487: 6424, 128488: 6425, 128483: 6426, 128484: 6427, 128479: 6428, 128480: 6429, 128485: 6430, 128486: 6431, 128481: 6432, 128482: 6433, 128499: 6434, 128500: 6435, 128523: 6436, 61536: 6437, 61537: 6438, 61653: 6439, 61654: 6440, 61452: 6441, 61453: 6442, 61449: 6443, 61450: 6444, 53662: 6445, 53663: 6446, 53664: 6447, 62629: 6448, 62630: 6449, 62631: 6450, 62632: 6451, 62633: 6452, 65990: 6453, 65991: 6454, 65992: 6455, 65993: 6456, 65994: 6457, 62713: 6458, 62714: 6459, 62715: 6460, 62716: 6461, 62717: 6462, 52916: 6463, 52917: 6464, 52892: 6465, 52893: 6466, 80723: 6467, 80724: 6468, 80725: 6469, 113000: 6470, 113303: 6471, 113304: 6472, 113305: 6473, 113243: 6474, 113244: 6475, 113245: 6476, 113347: 6477, 113349: 6478, 113115: 6479, 113118: 6480, 113119: 6481, 113080: 6482, 57752: 6483, 57753: 6484, 57754: 6485, 128384: 6486, 128391: 6487, 128394: 6488, 128392: 6489, 135057: 6490, 135052: 6491, 135070: 6492, 135094: 6493, 135091: 6494, 135174: 6495, 135125: 6496, 135117: 6497, 135157: 6498, 135992: 6499, 135986: 6500, 135975: 6501, 135996: 6502, 136032: 6503, 136007: 6504, 136000: 6505, 136005: 6506, 136077: 6507, 136039: 6508, 136050: 6509, 136064: 6510, 136059: 6511, 119327: 6512, 119328: 6513, 119329: 6514, 137769: 6515, 137770: 6516, 137771: 6517, 137849: 6518, 137874: 6519, 137839: 6520, 138011: 6521, 138012: 6522, 138013: 6523, 138046: 6524, 139649: 6525, 139656: 6526, 139437: 6527, 139405: 6528, 139427: 6529, 65294: 6530, 65295: 6531, 65296: 6532, 65297: 6533, 65298: 6534, 113171: 6535, 113172: 6536, 113173: 6537, 113259: 6538, 113261: 6539, 120360: 6540, 128382: 6541, 128375: 6542, 128390: 6543, 128353: 6544, 128354: 6545, 53738: 6546, 53739: 6547, 53740: 6548, 53582: 6549, 53583: 6550, 53584: 6551, 53570: 6552, 53571: 6553, 53572: 6554, 53710: 6555, 53711: 6556, 53712: 6557, 54506: 6558, 54507: 6559, 120252: 6560, 53714: 6561, 53715: 6562, 53716: 6563, 53598: 6564, 53599: 6565, 53600: 6566, 80241: 6567, 81211: 6568, 81212: 6569, 113008: 6570, 113271: 6571, 113272: 6572, 113273: 6573, 53650: 6574, 53651: 6575, 53652: 6576, 108971: 6577, 80811: 6578, 80812: 6579, 80813: 6580, 80787: 6581, 80788: 6582, 80789: 6583, 80719: 6584, 80720: 6585, 80721: 6586, 80875: 6587, 80876: 6588, 80877: 6589, 61530: 6590, 61531: 6591, 120245: 6592, 120250: 6593, 108898: 6594, 108950: 6595, 109004: 6596, 108959: 6597, 113311: 6598, 113312: 6599, 113313: 6600, 120140: 6601, 120137: 6602, 120136: 6603, 120197: 6604, 120198: 6605, 120199: 6606, 120205: 6607, 120206: 6608, 120207: 6609, 120173: 6610, 120174: 6611, 120175: 6612, 120148: 6613, 108956: 6614, 108917: 6615, 109012: 6616, 109007: 6617, 108925: 6618, 108961: 6619, 108953: 6620, 113316: 6621, 113091: 6622, 113092: 6623, 113195: 6624, 113196: 6625, 113197: 6626, 113075: 6627, 113076: 6628, 113077: 6629, 113050: 6630, 113051: 6631, 113052: 6632, 114023: 6633, 80743: 6634, 80744: 6635, 80745: 6636, 61521: 6637, 61522: 6638, 120147: 6639, 120152: 6640, 120143: 6641, 79369: 6642, 79370: 6643, 113005: 6644, 113274: 6645, 113275: 6646, 113276: 6647, 113277: 6648, 113081: 6649, 113082: 6650, 120238: 6651, 120239: 6652, 113191: 6653, 113192: 6654, 113193: 6655, 113287: 6656, 113288: 6657, 113289: 6658, 79375: 6659, 79376: 6660, 120242: 6661, 120254: 6662, 53758: 6663, 53759: 6664, 53760: 6665, 79834: 6666, 53706: 6667, 53707: 6668, 53708: 6669, 108968: 6670, 108947: 6671, 62539: 6672, 62540: 6673, 62541: 6674, 62542: 6675, 62543: 6676, 80891: 6677, 80892: 6678, 80893: 6679, 80883: 6680, 80884: 6681, 80885: 6682, 80731: 6683, 80732: 6684, 80733: 6685, 80851: 6686, 80852: 6687, 80853: 6688, 80819: 6689, 80820: 6690, 80821: 6691, 80431: 6692, 80432: 6693, 80433: 6694, 80434: 6695, 80435: 6696, 113290: 6697, 113291: 6698, 113292: 6699, 113293: 6700, 113231: 6701, 113233: 6702, 80619: 6703, 80425: 6704, 80426: 6705, 80427: 6706, 80428: 6707, 80429: 6708, 80347: 6709, 80348: 6710, 80349: 6711, 80350: 6712, 80351: 6713, 108943: 6714, 108929: 6715, 80437: 6716, 80438: 6717, 80439: 6718, 80440: 6719, 80441: 6720, 120138: 6721, 120213: 6722, 120214: 6723, 120215: 6724, 120151: 6725, 120201: 6726, 120202: 6727, 120203: 6728, 120150: 6729, 120246: 6730, 120248: 6731, 120247: 6732, 120244: 6733, 120356: 6734, 120409: 6735, 120357: 6736, 137948: 6737, 137964: 6738, 137950: 6739, 138121: 6740, 138117: 6741, 138119: 6742, 139267: 6743, 139181: 6744, 139182: 6745, 139183: 6746, 139386: 6747, 139392: 6748, 139404: 6749, 139184: 6750, 139229: 6751, 139230: 6752, 139231: 6753, 139232: 6754, 166489: 6755, 166494: 6756, 166501: 6757, 166475: 6758, 166473: 6759, 166481: 6760, 166469: 6761, 166498: 6762, 166472: 6763, 166496: 6764, 166529: 6765, 166499: 6766, 166459: 6767, 166503: 6768, 166470: 6769, 166457: 6770, 166485: 6771, 166477: 6772, 166460: 6773, 166461: 6774, 166467: 6775, 166490: 6776, 166528: 6777, 166535: 6778, 166515: 6779, 166520: 6780, 166542: 6781, 166514: 6782, 166603: 6783, 166562: 6784, 166556: 6785, 166597: 6786, 166568: 6787, 166567: 6788, 166557: 6789, 166566: 6790, 166589: 6791, 166558: 6792, 166600: 6793, 166583: 6794, 166572: 6795, 166599: 6796, 166582: 6797, 166581: 6798, 166598: 6799, 166577: 6800, 166578: 6801, 166594: 6802, 166584: 6803, 166569: 6804, 166571: 6805, 166579: 6806, 166586: 6807, 166596: 6808, 166601: 6809, 166561: 6810, 166565: 6811, 166575: 6812, 167397: 6813, 167413: 6814, 167465: 6815, 167474: 6816, 167470: 6817, 167414: 6818, 167457: 6819, 167461: 6820, 167539: 6821, 167528: 6822, 167525: 6823, 167520: 6824, 167550: 6825, 167536: 6826, 167571: 6827, 167551: 6828, 167540: 6829, 167503: 6830, 167492: 6831, 167575: 6832, 167480: 6833, 167542: 6834, 167570: 6835, 137854: 6836, 137857: 6837, 137858: 6838, 137814: 6839, 137859: 6840, 137819: 6841, 138074: 6842, 138054: 6843, 138034: 6844, 138070: 6845, 139226: 6846, 139227: 6847, 139228: 6848, 79357: 6849, 79358: 6850, 81170: 6851, 81171: 6852, 80193: 6853, 80194: 6854, 80195: 6855, 53754: 6856, 53755: 6857, 53756: 6858, 109001: 6859, 62623: 6860, 62624: 6861, 62625: 6862, 62626: 6863, 62627: 6864, 80389: 6865, 80390: 6866, 80391: 6867, 80392: 6868, 80393: 6869, 61659: 6870, 61660: 6871, 120145: 6872, 114033: 6873, 54491: 6874, 54492: 6875, 53678: 6876, 53679: 6877, 53680: 6878, 80205: 6879, 80206: 6880, 80207: 6881, 80269: 6882, 54515: 6883, 54516: 6884, 80859: 6885, 80860: 6886, 80861: 6887, 61629: 6888, 61630: 6889, 61549: 6890, 61599: 6891, 61600: 6892, 61563: 6893, 61564: 6894, 112936: 6895, 112937: 6896, 112938: 6897, 112939: 6898, 112989: 6899, 112990: 6900, 112991: 6901, 113283: 6902, 113284: 6903, 113285: 6904, 97867: 6905, 120146: 6906, 120149: 6907, 120233: 6908, 120234: 6909, 120235: 6910, 112926: 6911, 112927: 6912, 112928: 6913, 112929: 6914, 108926: 6915, 108940: 6916, 108905: 6917, 53602: 6918, 53603: 6919, 53604: 6920, 113203: 6921, 113204: 6922, 113205: 6923, 113140: 6924, 113143: 6925, 113144: 6926, 113179: 6927, 113180: 6928, 113181: 6929, 120153: 6930, 79573: 6931, 79574: 6932, 81127: 6933, 81128: 6934, 81136: 6935, 81137: 6936, 80245: 6937, 114052: 6938, 114062: 6939, 108907: 6940, 108958: 6941, 80335: 6942, 80336: 6943, 80337: 6944, 80338: 6945, 80339: 6946, 61686: 6947, 120139: 6948, 120157: 6949, 120158: 6950, 120159: 6951, 120155: 6952, 53646: 6953, 53647: 6954, 53648: 6955, 53690: 6956, 53691: 6957, 53692: 6958, 79564: 6959, 79565: 6960, 79930: 6961, 79931: 6962, 81142: 6963, 81143: 6964, 80161: 6965, 80162: 6966, 80163: 6967, 80257: 6968, 80258: 6969, 80259: 6970, 53746: 6971, 53747: 6972, 53748: 6973, 53638: 6974, 53639: 6975, 53640: 6976, 81184: 6977, 81185: 6978, 81196: 6979, 81197: 6980, 53718: 6981, 53719: 6982, 53720: 6983, 53682: 6984, 53683: 6985, 53684: 6986, 53578: 6987, 53579: 6988, 53580: 6989, 108997: 6990, 62509: 6991, 62510: 6992, 62511: 6993, 62512: 6994, 62513: 6995, 53554: 6996, 53555: 6997, 53556: 6998, 53694: 6999, 53695: 7000, 53696: 7001, 108919: 7002, 80899: 7003, 80900: 7004, 80901: 7005, 80419: 7006, 80420: 7007, 80421: 7008, 80422: 7009, 80423: 7010, 80485: 7011, 80486: 7012, 80487: 7013, 80488: 7014, 80489: 7015, 61687: 7016, 61554: 7017, 61555: 7018, 80071: 7019, 80072: 7020, 80533: 7021, 80534: 7022, 80535: 7023, 80536: 7024, 80537: 7025, 80557: 7026, 80558: 7027, 80559: 7028, 80560: 7029, 80561: 7030, 79363: 7031, 79364: 7032, 79579: 7033, 79580: 7034, 80277: 7035, 80278: 7036, 80279: 7037, 80229: 7038, 80230: 7039, 80231: 7040, 80181: 7041, 80182: 7042, 80183: 7043, 81199: 7044, 81200: 7045, 108913: 7046, 54209: 7047, 54210: 7048, 80739: 7049, 80740: 7050, 80741: 7051, 61674: 7052, 61675: 7053, 113199: 7054, 113200: 7055, 113201: 7056, 113176: 7057, 113207: 7058, 113208: 7059, 113209: 7060, 113307: 7061, 113308: 7062, 113309: 7063, 139652: 7064, 139302: 7065, 139314: 7066, 166354: 7067, 166340: 7068, 167627: 7069, 167660: 7070, 167631: 7071, 167601: 7072, 167579: 7073, 113125: 7074, 113128: 7075, 113129: 7076, 120241: 7077, 120362: 7078, 120361: 7079, 53658: 7080, 53659: 7081, 53660: 7082, 53618: 7083, 53619: 7084, 53620: 7085, 81202: 7086, 81203: 7087, 81155: 7088, 81156: 7089, 79927: 7090, 79928: 7091, 108920: 7092, 54335: 7093, 54336: 7094, 80791: 7095, 80792: 7096, 80793: 7097, 98970: 7098, 98971: 7099, 98972: 7100, 98973: 7101, 98974: 7102, 114045: 7103, 120407: 7104, 120358: 7105, 137944: 7106, 137962: 7107, 137949: 7108, 138111: 7109, 166462: 7110, 166482: 7111, 166493: 7112, 166484: 7113, 166492: 7114, 166458: 7115, 166537: 7116, 166523: 7117, 166510: 7118, 166563: 7119, 79570: 7120, 79571: 7121, 79561: 7122, 79562: 7123, 79576: 7124, 79577: 7125, 81133: 7126, 81134: 7127, 79849: 7128, 79850: 7129, 79921: 7130, 79922: 7131, 81139: 7132, 81140: 7133, 81164: 7134, 81165: 7135, 80185: 7136, 80186: 7137, 80187: 7138, 108934: 7139, 66146: 7140, 66148: 7141, 80575: 7142, 80576: 7143, 80577: 7144, 80578: 7145, 80579: 7146, 113235: 7147, 113236: 7148, 113237: 7149, 114056: 7150, 114030: 7151, 114058: 7152, 97913: 7153, 98948: 7154, 98949: 7155, 98950: 7156, 98951: 7157, 98952: 7158, 101792: 7159, 101793: 7160, 101795: 7161, 101797: 7162, 101798: 7163, 99026: 7164, 109013: 7165, 99027: 7166, 99028: 7167, 99029: 7168, 99031: 7169, 108935: 7170, 120354: 7171, 137963: 7172, 138124: 7173, 138115: 7174, 137939: 7175, 137952: 7176, 137960: 7177, 137954: 7178, 137938: 7179, 120411: 7180, 120373: 7181, 139218: 7182, 139219: 7183, 139220: 7184, 139350: 7185, 139351: 7186, 166491: 7187, 166488: 7188, 166513: 7189, 166517: 7190, 166522: 7191, 166539: 7192, 166590: 7193, 166574: 7194, 167429: 7195, 167448: 7196, 167459: 7197, 167428: 7198, 167444: 7199, 167411: 7200, 167404: 7201, 167501: 7202, 167489: 7203, 167554: 7204, 167530: 7205, 167477: 7206, 167487: 7207, 167481: 7208, 128527: 7209, 128507: 7210, 128508: 7211, 137820: 7212, 138023: 7213, 138024: 7214, 138025: 7215, 138050: 7216, 138042: 7217, 138066: 7218, 137821: 7219, 137759: 7220, 137794: 7221, 166328: 7222, 166319: 7223, 166350: 7224, 166343: 7225, 166342: 7226, 166345: 7227, 166316: 7228, 166336: 7229, 166317: 7230, 166361: 7231, 166358: 7232, 166365: 7233, 166394: 7234, 166398: 7235, 166445: 7236, 166435: 7237, 166412: 7238, 167432: 7239, 167473: 7240, 79942: 7241, 79943: 7242, 80169: 7243, 80170: 7244, 80171: 7245, 108977: 7246, 80707: 7247, 80708: 7248, 80709: 7249, 80653: 7250, 80654: 7251, 80655: 7252, 80656: 7253, 80657: 7254, 80545: 7255, 80546: 7256, 80547: 7257, 80548: 7258, 80549: 7259, 113323: 7260, 113324: 7261, 113325: 7262, 113110: 7263, 113113: 7264, 113114: 7265, 113215: 7266, 113216: 7267, 113217: 7268, 137946: 7269, 137955: 7270, 137942: 7271, 137945: 7272, 167514: 7273, 167521: 7274, 167522: 7275, 167568: 7276, 167516: 7277, 167453: 7278, 167401: 7279, 167420: 7280, 167471: 7281, 167455: 7282, 167472: 7283, 167406: 7284, 167430: 7285, 80201: 7286, 80202: 7287, 80203: 7288, 81187: 7289, 81188: 7290, 81205: 7291, 81206: 7292, 54476: 7293, 54477: 7294, 113232: 7295, 101745: 7296, 101747: 7297, 101749: 7298, 101752: 7299, 101755: 7300, 99311: 7301, 99312: 7302, 99314: 7303, 99319: 7304, 99321: 7305, 99361: 7306, 99362: 7307, 99363: 7308, 99364: 7309, 99365: 7310, 120237: 7311, 114039: 7312, 137805: 7313, 137806: 7314, 137824: 7315, 139643: 7316, 139644: 7317, 139647: 7318, 166356: 7319, 166446: 7320, 167623: 7321, 167611: 7322, 167662: 7323, 139439: 7324, 139406: 7325, 139407: 7326, 108931: 7327, 109016: 7328, 108908: 7329, 120353: 7330, 120370: 7331, 137958: 7332, 137936: 7333, 137943: 7334, 166455: 7335, 166521: 7336, 166525: 7337, 166538: 7338, 166516: 7339, 166511: 7340, 166533: 7341, 166573: 7342, 166544: 7343, 166518: 7344, 166592: 7345, 166591: 7346, 166564: 7347, 166587: 7348, 166560: 7349, 166576: 7350, 166580: 7351, 166604: 7352, 167452: 7353, 167399: 7354, 167426: 7355, 167405: 7356, 167479: 7357, 167495: 7358, 167491: 7359, 167567: 7360, 167506: 7361, 167566: 7362, 167553: 7363, 167561: 7364, 128529: 7365, 128530: 7366, 138116: 7367, 138118: 7368, 108976: 7369, 109009: 7370, 108994: 7371, 108941: 7372, 108962: 7373, 108988: 7374, 108964: 7375, 108914: 7376, 108985: 7377, 108937: 7378, 108923: 7379, 108910: 7380, 166463: 7381, 166476: 7382, 120141: 7383, 166349: 7384, 166351: 7385, 166339: 7386, 166338: 7387, 166353: 7388, 166335: 7389, 166329: 7390, 166322: 7391, 166321: 7392, 166324: 7393, 166391: 7394, 166362: 7395, 166364: 7396, 166379: 7397, 166439: 7398, 166431: 7399, 166448: 7400, 166330: 7401, 166428: 7402, 166416: 7403, 166443: 7404, 166433: 7405, 166450: 7406, 166411: 7407, 166414: 7408, 166425: 7409, 166440: 7410, 167653: 7411, 167629: 7412, 167642: 7413, 167591: 7414, 167599: 7415, 167649: 7416, 167610: 7417, 167628: 7418, 167651: 7419, 167675: 7420, 167727: 7421, 167734: 7422, 167725: 7423, 167685: 7424, 167669: 7425, 167780: 7426, 167757: 7427, 167762: 7428, 167813: 7429, 167804: 7430, 167810: 7431, 167775: 7432, 167822: 7433, 167753: 7434, 167836: 7435, 137799: 7436, 137800: 7437, 137801: 7438, 137830: 7439, 137831: 7440, 166331: 7441, 166323: 7442, 166326: 7443, 166370: 7444, 166363: 7445, 166403: 7446, 166378: 7447, 166372: 7448, 166438: 7449, 166415: 7450, 166426: 7451, 166430: 7452, 166441: 7453, 166422: 7454, 166413: 7455, 167445: 7456, 167418: 7457, 167435: 7458, 167557: 7459, 167548: 7460, 167534: 7461, 167556: 7462, 167485: 7463, 167552: 7464, 167493: 7465, 139178: 7466, 139179: 7467, 139180: 7468, 54064: 7469, 54065: 7470, 54066: 7471, 137894: 7472, 167639: 7473, 167592: 7474, 167596: 7475, 167588: 7476, 167582: 7477, 167590: 7478, 108967: 7479, 120406: 7480, 138122: 7481, 139347: 7482, 139348: 7483, 139344: 7484, 139345: 7485, 166483: 7486, 166464: 7487, 166474: 7488, 166466: 7489, 166487: 7490, 166471: 7491, 166502: 7492, 166524: 7493, 166526: 7494, 166585: 7495, 166495: 7496, 166486: 7497, 166602: 7498, 167512: 7499, 166559: 7500, 166570: 7501, 166588: 7502, 167572: 7503, 167484: 7504, 167532: 7505, 167537: 7506, 167541: 7507, 167497: 7508, 167510: 7509, 167499: 7510, 167515: 7511, 167546: 7512, 166595: 7513, 128539: 7514, 128525: 7515, 137842: 7516, 120181: 7517, 120182: 7518, 120183: 7519, 167580: 7520, 167586: 7521, 167655: 7522, 167654: 7523, 167598: 7524, 167622: 7525, 167659: 7526, 137795: 7527, 137796: 7528, 137774: 7529, 139433: 7530, 139438: 7531, 166348: 7532, 166369: 7533, 166368: 7534, 166359: 7535, 166396: 7536, 166420: 7537, 166409: 7538, 166449: 7539, 167578: 7540, 167587: 7541, 167646: 7542, 167637: 7543, 167597: 7544, 167595: 7545, 167593: 7546, 167594: 7547, 167644: 7548, 167684: 7549, 167739: 7550, 167674: 7551, 167730: 7552, 167692: 7553, 167699: 7554, 167745: 7555, 167830: 7556, 167777: 7557, 167747: 7558, 167793: 7559, 167779: 7560, 167784: 7561, 167756: 7562, 167819: 7563, 167808: 7564, 167608: 7565, 167635: 7566, 167624: 7567, 167833: 7568, 167801: 7569, 167761: 7570, 167786: 7571, 167811: 7572, 167752: 7573, 137780: 7574, 137781: 7575, 137979: 7576, 137980: 7577, 137981: 7578, 137971: 7579, 137972: 7580, 137973: 7581, 138038: 7582, 138039: 7583, 138040: 7584, 138041: 7585, 138079: 7586, 138080: 7587, 138081: 7588, 166320: 7589, 166357: 7590, 166421: 7591, 166334: 7592, 166352: 7593, 166377: 7594, 166344: 7595, 166337: 7596, 166395: 7597, 166355: 7598, 166374: 7599, 166429: 7600, 166419: 7601, 166410: 7602, 166408: 7603, 166423: 7604, 166407: 7605, 166436: 7606, 166451: 7607, 166447: 7608, 167723: 7609, 167726: 7610, 167683: 7611, 167741: 7612, 167688: 7613, 167717: 7614, 167691: 7615, 167705: 7616, 167788: 7617, 167783: 7618, 167759: 7619, 167764: 7620, 167838: 7621, 167768: 7622, 166434: 7623, 167845: 7624, 167800: 7625, 167824: 7626, 167751: 7627, 167755: 7628, 167749: 7629, 167821: 7630, 167664: 7631, 167617: 7632, 137862: 7633, 137863: 7634, 138051: 7635, 138052: 7636, 138053: 7637, 167438: 7638, 167408: 7639, 167410: 7640, 167440: 7641, 167451: 7642, 167443: 7643, 166325: 7644, 166318: 7645, 166327: 7646, 167531: 7647, 167508: 7648, 167535: 7649, 167574: 7650, 167524: 7651, 167486: 7652, 137847: 7653, 137848: 7654, 137843: 7655, 137904: 7656, 166375: 7657, 166376: 7658, 166399: 7659, 167416: 7660, 167449: 7661, 167403: 7662, 167427: 7663, 167496: 7664, 167488: 7665, 167513: 7666, 119351: 7667, 119352: 7668, 119353: 7669, 119331: 7670, 119332: 7671, 119333: 7672, 137892: 7673, 137893: 7674, 166404: 7675, 166366: 7676, 166400: 7677, 166424: 7678, 166405: 7679, 166417: 7680, 167626: 7681, 167657: 7682, 167583: 7683, 167603: 7684, 167716: 7685, 167678: 7686, 167712: 7687, 167695: 7688, 167689: 7689, 167690: 7690, 167715: 7691, 167754: 7692, 167814: 7693, 167795: 7694, 167769: 7695, 167794: 7696, 167785: 7697, 167802: 7698, 167606: 7699, 167609: 7700, 167645: 7701, 167630: 7702, 167638: 7703, 167658: 7704, 167585: 7705, 167806: 7706, 167789: 7707, 167778: 7708, 167834: 7709, 167750: 7710, 167614: 7711, 167661: 7712, 167581: 7713, 167605: 7714, 167650: 7715, 167619: 7716, 167787: 7717, 167815: 7718, 167809: 7719, 167796: 7720, 167763: 7721, 137940: 7722, 108901: 7723, 120359: 7724, 166504: 7725, 166505: 7726, 166530: 7727, 138075: 7728, 138076: 7729, 138077: 7730, 138030: 7731, 166346: 7732, 166341: 7733, 166367: 7734, 167604: 7735, 167621: 7736, 167589: 7737, 167576: 7738, 119355: 7739, 119356: 7740, 119357: 7741, 166401: 7742, 166432: 7743, 166453: 7744, 166427: 7745, 167600: 7746, 137760: 7747, 137761: 7748, 137897: 7749, 137898: 7750, 137775: 7751, 137776: 7752, 137882: 7753, 137883: 7754, 137987: 7755, 137988: 7756, 137989: 7757, 138082: 7758, 166373: 7759, 166442: 7760, 166444: 7761, 166406: 7762, 166418: 7763, 167549: 7764, 167490: 7765, 167454: 7766, 167462: 7767, 167436: 7768, 167464: 7769, 120377: 7770, 138123: 7771, 120363: 7772, 120372: 7773, 166468: 7774, 166507: 7775, 166593: 7776, 167417: 7777, 167425: 7778, 167475: 7779, 167469: 7780, 167409: 7781, 167560: 7782, 167518: 7783, 167526: 7784, 167509: 7785, 167505: 7786, 167569: 7787, 167529: 7788, 167442: 7789, 128503: 7790, 128504: 7791, 128550: 7792, 128526: 7793, 108928: 7794, 108955: 7795, 166497: 7796, 166532: 7797, 166555: 7798, 167467: 7799, 167441: 7800, 167523: 7801, 167562: 7802, 167511: 7803, 128519: 7804, 128517: 7805, 138067: 7806, 138068: 7807, 138069: 7808, 138043: 7809, 138044: 7810, 138045: 7811, 138058: 7812, 166347: 7813, 166315: 7814, 166390: 7815, 166392: 7816, 166452: 7817, 167437: 7818, 166536: 7819, 137815: 7820, 137816: 7821, 137877: 7822, 137878: 7823, 137765: 7824, 137766: 7825, 166371: 7826, 167415: 7827, 167396: 7828, 167402: 7829, 167533: 7830, 167547: 7831, 54024: 7832, 54025: 7833, 54026: 7834, 54020: 7835, 54021: 7836, 54022: 7837, 167634: 7838, 167648: 7839, 167743: 7840, 167722: 7841, 167687: 7842, 167670: 7843, 167719: 7844, 167731: 7845, 167718: 7846, 167812: 7847, 167766: 7848, 167827: 7849, 167791: 7850, 167760: 7851, 167607: 7852, 167625: 7853, 120405: 7854, 166508: 7855, 166506: 7856, 166527: 7857, 166541: 7858, 166512: 7859, 167412: 7860, 167538: 7861, 167555: 7862, 166360: 7863, 167424: 7864, 167500: 7865, 167502: 7866, 138019: 7867, 138020: 7868, 138021: 7869, 166333: 7870, 166397: 7871, 167577: 7872, 166437: 7873, 128344: 7874, 166393: 7875, 166479: 7876, 166509: 7877, 120225: 7878, 120226: 7879, 120227: 7880, 137887: 7881, 137888: 7882, 167545: 7883, 167543: 7884, 108949: 7885, 166465: 7886, 166543: 7887, 120165: 7888, 120166: 7889, 120167: 7890, 138063: 7891, 138064: 7892, 138065: 7893, 138015: 7894, 138016: 7895, 138017: 7896, 166454: 7897, 167666: 7898, 167682: 7899, 167707: 7900, 167767: 7901, 167805: 7902, 167798: 7903, 167776: 7904, 167613: 7905, 120189: 7906, 120190: 7907, 120191: 7908, 120221: 7909, 120222: 7910, 120223: 7911, 167665: 7912, 137995: 7913, 137996: 7914, 137997: 7915, 167656: 7916, 167663: 7917, 167742: 7918, 167704: 7919, 167744: 7920, 167686: 7921, 167676: 7922, 167698: 7923, 167774: 7924, 167844: 7925, 167799: 7926, 137852: 7927, 137853: 7928, 167703: 7929, 167733: 7930, 167667: 7931, 167765: 7932, 167816: 7933, 167829: 7934, 167832: 7935, 167640: 7936, 167620: 7937, 167652: 7938, 167835: 7939, 167807: 7940, 54000: 7941, 54001: 7942, 54002: 7943, 120169: 7944, 120170: 7945, 120171: 7946, 85317: 7947, 85318: 7948, 85355: 7949, 85356: 7950, 85357: 7951, 85463: 7952, 85464: 7953, 85465: 7954, 85275: 7955, 85276: 7956, 85367: 7957, 85368: 7958, 85369: 7959, 85314: 7960, 85315: 7961, 85479: 7962, 85480: 7963, 85481: 7964, 84802: 7965, 84803: 7966, 84804: 7967, 84759: 7968, 84760: 7969, 85379: 7970, 85380: 7971, 85381: 7972, 85519: 7973, 85520: 7974, 85521: 7975, 92321: 7976, 92335: 7977, 92329: 7978, 92344: 7979, 92336: 7980, 92342: 7981, 92341: 7982, 92330: 7983, 85885: 7984, 85801: 7985, 85848: 7986, 85814: 7987, 85866: 7988, 85859: 7989, 85798: 7990, 85796: 7991, 85938: 7992, 85953: 7993, 85975: 7994, 85964: 7995, 85955: 7996, 85968: 7997, 86061: 7998, 85904: 7999, 85906: 8000, 85939: 8001, 86052: 8002, 86062: 8003, 86077: 8004, 86046: 8005, 85959: 8006, 85901: 8007, 85940: 8008, 85894: 8009, 85962: 8010, 85870: 8011, 85889: 8012, 85857: 8013, 85804: 8014, 85972: 8015, 85932: 8016, 86067: 8017, 85974: 8018, 85898: 8019, 86079: 8020, 86045: 8021, 86049: 8022, 86048: 8023, 86066: 8024, 85831: 8025, 85876: 8026, 85799: 8027, 85819: 8028, 85895: 8029, 85934: 8030, 86065: 8031, 86068: 8032, 85958: 8033, 85933: 8034, 85926: 8035, 85965: 8036, 85961: 8037, 85942: 8038, 86080: 8039, 85971: 8040, 85956: 8041, 86072: 8042, 86076: 8043, 85875: 8044, 85881: 8045, 85803: 8046, 85832: 8047, 85841: 8048, 85815: 8049, 85805: 8050, 85807: 8051, 85821: 8052, 85842: 8053, 85863: 8054, 85887: 8055, 85835: 8056, 85837: 8057, 85943: 8058, 85893: 8059, 85878: 8060, 85847: 8061, 85865: 8062, 85849: 8063, 85830: 8064, 85838: 8065, 85879: 8066, 85871: 8067, 85844: 8068, 85810: 8069, 85952: 8070, 85909: 8071, 85948: 8072, 85908: 8073, 85951: 8074, 85900: 8075, 86051: 8076, 86075: 8077, 86073: 8078, 86078: 8079, 85886: 8080, 85899: 8081, 85966: 8082, 86050: 8083, 86074: 8084, 85950: 8085, 86047: 8086, 85973: 8087, 85969: 8088, 86064: 8089, 85941: 8090, 85910: 8091, 85854: 8092, 86069: 8093, 85840: 8094, 85829: 8095, 85902: 8096, 85925: 8097, 85927: 8098, 85896: 8099, 86054: 8100, 85892: 8101, 86063: 8102, 85954: 8103, 85960: 8104, 85947: 8105, 85946: 8106, 85936: 8107, 85929: 8108, 85802: 8109, 85868: 8110, 85795: 8111, 85860: 8112, 52906: 8113, 52829: 8114, 52822: 8115, 52835: 8116, 66343: 8117, 66449: 8118, 66438: 8119, 66477: 8120, 66494: 8121, 66336: 8122, 66424: 8123, 66478: 8124, 66437: 8125, 66488: 8126, 66412: 8127, 66528: 8128, 66451: 8129, 66390: 8130, 66440: 8131, 66439: 8132, 66407: 8133, 66472: 8134, 85702: 8135, 85715: 8136, 85696: 8137, 85747: 8138, 85695: 8139, 52846: 8140, 53020: 8141, 52972: 8142, 52981: 8143, 52827: 8144, 52842: 8145, 52815: 8146, 85731: 8147, 85750: 8148, 85729: 8149, 85727: 8150, 85704: 8151, 85733: 8152, 66335: 8153, 66556: 8154, 52841: 8155, 52936: 8156, 52836: 8157, 52855: 8158, 52816: 8159, 85701: 8160, 85738: 8161, 52930: 8162, 52978: 8163, 52837: 8164, 52813: 8165, 66354: 8166, 66410: 8167, 66536: 8168, 66375: 8169, 85717: 8170, 85699: 8171, 85744: 8172, 85694: 8173, 85712: 8174, 85703: 8175, 85709: 8176, 85700: 8177, 66542: 8178, 66377: 8179, 66473: 8180, 66507: 8181, 66364: 8182, 66368: 8183, 66387: 8184, 66514: 8185, 85693: 8186, 85726: 8187, 85734: 8188, 85725: 8189, 85723: 8190, 52843: 8191, 52903: 8192, 52924: 8193, 52825: 8194, 53014: 8195, 52885: 8196, 85692: 8197, 85728: 8198, 66393: 8199, 66385: 8200, 66523: 8201, 66533: 8202, 66484: 8203, 66532: 8204, 66487: 8205, 66564: 8206, 52912: 8207, 53017: 8208, 52990: 8209, 52840: 8210, 53002: 8211, 52987: 8212, 52900: 8213, 52864: 8214, 85714: 8215, 85698: 8216, 66418: 8217, 66518: 8218, 66381: 8219, 52817: 8220, 52867: 8221, 85697: 8222, 85742: 8223, 52939: 8224, 52921: 8225, 85711: 8226, 85706: 8227, 66553: 8228, 66493: 8229, 66328: 8230, 66374: 8231, 66497: 8232, 66492: 8233, 66452: 8234, 66347: 8235, 66443: 8236, 85710: 8237, 85749: 8238, 85720: 8239, 85705: 8240, 85735: 8241, 85708: 8242, 85748: 8243, 52879: 8244, 85716: 8245, 85730: 8246, 85740: 8247, 85707: 8248, 52963: 8249, 52838: 8250, 52821: 8251, 52984: 8252, 85736: 8253, 85713: 8254, 66333: 8255, 66490: 8256, 66483: 8257, 66411: 8258, 66359: 8259, 66421: 8260, 66416: 8261, 66388: 8262, 66423: 8263, 85722: 8264, 85719: 8265, 85751: 8266, 85741: 8267, 52814: 8268, 52870: 8269, 52894: 8270, 66430: 8271, 66471: 8272, 66432: 8273, 66396: 8274, 66474: 8275, 66346: 8276, 66434: 8277, 66498: 8278, 66468: 8279, 66455: 8280, 66545: 8281, 66548: 8282, 52951: 8283, 52819: 8284, 52918: 8285, 66461: 8286, 66537: 8287, 66551: 8288, 66403: 8289, 66525: 8290, 52876: 8291, 52909: 8292, 52818: 8293, 85739: 8294, 66509: 8295, 85718: 8296, 66366: 8297, 66562: 8298, 66389: 8299, 52933: 8300, 52832: 8301, 85691: 8302, 52852: 8303, 66379: 8304, 66534: 8305, 66485: 8306, 66530: 8307, 66464: 8308, 66441: 8309, 52888: 8310, 66506: 8311, 66334: 8312, 66341: 8313, 85724: 8314, 85745: 8315, 85746: 8316, 53008: 8317, 52897: 8318, 66369: 8319, 66466: 8320, 52849: 8321, 52969: 8322, 66546: 8323, 66448: 8324, 66406: 8325, 66370: 8326, 52831: 8327, 85732: 8328, 66245: 8329, 66241: 8330, 66304: 8331, 65661: 8332, 65862: 8333, 66321: 8334, 66251: 8335, 66212: 8336, 66248: 8337, 66214: 8338, 66195: 8339, 66224: 8340, 65665: 8341, 65817: 8342, 66278: 8343, 65765: 8344, 65713: 8345, 66266: 8346, 65701: 8347, 66205: 8348, 66249: 8349, 66222: 8350, 66206: 8351, 66209: 8352, 66203: 8353, 66283: 8354, 65777: 8355, 66242: 8356, 66226: 8357, 65729: 8358, 65717: 8359, 66285: 8360, 65837: 8361, 65872: 8362, 66277: 8363, 65697: 8364, 66194: 8365, 66257: 8366, 65733: 8367, 66323: 8368, 66221: 8369, 65813: 8370, 66293: 8371, 65721: 8372, 66199: 8373, 66219: 8374, 66185: 8375, 65861: 8376, 65769: 8377, 66318: 8378, 65669: 8379, 66237: 8380, 65773: 8381, 65653: 8382, 65873: 8383, 66198: 8384, 65617: 8385, 66176: 8386, 66244: 8387, 66300: 8388, 66279: 8389, 66286: 8390, 66197: 8391, 66292: 8392, 65801: 8393, 66210: 8394, 65809: 8395, 66254: 8396, 66306: 8397, 66187: 8398, 66303: 8399, 66261: 8400, 66296: 8401, 66215: 8402, 97812: 8403, 65599: 8404, 66175: 8405, 66308: 8406, 65805: 8407, 65633: 8408, 66295: 8409, 65761: 8410, 66253: 8411, 65737: 8412, 66275: 8413, 66180: 8414, 66243: 8415, 66240: 8416, 66250: 8417, 65693: 8418, 66262: 8419, 66316: 8420, 65613: 8421, 65868: 8422, 65821: 8423, 97872: 8424, 66287: 8425, 66297: 8426, 66193: 8427, 66291: 8428, 65649: 8429, 66234: 8430, 66289: 8431, 66252: 8432, 66272: 8433, 66238: 8434, 65757: 8435, 65841: 8436, 66231: 8437, 66228: 8438, 66259: 8439, 65749: 8440, 66188: 8441, 66178: 8442, 65705: 8443, 66202: 8444, 66299: 8445, 65845: 8446, 65789: 8447, 66269: 8448, 65863: 8449, 66190: 8450, 65753: 8451, 66235: 8452, 65870: 8453, 65865: 8454, 65625: 8455, 65866: 8456, 66267: 8457, 66223: 8458, 66322: 8459, 65673: 8460, 66281: 8461, 65797: 8462, 66182: 8463, 66227: 8464, 66310: 8465, 66274: 8466, 66298: 8467, 66183: 8468, 66179: 8469, 66204: 8470, 66186: 8471, 66218: 8472, 66229: 8473, 66264: 8474, 66184: 8475, 66311: 8476, 65689: 8477, 65781: 8478, 65858: 8479, 66213: 8480, 66192: 8481, 65629: 8482, 66200: 8483, 66280: 8484, 66312: 8485, 66305: 8486, 65745: 8487, 65825: 8488, 53318: 8489, 53313: 8490, 53281: 8491, 53297: 8492, 53284: 8493, 53316: 8494, 53309: 8495, 53321: 8496, 66651: 8497, 66695: 8498, 66692: 8499, 66575: 8500, 66681: 8501, 66629: 8502, 66708: 8503, 66713: 8504, 66657: 8505, 66621: 8506, 53307: 8507, 53264: 8508, 53319: 8509, 53334: 8510, 53343: 8511, 53308: 8512, 53275: 8513, 53306: 8514, 53336: 8515, 66672: 8516, 66683: 8517, 66609: 8518, 66622: 8519, 66614: 8520, 66574: 8521, 53288: 8522, 66616: 8523, 66606: 8524, 66686: 8525, 66603: 8526, 66709: 8527, 66710: 8528, 66693: 8529, 53330: 8530, 53314: 8531, 53347: 8532, 66660: 8533, 66663: 8534, 66711: 8535, 66655: 8536, 66715: 8537, 66597: 8538, 66595: 8539, 66662: 8540, 66691: 8541, 66612: 8542, 66619: 8543, 66604: 8544, 53269: 8545, 53352: 8546, 53350: 8547, 53289: 8548, 66581: 8549, 66667: 8550, 66659: 8551, 53300: 8552, 53272: 8553, 53292: 8554, 66702: 8555, 66678: 8556, 66570: 8557, 53339: 8558, 53263: 8559, 53304: 8560, 53322: 8561, 66656: 8562, 66583: 8563, 66618: 8564, 66610: 8565, 53312: 8566, 53282: 8567, 53302: 8568, 53323: 8569, 66576: 8570, 66626: 8571, 66589: 8572, 66654: 8573, 53296: 8574, 53327: 8575, 66615: 8576, 66644: 8577, 66647: 8578, 53274: 8579, 53270: 8580, 53337: 8581, 66679: 8582, 66673: 8583, 53311: 8584, 66685: 8585, 66608: 8586, 53340: 8587, 66630: 8588, 66668: 8589, 66675: 8590, 66700: 8591, 53324: 8592, 53320: 8593, 66688: 8594, 66611: 8595, 53332: 8596, 53351: 8597, 66701: 8598, 66642: 8599, 66613: 8600, 53328: 8601, 53333: 8602, 66634: 8603, 53265: 8604, 53299: 8605, 66714: 8606, 66572: 8607, 53310: 8608, 53317: 8609, 53331: 8610, 66671: 8611, 53298: 8612, 53301: 8613, 66704: 8614, 66706: 8615, 66664: 8616, 66653: 8617, 66625: 8618, 66602: 8619, 66707: 8620, 66587: 8621, 66607: 8622, 66568: 8623, 53315: 8624, 53283: 8625, 66689: 8626, 66705: 8627, 66594: 8628, 66573: 8629, 66636: 8630, 53277: 8631, 53295: 8632, 53268: 8633, 66598: 8634, 66620: 8635, 66596: 8636, 66567: 8637, 66690: 8638, 66641: 8639, 53266: 8640, 66599: 8641, 53285: 8642, 66649: 8643, 66569: 8644, 53348: 8645, 66624: 8646, 53273: 8647, 53293: 8648, 53345: 8649, 53326: 8650, 66666: 8651, 66698: 8652, 66590: 8653, 53271: 8654, 66645: 8655, 53338: 8656, 66648: 8657, 66579: 8658, 66643: 8659, 66571: 8660, 66637: 8661, 66623: 8662, 66680: 8663, 66638: 8664, 66605: 8665, 66677: 8666, 66577: 8667, 66640: 8668, 66582: 8669, 66699: 8670, 53342: 8671, 66601: 8672, 66646: 8673, 66593: 8674, 66631: 8675, 53278: 8676, 66592: 8677, 66585: 8678, 66674: 8679, 66661: 8680, 53280: 8681, 53325: 8682, 53303: 8683, 66578: 8684, 66639: 8685, 66687: 8686, 66584: 8687, 66586: 8688, 66633: 8689, 66696: 8690, 66712: 8691, 66703: 8692, 66580: 8693, 88406: 8694, 87027: 8695, 87126: 8696, 87121: 8697, 87107: 8698, 87092: 8699, 87111: 8700, 8462: 8701, 87048: 8702, 87038: 8703, 87041: 8704, 87063: 8705, 87077: 8706, 87057: 8707, 87110: 8708, 86235: 8709, 86149: 8710, 86142: 8711, 86158: 8712, 86166: 8713, 86152: 8714, 86232: 8715, 86144: 8716, 86146: 8717, 86167: 8718, 86140: 8719, 86164: 8720, 86163: 8721, 86157: 8722, 86170: 8723, 86160: 8724, 86138: 8725, 86219: 8726, 86197: 8727, 86228: 8728, 86199: 8729, 86218: 8730, 86192: 8731, 86210: 8732, 86217: 8733, 86215: 8734, 86202: 8735, 86139: 8736, 86141: 8737, 86154: 8738, 86143: 8739, 86162: 8740, 86147: 8741, 86172: 8742, 86153: 8743, 86206: 8744, 86198: 8745, 86225: 8746, 86223: 8747, 86201: 8748, 86187: 8749, 86151: 8750, 86233: 8751, 86156: 8752, 86165: 8753, 86168: 8754, 86196: 8755, 86231: 8756, 86190: 8757, 86234: 8758, 86203: 8759, 86195: 8760, 86216: 8761, 86226: 8762, 86213: 8763, 86145: 8764, 86137: 8765, 86200: 8766, 86150: 8767, 86208: 8768, 86159: 8769, 86155: 8770, 86171: 8771, 86173: 8772, 86193: 8773, 86207: 8774, 86236: 8775, 86209: 8776, 86211: 8777, 86220: 8778, 86222: 8779, 86221: 8780, 86148: 8781, 86169: 8782, 86161: 8783, 86188: 8784, 86191: 8785, 86189: 8786, 86212: 8787, 86205: 8788, 86214: 8789, 86227: 8790, 86224: 8791, 86204: 8792, 86194: 8793, 86229: 8794, 86230: 8795, 54118: 8796, 86850: 8797, 86846: 8798, 54155: 8799, 54133: 8800, 54140: 8801, 86862: 8802, 86839: 8803, 54108: 8804, 54143: 8805, 86791: 8806, 54154: 8807, 54124: 8808, 54149: 8809, 54104: 8810, 54119: 8811, 54153: 8812, 86854: 8813, 54159: 8814, 54112: 8815, 86776: 8816, 86781: 8817, 86861: 8818, 54152: 8819, 54157: 8820, 86780: 8821, 86878: 8822, 54141: 8823, 54128: 8824, 54116: 8825, 86788: 8826, 86859: 8827, 54129: 8828, 54110: 8829, 86858: 8830, 54162: 8831, 54156: 8832, 54123: 8833, 71367: 8834, 71364: 8835, 71348: 8836, 94884: 8837, 94870: 8838, 94893: 8839, 71366: 8840, 94901: 8841, 94883: 8842, 60143: 8843, 60087: 8844, 60122: 8845, 60074: 8846, 108981: 8847, 85013: 8848, 85243: 8849, 85248: 8850, 85247: 8851, 84671: 8852, 84667: 8853, 91671: 8854, 85249: 8855, 85049: 8856, 85218: 8857, 84664: 8858, 85052: 8859, 87557: 8860, 87446: 8861, 87465: 8862, 87518: 8863, 87434: 8864, 87566: 8865, 87432: 8866, 87548: 8867, 87519: 8868, 87443: 8869, 87552: 8870, 87447: 8871, 87532: 8872, 87546: 8873, 87554: 8874, 87600: 8875, 87541: 8876, 87535: 8877, 87517: 8878, 87450: 8879, 87586: 8880, 87440: 8881, 87462: 8882, 87533: 8883, 87540: 8884, 87515: 8885, 87426: 8886, 87448: 8887, 87593: 8888, 87512: 8889, 87433: 8890, 87469: 8891, 87560: 8892, 87539: 8893, 87453: 8894, 87591: 8895, 87460: 8896, 87466: 8897, 87444: 8898, 87428: 8899, 87582: 8900, 87570: 8901, 87564: 8902, 87430: 8903, 87467: 8904, 87435: 8905, 87597: 8906, 87459: 8907, 87521: 8908, 87562: 8909, 87431: 8910, 87544: 8911, 87424: 8912, 87592: 8913, 87470: 8914, 87520: 8915, 87588: 8916, 87595: 8917, 87423: 8918, 87563: 8919, 87456: 8920, 87568: 8921, 87449: 8922, 87587: 8923, 87468: 8924, 87516: 8925, 87445: 8926, 87550: 8927, 87461: 8928, 87441: 8929, 87567: 8930, 87590: 8931, 87442: 8932, 87427: 8933, 87463: 8934, 87571: 8935, 87585: 8936, 87559: 8937, 87437: 8938, 87596: 8939, 87422: 8940, 87561: 8941, 87513: 8942, 87598: 8943, 87436: 8944, 87569: 8945, 87455: 8946, 87458: 8947, 87452: 8948, 87536: 8949, 87589: 8950, 87429: 8951, 87438: 8952, 87538: 8953, 87514: 8954, 87594: 8955, 87565: 8956, 87584: 8957, 87471: 8958, 87537: 8959, 87601: 8960, 87425: 8961, 87464: 8962, 87451: 8963, 87599: 8964, 87439: 8965, 88086: 8966, 90662: 8967, 90701: 8968, 90692: 8969, 90702: 8970, 90659: 8971, 88616: 8972, 88622: 8973, 88501: 8974, 88597: 8975, 88518: 8976, 88621: 8977, 88602: 8978, 88532: 8979, 88539: 8980, 88605: 8981, 88591: 8982, 88525: 8983, 88519: 8984, 88516: 8985, 88619: 8986, 88498: 8987, 88627: 8988, 88613: 8989, 88590: 8990, 88502: 8991, 88549: 8992, 88536: 8993, 88548: 8994, 89670: 8995, 89754: 8996, 84907: 8997, 89823: 8998, 89965: 8999, 89923: 9000, 89968: 9001, 89829: 9002, 89896: 9003, 89960: 9004, 89939: 9005, 89884: 9006, 89893: 9007, 53871: 9008, 53870: 9009, 53894: 9010, 53836: 9011, 53881: 9012, 53968: 9013, 53964: 9014, 53910: 9015, 53953: 9016, 53895: 9017, 53848: 9018, 53935: 9019, 84899: 9020, 89667: 9021, 84898: 9022, 89713: 9023, 89750: 9024, 89718: 9025, 84895: 9026, 89710: 9027, 89755: 9028, 89704: 9029, 84896: 9030, 84901: 9031, 89720: 9032, 89714: 9033, 84897: 9034, 89662: 9035, 89747: 9036, 89827: 9037, 89921: 9038, 89902: 9039, 89950: 9040, 89859: 9041, 89863: 9042, 89934: 9043, 89866: 9044, 89919: 9045, 53874: 9046, 53929: 9047, 53833: 9048, 53969: 9049, 53936: 9050, 53867: 9051, 89706: 9052, 84905: 9053, 89738: 9054, 89759: 9055, 89726: 9056, 84904: 9057, 89757: 9058, 89740: 9059, 89722: 9060, 89745: 9061, 89735: 9062, 89701: 9063, 84893: 9064, 89858: 9065, 89959: 9066, 89857: 9067, 89922: 9068, 89954: 9069, 89924: 9070, 89729: 9071, 84903: 9072, 89727: 9073, 89947: 9074, 89899: 9075, 89851: 9076, 89911: 9077, 89865: 9078, 89920: 9079, 89935: 9080, 53976: 9081, 53928: 9082, 89944: 9083, 89885: 9084, 89719: 9085, 84890: 9086, 89746: 9087, 89741: 9088, 89749: 9089, 89668: 9090, 89732: 9091, 89914: 9092, 89669: 9093, 84892: 9094, 89731: 9095, 89895: 9096, 89852: 9097, 89868: 9098, 89927: 9099, 89967: 9100, 84902: 9101, 89665: 9102, 53864: 9103, 53957: 9104, 53840: 9105, 53923: 9106, 53868: 9107, 89739: 9108, 89709: 9109, 89758: 9110, 89721: 9111, 89748: 9112, 89723: 9113, 89962: 9114, 89928: 9115, 89948: 9116, 89854: 9117, 89953: 9118, 89661: 9119, 89881: 9120, 89969: 9121, 89882: 9122, 89943: 9123, 89743: 9124, 89933: 9125, 89912: 9126, 89890: 9127, 89856: 9128, 89744: 9129, 89733: 9130, 89753: 9131, 89937: 9132, 89958: 9133, 89830: 9134, 89964: 9135, 89951: 9136, 89712: 9137, 89734: 9138, 89862: 9139, 89961: 9140, 89897: 9141, 89903: 9142, 89828: 9143, 53905: 9144, 53938: 9145, 53930: 9146, 53975: 9147, 89870: 9148, 89825: 9149, 89955: 9150, 89909: 9151, 89970: 9152, 89930: 9153, 53839: 9154, 53955: 9155, 53849: 9156, 53941: 9157, 89826: 9158, 89730: 9159, 89918: 9160, 89915: 9161, 89966: 9162, 89916: 9163, 53908: 9164, 53932: 9165, 89708: 9166, 89728: 9167, 89931: 9168, 89664: 9169, 89942: 9170, 89941: 9171, 89907: 9172, 89905: 9173, 89760: 9174, 89888: 9175, 89891: 9176, 89926: 9177, 53876: 9178, 89860: 9179, 89855: 9180, 89824: 9181, 89887: 9182, 89883: 9183, 89898: 9184, 53942: 9185, 53842: 9186, 53852: 9187, 53956: 9188, 53926: 9189, 53902: 9190, 53896: 9191, 53959: 9192, 53851: 9193, 53844: 9194, 89957: 9195, 89956: 9196, 53846: 9197, 53934: 9198, 53847: 9199, 89913: 9200, 89900: 9201, 89910: 9202, 53937: 9203, 89952: 9204, 89901: 9205, 89869: 9206, 89822: 9207, 89908: 9208, 89936: 9209, 53869: 9210, 89886: 9211, 89861: 9212, 89889: 9213, 89892: 9214, 89864: 9215, 89705: 9216, 53961: 9217, 53912: 9218, 53939: 9219, 53924: 9220, 89894: 9221, 89963: 9222, 89938: 9223, 89940: 9224, 89904: 9225, 89821: 9226, 53882: 9227, 89737: 9228, 89853: 9229, 89925: 9230, 53954: 9231, 53879: 9232, 89929: 9233, 53873: 9234, 89949: 9235, 53933: 9236, 53904: 9237, 89917: 9238, 89945: 9239, 53835: 9240, 53834: 9241, 89867: 9242, 89906: 9243, 89932: 9244, 53872: 9245, 53903: 9246, 53877: 9247, 53909: 9248, 53838: 9249, 53958: 9250, 54007: 9251, 54051: 9252, 54079: 9253, 54274: 9254, 90651: 9255, 90335: 9256, 90495: 9257, 90377: 9258, 54394: 9259, 54373: 9260, 54190: 9261, 54418: 9262, 54220: 9263, 54331: 9264, 54238: 9265, 90437: 9266, 90326: 9267, 90543: 9268, 90473: 9269, 90512: 9270, 90368: 9271, 90365: 9272, 90416: 9273, 90452: 9274, 90600: 9275, 90329: 9276, 54307: 9277, 54298: 9278, 90658: 9279, 90332: 9280, 90338: 9281, 90639: 9282, 90698: 9283, 90654: 9284, 90645: 9285, 54400: 9286, 54286: 9287, 54367: 9288, 54376: 9289, 90521: 9290, 90540: 9291, 90350: 9292, 90712: 9293, 90344: 9294, 54391: 9295, 54325: 9296, 54280: 9297, 54172: 9298, 54343: 9299, 54214: 9300, 54178: 9301, 90534: 9302, 90404: 9303, 90320: 9304, 90642: 9305, 90455: 9306, 90572: 9307, 90440: 9308, 90353: 9309, 90314: 9310, 90648: 9311, 90581: 9312, 90709: 9313, 90428: 9314, 90591: 9315, 90524: 9316, 54163: 9317, 90489: 9318, 90688: 9319, 90401: 9320, 90398: 9321, 90389: 9322, 90603: 9323, 54301: 9324, 54361: 9325, 54328: 9326, 90356: 9327, 90633: 9328, 90410: 9329, 90693: 9330, 54316: 9331, 90479: 9332, 90392: 9333, 54403: 9334, 54337: 9335, 90518: 9336, 54181: 9337, 90383: 9338, 90537: 9339, 90374: 9340, 54415: 9341, 54229: 9342, 90323: 9343, 90501: 9344, 90458: 9345, 90422: 9346, 90597: 9347, 90431: 9348, 90636: 9349, 54322: 9350, 54184: 9351, 54355: 9352, 90483: 9353, 54241: 9354, 54244: 9355, 54379: 9356, 54256: 9357, 54226: 9358, 90578: 9359, 90419: 9360, 90486: 9361, 54166: 9362, 54340: 9363, 54187: 9364, 90446: 9365, 90449: 9366, 90425: 9367, 54253: 9368, 90341: 9369, 54364: 9370, 90594: 9371, 90317: 9372, 90531: 9373, 54346: 9374, 90407: 9375, 90706: 9376, 90718: 9377, 90715: 9378, 86343: 9379, 86509: 9380, 86323: 9381, 86325: 9382, 86316: 9383, 86354: 9384, 86348: 9385, 86450: 9386, 86353: 9387, 58810: 9388, 86319: 9389, 86446: 9390, 86324: 9391, 86534: 9392, 86442: 9393, 86350: 9394, 86553: 9395, 86753: 9396, 86602: 9397, 86668: 9398, 86646: 9399, 86624: 9400, 86533: 9401, 86557: 9402, 86344: 9403, 86511: 9404, 86349: 9405, 53773: 9406, 58825: 9407, 86766: 9408, 86736: 9409, 86738: 9410, 86671: 9411, 86757: 9412, 86355: 9413, 86454: 9414, 86529: 9415, 86357: 9416, 53798: 9417, 86650: 9418, 86733: 9419, 58799: 9420, 58824: 9421, 86322: 9422, 86358: 9423, 86549: 9424, 86555: 9425, 86537: 9426, 53787: 9427, 58798: 9428, 53793: 9429, 86352: 9430, 86318: 9431, 86556: 9432, 58817: 9433, 58802: 9434, 86345: 9435, 86552: 9436, 86519: 9437, 86448: 9438, 86539: 9439, 86315: 9440, 86531: 9441, 86530: 9442, 86541: 9443, 86517: 9444, 86542: 9445, 86580: 9446, 86607: 9447, 86731: 9448, 86669: 9449, 86758: 9450, 58811: 9451, 86649: 9452, 86755: 9453, 86551: 9454, 86521: 9455, 86327: 9456, 86332: 9457, 86346: 9458, 86329: 9459, 53780: 9460, 86604: 9461, 86726: 9462, 86665: 9463, 86724: 9464, 86735: 9465, 86313: 9466, 86328: 9467, 86532: 9468, 86356: 9469, 53781: 9470, 86747: 9471, 86740: 9472, 86742: 9473, 86647: 9474, 86444: 9475, 86545: 9476, 53796: 9477, 86576: 9478, 86762: 9479, 86660: 9480, 86347: 9481, 86440: 9482, 86320: 9483, 86523: 9484, 86642: 9485, 86314: 9486, 86456: 9487, 86622: 9488, 86628: 9489, 86630: 9490, 86536: 9491, 86341: 9492, 86538: 9493, 86625: 9494, 86643: 9495, 86664: 9496, 86515: 9497, 86547: 9498, 86581: 9499, 86606: 9500, 86609: 9501, 86574: 9502, 86342: 9503, 86573: 9504, 86572: 9505, 86626: 9506, 86317: 9507, 86631: 9508, 86770: 9509, 86361: 9510, 86749: 9511, 86331: 9512, 53800: 9513, 86722: 9514, 86737: 9515, 86743: 9516, 86575: 9517, 86765: 9518, 86732: 9519, 86763: 9520, 140086: 9521, 54413: 9522, 54414: 9523, 54072: 9524, 54073: 9525, 54074: 9526, 53992: 9527, 53993: 9528, 53994: 9529, 54068: 9530, 54069: 9531, 54070: 9532, 54088: 9533, 54089: 9534, 54090: 9535, 54008: 9536, 54009: 9537, 54010: 9538, 54191: 9539, 54192: 9540, 54332: 9541, 54333: 9542, 54314: 9543, 54315: 9544, 90438: 9545, 90439: 9546, 90499: 9547, 90500: 9548, 97793: 9549, 97903: 9550, 97791: 9551, 65666: 9552, 65667: 9553, 65668: 9554, 90327: 9555, 90328: 9556, 90453: 9557, 90454: 9558, 90601: 9559, 90602: 9560, 54263: 9561, 54264: 9562, 54398: 9563, 54399: 9564, 90640: 9565, 90641: 9566, 54359: 9567, 54360: 9568, 54401: 9569, 54402: 9570, 54287: 9571, 54288: 9572, 54052: 9573, 54053: 9574, 54054: 9575, 54048: 9576, 54049: 9577, 54050: 9578, 53988: 9579, 53989: 9580, 53990: 9581, 97775: 9582, 52847: 9583, 52848: 9584, 52976: 9585, 52977: 9586, 108944: 9587, 54028: 9588, 54029: 9589, 54030: 9590, 108902: 9591, 54040: 9592, 54041: 9593, 54042: 9594, 54044: 9595, 54045: 9596, 54046: 9597, 108952: 9598, 108983: 9599, 108916: 9600, 108970: 9601, 54392: 9602, 54393: 9603, 54221: 9604, 54222: 9605, 54281: 9606, 54282: 9607, 54269: 9608, 54270: 9609, 54016: 9610, 54017: 9611, 54018: 9612, 54080: 9613, 54081: 9614, 54082: 9615, 54092: 9616, 54093: 9617, 54094: 9618, 97777: 9619, 97795: 9620, 90417: 9621, 90418: 9622, 90535: 9623, 90536: 9624, 90405: 9625, 90406: 9626, 90321: 9627, 90322: 9628, 90351: 9629, 90352: 9630, 90643: 9631, 90644: 9632, 90456: 9633, 90457: 9634, 90441: 9635, 90442: 9636, 90381: 9637, 90382: 9638, 90592: 9639, 90593: 9640, 90526: 9641, 90528: 9642, 90330: 9643, 90331: 9644, 54084: 9645, 54085: 9646, 54086: 9647, 54056: 9648, 54057: 9649, 54058: 9650, 54004: 9651, 54005: 9652, 54006: 9653, 109003: 9654, 108974: 9655, 108911: 9656, 65786: 9657, 65787: 9658, 65788: 9659, 65734: 9660, 65735: 9661, 65736: 9662, 97839: 9663, 97911: 9664, 97806: 9665, 97907: 9666, 65670: 9667, 65671: 9668, 65672: 9669, 65774: 9670, 65775: 9671, 65776: 9672, 97887: 9673, 97918: 9674, 97833: 9675, 53018: 9676, 53019: 9677, 52991: 9678, 52992: 9679, 52988: 9680, 52989: 9681, 52874: 9682, 52875: 9683, 52949: 9684, 52950: 9685, 54293: 9686, 54294: 9687, 54206: 9688, 54207: 9689, 54100: 9690, 54101: 9691, 54102: 9692, 54407: 9693, 90354: 9694, 90355: 9695, 54408: 9696, 54431: 9697, 54323: 9698, 54324: 9699, 65766: 9700, 65767: 9701, 65768: 9702, 65810: 9703, 65811: 9704, 65812: 9705, 53021: 9706, 53022: 9707, 54248: 9708, 54249: 9709, 97855: 9710, 97898: 9711, 97786: 9712, 97923: 9713, 97894: 9714, 97865: 9715, 97799: 9716, 97814: 9717, 97915: 9718, 97857: 9719, 65806: 9720, 65807: 9721, 65808: 9722, 54224: 9723, 54225: 9724, 54404: 9725, 54405: 9726, 54380: 9727, 54381: 9728, 54257: 9729, 54258: 9730, 54194: 9731, 54195: 9732, 54302: 9733, 54303: 9734, 54308: 9735, 54309: 9736, 54260: 9737, 54261: 9738, 54386: 9739, 54387: 9740, 54383: 9741, 54384: 9742, 54203: 9743, 54204: 9744, 52952: 9745, 52953: 9746, 54419: 9747, 54420: 9748, 54311: 9749, 54312: 9750, 54290: 9751, 54291: 9752, 97797: 9753, 97889: 9754, 97825: 9755, 97837: 9756, 65678: 9757, 65679: 9758, 65680: 9759, 65706: 9760, 65707: 9761, 65708: 9762, 108991: 9763, 97811: 9764, 90652: 9765, 90653: 9766, 97891: 9767, 97866: 9768, 97782: 9769, 90487: 9770, 90488: 9771, 97854: 9772, 97823: 9773, 97794: 9774, 97779: 9775, 97781: 9776, 97925: 9777, 97873: 9778, 54251: 9779, 54252: 9780, 90393: 9781, 90394: 9782, 90595: 9783, 90596: 9784, 54317: 9785, 54318: 9786, 97843: 9787, 97875: 9788, 54170: 9789, 54171: 9790, 90459: 9791, 90460: 9792, 90324: 9793, 90325: 9794, 97877: 9795, 97773: 9796, 97849: 9797, 97818: 9798, 54179: 9799, 54180: 9800, 97930: 9801, 97851: 9802, 97895: 9803, 97870: 9804, 54305: 9805, 54306: 9806, 54197: 9807, 54198: 9808, 97902: 9809, 97802: 9810, 97831: 9811, 54389: 9812, 54390: 9813, 54227: 9814, 54228: 9815, 90372: 9816, 90373: 9817, 90522: 9818, 90523: 9819, 90390: 9820, 90391: 9821, 90318: 9822, 90319: 9823, 90429: 9824, 90430: 9825, 90369: 9826, 90370: 9827, 97890: 9828, 54326: 9829, 54327: 9830, 54173: 9831, 54174: 9832, 90357: 9833, 90358: 9834, 54236: 9835, 54237: 9836, 90582: 9837, 90583: 9838, 97853: 9839, 97859: 9840, 97830: 9841, 65690: 9842, 65691: 9843, 65692: 9844, 65746: 9845, 65747: 9846, 65748: 9847, 52937: 9848, 52938: 9849, 52886: 9850, 52887: 9851, 51437: 9852, 51470: 9853, 51427: 9854, 51419: 9855, 57716: 9856, 57701: 9857, 57662: 9858, 58569: 9859, 57707: 9860, 57686: 9861, 58542: 9862, 92326: 9863, 57692: 9864, 57689: 9865, 57683: 9866, 47046: 9867, 47078: 9868, 47044: 9869, 47141: 9870, 47069: 9871, 58548: 9872, 57680: 9873, 58554: 9874, 58536: 9875, 58551: 9876, 57644: 9877, 57704: 9878, 47132: 9879, 47051: 9880, 57665: 9881, 57671: 9882, 92323: 9883, 58527: 9884, 57677: 9885, 58590: 9886, 58521: 9887, 58512: 9888, 58533: 9889, 57719: 9890, 57668: 9891, 58593: 9892, 57713: 9893, 58530: 9894, 58539: 9895, 58557: 9896, 57695: 9897, 57647: 9898, 58560: 9899, 58596: 9900, 47056: 9901, 47040: 9902, 47067: 9903, 57641: 9904, 47129: 9905, 47049: 9906, 47099: 9907, 47060: 9908, 47084: 9909, 57725: 9910, 57653: 9911, 57698: 9912, 58572: 9913, 51388: 9914, 51342: 9915, 57133: 9916, 51335: 9917, 51353: 9918, 51358: 9919, 51375: 9920, 51378: 9921, 51374: 9922, 51384: 9923, 51325: 9924, 51377: 9925, 51355: 9926, 51332: 9927, 51334: 9928, 51312: 9929, 51343: 9930, 51386: 9931, 51344: 9932, 51354: 9933, 57132: 9934, 48830: 9935, 48824: 9936, 58199: 9937, 57823: 9938, 57981: 9939, 57887: 9940, 58094: 9941, 58229: 9942, 57779: 9943, 57929: 9944, 57985: 9945, 58164: 9946, 58179: 9947, 57731: 9948, 57961: 9949, 58184: 9950, 57795: 9951, 58045: 9952, 57771: 9953, 58073: 9954, 57945: 9955, 57891: 9956, 57957: 9957, 58114: 9958, 58239: 9959, 58119: 9960, 57867: 9961, 58109: 9962, 57735: 9963, 58081: 9964, 58214: 9965, 58009: 9966, 58025: 9967, 58041: 9968, 57913: 9969, 57921: 9970, 58077: 9971, 58209: 9972, 57743: 9973, 58174: 9974, 58099: 9975, 58089: 9976, 57767: 9977, 57747: 9978, 57787: 9979, 57883: 9980, 58061: 9981, 57763: 9982, 57863: 9983, 58149: 9984, 57807: 9985, 57953: 9986, 58219: 9987, 57965: 9988, 57791: 9989, 57917: 9990, 57827: 9991, 58169: 9992, 57993: 9993, 58234: 9994, 58189: 9995, 57969: 9996, 57937: 9997, 57907: 9998, 57783: 9999, 57941: 10000, 58194: 10001, 57759: 10002, 57903: 10003, 57799: 10004, 58005: 10005, 58029: 10006, 58224: 10007, 58017: 10008, 57843: 10009, 57899: 10010, 47836: 10011, 47804: 10012, 47824: 10013, 47788: 10014, 47784: 10015, 47792: 10016, 58462: 10017, 47856: 10018, 47828: 10019, 47816: 10020, 47860: 10021, 47832: 10022, 47896: 10023, 47872: 10024, 48118: 10025, 48066: 10026, 48170: 10027, 58487: 10028, 47800: 10029, 47812: 10030, 47868: 10031, 47892: 10032, 47864: 10033, 58432: 10034, 58412: 10035, 47844: 10036, 47876: 10037, 48114: 10038, 48158: 10039, 47900: 10040, 47796: 10041, 47880: 10042, 58447: 10043, 48070: 10044, 47888: 10045, 48122: 10046, 47848: 10047, 46821: 10048, 46860: 10049, 46866: 10050, 46863: 10051, 57461: 10052, 57485: 10053, 57542: 10054, 57503: 10055, 57632: 10056, 57536: 10057, 57521: 10058, 57563: 10059, 57539: 10060, 57572: 10061, 57620: 10062, 57626: 10063, 57599: 10064, 46800: 10065, 46809: 10066, 46812: 10067, 46797: 10068, 57500: 10069, 57524: 10070, 57482: 10071, 46869: 10072, 46875: 10073, 46842: 10074, 46830: 10075, 46833: 10076, 46803: 10077, 46857: 10078, 57515: 10079, 57545: 10080, 46839: 10081, 46845: 10082, 57638: 10083, 57587: 10084, 57497: 10085, 57548: 10086, 57494: 10087, 57491: 10088, 57467: 10089, 57533: 10090, 57509: 10091, 57512: 10092, 57551: 10093, 46872: 10094, 57488: 10095, 57470: 10096, 57518: 10097, 57593: 10098, 46848: 10099, 57590: 10100, 57617: 10101, 57635: 10102, 57605: 10103, 57464: 10104, 57602: 10105, 46851: 10106, 57614: 10107, 57473: 10108, 57608: 10109, 57557: 10110, 57560: 10111, 46836: 10112, 46854: 10113, 46794: 10114, 57506: 10115, 57527: 10116, 57623: 10117, 57554: 10118, 57530: 10119, 57581: 10120, 46806: 10121, 46881: 10122, 57566: 10123, 57629: 10124, 57479: 10125, 57476: 10126, 46878: 10127, 57578: 10128, 91519: 10129, 91520: 10130, 91512: 10131, 91084: 10132, 91064: 10133, 91072: 10134, 91063: 10135, 91058: 10136, 91517: 10137, 91065: 10138, 91062: 10139, 91075: 10140, 91059: 10141, 91068: 10142, 91056: 10143, 91071: 10144, 91113: 10145, 91153: 10146, 91115: 10147, 91537: 10148, 91099: 10149, 91118: 10150, 91534: 10151, 91535: 10152, 91131: 10153, 91094: 10154, 91089: 10155, 91129: 10156, 91128: 10157, 91143: 10158, 91098: 10159, 91145: 10160, 91141: 10161, 91132: 10162, 91151: 10163, 91139: 10164, 91087: 10165, 91124: 10166, 91104: 10167, 91101: 10168, 91086: 10169, 91112: 10170, 91120: 10171, 92374: 10172, 92380: 10173, 92375: 10174, 92390: 10175, 92364: 10176, 92360: 10177, 92391: 10178, 92377: 10179, 92359: 10180, 92367: 10181, 92386: 10182, 92395: 10183, 92382: 10184, 92385: 10185, 92384: 10186, 92369: 10187, 74482: 10188, 74420: 10189, 74527: 10190, 74542: 10191, 74452: 10192, 74477: 10193, 74517: 10194, 74457: 10195, 74462: 10196, 74532: 10197, 74428: 10198, 74512: 10199, 74507: 10200, 74432: 10201, 74467: 10202, 74412: 10203, 74424: 10204, 74416: 10205, 74502: 10206, 74492: 10207, 74472: 10208, 74562: 10209, 74561: 10210, 74557: 10211, 74574: 10212, 74554: 10213, 74558: 10214, 74581: 10215, 74570: 10216, 74566: 10217, 74578: 10218, 74552: 10219, 74575: 10220, 74560: 10221, 74577: 10222, 74580: 10223, 74576: 10224, 74567: 10225, 74404: 10226, 74403: 10227, 74407: 10228, 69214: 10229, 68586: 10230, 68818: 10231, 69006: 10232, 74821: 10233, 69038: 10234, 69070: 10235, 74881: 10236, 68570: 10237, 74789: 10238, 68814: 10239, 68950: 10240, 74817: 10241, 74829: 10242, 69122: 10243, 69130: 10244, 68582: 10245, 68798: 10246, 69218: 10247, 69022: 10248, 74877: 10249, 68862: 10250, 74809: 10251, 74801: 10252, 69146: 10253, 68918: 10254, 74797: 10255, 69094: 10256, 74845: 10257, 69182: 10258, 69050: 10259, 68626: 10260, 68926: 10261, 74853: 10262, 68786: 10263, 68858: 10264, 68902: 10265, 68610: 10266, 74885: 10267, 68822: 10268, 68874: 10269, 68898: 10270, 68650: 10271, 68630: 10272, 68618: 10273, 68974: 10274, 69010: 10275, 68954: 10276, 68986: 10277, 68810: 10278, 69186: 10279, 69026: 10280, 69154: 10281, 68930: 10282, 68602: 10283, 69206: 10284, 68882: 10285, 68958: 10286, 74785: 10287, 68838: 10288, 68566: 10289, 68878: 10290, 68578: 10291, 74893: 10292, 69054: 10293, 69098: 10294, 69110: 10295, 68638: 10296, 68622: 10297, 69118: 10298, 69058: 10299, 68938: 10300, 68834: 10301, 68554: 10302, 68982: 10303, 68538: 10304, 68546: 10305, 68806: 10306, 68558: 10307, 69142: 10308, 68802: 10309, 69166: 10310, 69086: 10311, 69106: 10312, 69126: 10313, 69198: 10314, 68854: 10315, 69222: 10316, 74837: 10317, 68542: 10318, 68543: 10319, 68594: 10320, 74781: 10321, 68634: 10322, 69162: 10323, 69250: 10324, 69246: 10325, 68886: 10326, 69150: 10327, 69018: 10328, 68850: 10329, 69194: 10330, 69078: 10331, 74889: 10332, 68962: 10333, 68870: 10334, 88954: 10335, 71787: 10336, 88960: 10337, 71784: 10338, 71774: 10339, 71785: 10340, 71780: 10341, 71768: 10342, 71772: 10343, 71795: 10344, 88946: 10345, 71789: 10346, 88951: 10347, 71767: 10348, 71776: 10349, 88956: 10350, 71777: 10351, 71783: 10352, 88957: 10353, 71794: 10354, 71778: 10355, 88945: 10356, 71701: 10357, 71651: 10358, 71683: 10359, 71698: 10360, 71722: 10361, 88866: 10362, 71680: 10363, 88869: 10364, 71647: 10365, 88918: 10366, 71694: 10367, 71717: 10368, 71689: 10369, 71728: 10370, 71695: 10371, 71704: 10372, 71673: 10373, 88885: 10374, 71690: 10375, 89029: 10376, 71681: 10377, 88867: 10378, 71685: 10379, 71662: 10380, 71710: 10381, 71724: 10382, 71675: 10383, 88899: 10384, 71686: 10385, 71640: 10386, 71655: 10387, 71725: 10388, 71668: 10389, 71682: 10390, 71672: 10391, 88877: 10392, 71693: 10393, 71696: 10394, 71674: 10395, 71718: 10396, 71707: 10397, 71705: 10398, 71700: 10399, 89022: 10400, 88876: 10401, 88907: 10402, 71645: 10403, 71714: 10404, 71692: 10405, 71653: 10406, 71671: 10407, 88911: 10408, 71656: 10409, 71664: 10410, 71713: 10411, 71660: 10412, 71676: 10413, 88879: 10414, 71697: 10415, 89025: 10416, 71659: 10417, 71684: 10418, 71712: 10419, 71666: 10420, 71648: 10421, 71641: 10422, 89024: 10423, 88920: 10424, 71663: 10425, 88921: 10426, 88889: 10427, 71687: 10428, 89039: 10429, 88878: 10430, 88923: 10431, 89038: 10432, 88910: 10433, 89026: 10434, 88902: 10435, 88882: 10436, 89030: 10437, 89037: 10438, 88868: 10439, 71667: 10440, 88940: 10441, 88933: 10442, 88931: 10443, 88927: 10444, 88935: 10445, 88926: 10446, 89419: 10447, 89422: 10448, 89451: 10449, 89425: 10450, 89434: 10451, 89390: 10452, 89411: 10453, 89384: 10454, 75716: 10455, 89393: 10456, 89375: 10457, 89409: 10458, 89461: 10459, 89385: 10460, 89366: 10461, 89431: 10462, 89417: 10463, 75700: 10464, 75684: 10465, 89396: 10466, 89439: 10467, 89399: 10468, 89391: 10469, 89383: 10470, 89442: 10471, 89369: 10472, 75699: 10473, 75664: 10474, 75698: 10475, 75651: 10476, 89413: 10477, 89360: 10478, 89420: 10479, 89382: 10480, 89450: 10481, 89357: 10482, 75637: 10483, 89441: 10484, 75653: 10485, 89460: 10486, 75683: 10487, 75632: 10488, 75689: 10489, 75662: 10490, 75707: 10491, 89436: 10492, 89379: 10493, 89408: 10494, 75663: 10495, 75641: 10496, 75648: 10497, 75642: 10498, 75644: 10499, 75636: 10500, 75678: 10501, 75652: 10502, 75711: 10503, 75646: 10504, 75718: 10505, 89447: 10506, 75676: 10507, 89438: 10508, 89388: 10509, 89394: 10510, 89351: 10511, 75695: 10512, 89368: 10513, 89378: 10514, 89401: 10515, 89389: 10516, 89403: 10517, 89466: 10518, 89437: 10519, 75712: 10520, 75645: 10521, 75670: 10522, 75719: 10523, 89532: 10524, 75497: 10525, 75593: 10526, 75568: 10527, 75600: 10528, 75479: 10529, 75487: 10530, 75573: 10531, 75608: 10532, 89521: 10533, 89482: 10534, 89488: 10535, 89516: 10536, 89589: 10537, 89561: 10538, 89533: 10539, 89563: 10540, 89582: 10541, 89523: 10542, 89540: 10543, 89526: 10544, 89527: 10545, 75526: 10546, 75603: 10547, 75495: 10548, 89485: 10549, 89507: 10550, 89473: 10551, 89489: 10552, 75473: 10553, 75616: 10554, 75607: 10555, 89551: 10556, 89553: 10557, 89486: 10558, 89541: 10559, 75584: 10560, 75490: 10561, 75509: 10562, 75559: 10563, 71496: 10564, 71215: 10565, 71262: 10566, 71201: 10567, 71234: 10568, 71122: 10569, 71466: 10570, 71576: 10571, 71470: 10572, 71449: 10573, 71458: 10574, 71325: 10575, 71549: 10576, 71241: 10577, 71290: 10578, 71182: 10579, 71485: 10580, 71161: 10581, 71451: 10582, 71436: 10583, 71443: 10584, 71429: 10585, 71532: 10586, 71431: 10587, 71276: 10588, 71157: 10589, 71213: 10590, 71535: 10591, 84887: 10592, 84958: 10593, 84723: 10594, 84954: 10595, 84835: 10596, 84935: 10597, 84934: 10598, 84911: 10599, 84830: 10600, 84784: 10601, 84912: 10602, 84914: 10603, 84931: 10604, 84927: 10605, 84930: 10606, 84836: 10607, 84722: 10608, 84922: 10609, 84928: 10610, 84910: 10611, 84925: 10612, 84963: 10613, 61263: 10614, 61303: 10615, 61301: 10616, 61270: 10617, 61331: 10618, 60211: 10619, 61391: 10620, 61387: 10621, 60193: 10622, 60313: 10623, 60319: 10624, 61319: 10625, 60241: 10626, 60325: 10627, 60004: 10628, 59978: 10629, 59995: 10630, 60035: 10631, 60024: 10632, 60011: 10633, 60012: 10634, 60022: 10635, 59987: 10636, 59996: 10637, 60010: 10638, 60015: 10639, 59983: 10640, 60002: 10641, 59986: 10642, 60026: 10643, 60020: 10644, 59988: 10645, 59992: 10646, 60021: 10647, 60000: 10648, 59993: 10649, 60033: 10650, 59980: 10651, 59977: 10652, 60027: 10653, 59979: 10654, 59990: 10655, 59998: 10656, 60016: 10657, 60014: 10658, 60031: 10659, 60013: 10660, 53565: 10661, 85411: 10662, 85419: 10663, 53701: 10664, 85362: 10665, 84821: 10666, 85382: 10667, 85390: 10668, 85358: 10669, 84755: 10670, 85466: 10671, 85322: 10672, 85301: 10673, 53725: 10674, 85283: 10675, 85446: 10676, 53749: 10677, 85470: 10678, 84776: 10679, 84747: 10680, 80902: 10681, 80862: 10682, 80895: 10683, 80896: 10684, 80897: 10685, 80870: 10686, 61198: 10687, 61159: 10688, 61124: 10689, 61146: 10690, 61127: 10691, 61176: 10692, 60061: 10693, 61209: 10694, 61156: 10695, 61154: 10696, 61197: 10697, 61174: 10698, 61138: 10699, 61237: 10700, 61214: 10701, 48078: 10702, 61140: 10703, 61167: 10704, 61231: 10705, 61188: 10706, 61219: 10707, 61207: 10708, 61232: 10709, 61201: 10710, 61220: 10711, 59954: 10712, 59929: 10713, 59857: 10714, 59867: 10715, 59935: 10716, 59893: 10717, 84668: 10718, 59927: 10719, 59919: 10720, 59952: 10721, 59886: 10722, 85214: 10723, 59925: 10724, 59870: 10725, 59901: 10726, 84675: 10727, 59900: 10728, 59911: 10729, 59959: 10730, 59868: 10731, 59863: 10732, 59892: 10733, 71371: 10734, 71374: 10735, 71393: 10736, 86280: 10737, 86282: 10738, 86278: 10739, 86262: 10740, 86286: 10741, 86383: 10742, 86283: 10743, 86391: 10744, 86240: 10745, 86382: 10746, 86372: 10747, 86287: 10748, 86374: 10749, 86297: 10750, 86281: 10751, 86306: 10752, 86300: 10753, 86242: 10754, 86269: 10755, 86293: 10756, 86289: 10757, 86370: 10758, 86243: 10759, 61514: 10760, 61706: 10761, 61637: 10762, 61505: 10763, 61679: 10764, 61676: 10765, 61613: 10766, 61490: 10767, 61475: 10768, 61445: 10769, 61478: 10770, 61472: 10771, 61700: 10772, 61439: 10773, 61511: 10774, 61502: 10775, 61574: 10776, 61697: 10777, 61457: 10778, 61571: 10779, 61442: 10780, 61670: 10781, 61523: 10782, 85578: 10783, 85538: 10784, 85562: 10785, 85559: 10786, 85577: 10787, 85567: 10788, 85565: 10789, 85568: 10790, 85545: 10791, 85602: 10792, 85540: 10793, 85542: 10794, 85571: 10795, 85600: 10796, 85603: 10797, 85605: 10798, 85608: 10799, 85583: 10800, 85591: 10801, 85572: 10802, 85582: 10803, 85610: 10804, 85611: 10805, 85619: 10806, 85530: 10807, 85622: 10808, 85548: 10809, 85595: 10810, 85564: 10811, 85576: 10812, 85573: 10813, 85534: 10814, 85579: 10815, 85552: 10816, 85574: 10817, 85533: 10818, 85546: 10819, 85597: 10820, 85594: 10821, 85561: 10822, 85588: 10823, 85560: 10824, 85627: 10825, 85620: 10826, 85616: 10827, 85589: 10828, 85580: 10829, 85585: 10830, 85563: 10831, 85531: 10832, 85541: 10833, 85575: 10834, 85529: 10835, 85621: 10836, 85615: 10837, 85535: 10838, 85544: 10839, 85539: 10840, 85557: 10841, 85613: 10842, 85618: 10843, 85625: 10844, 85549: 10845, 85609: 10846, 85598: 10847, 85570: 10848, 85547: 10849, 85624: 10850, 85626: 10851, 85558: 10852, 85569: 10853, 85584: 10854, 85586: 10855, 85526: 10856, 85592: 10857, 85527: 10858, 85555: 10859, 85604: 10860, 85528: 10861, 85581: 10862, 85599: 10863, 85607: 10864, 84738: 10865, 85341: 10866, 84730: 10867, 84734: 10868, 84735: 10869, 85271: 10870, 85338: 10871, 85269: 10872, 90940: 10873, 90919: 10874, 90945: 10875, 90923: 10876, 90848: 10877, 90837: 10878, 91625: 10879, 90842: 10880, 91636: 10881, 90960: 10882, 90931: 10883, 90844: 10884, 90949: 10885, 90917: 10886, 90918: 10887, 91635: 10888, 91611: 10889, 90858: 10890, 90930: 10891, 91630: 10892, 90916: 10893, 90840: 10894, 91631: 10895, 90927: 10896, 90915: 10897, 91606: 10898, 90948: 10899, 90946: 10900, 54981: 10901, 54535: 10902, 54573: 10903, 54581: 10904, 54589: 10905, 54544: 10906, 54571: 10907, 54555: 10908, 54606: 10909, 54601: 10910, 54463: 10911, 54469: 10912, 75323: 10913, 75336: 10914, 75328: 10915, 75327: 10916, 75308: 10917, 75331: 10918, 75329: 10919, 75321: 10920, 75311: 10921, 75310: 10922, 75324: 10923, 75317: 10924, 107682: 10925, 107683: 10926, 107684: 10927, 107796: 10928, 107797: 10929, 107798: 10930, 107789: 10931, 107790: 10932, 107791: 10933, 107746: 10934, 107747: 10935, 107748: 10936, 107869: 10937, 107870: 10938, 107871: 10939, 107820: 10940, 107821: 10941, 107822: 10942, 107757: 10943, 107758: 10944, 107759: 10945, 107771: 10946, 107772: 10947, 107773: 10948, 107813: 10949, 107814: 10950, 107815: 10951, 107775: 10952, 107776: 10953, 107777: 10954, 107671: 10955, 107672: 10956, 107673: 10957, 107718: 10958, 107719: 10959, 107720: 10960, 107866: 10961, 107867: 10962, 107868: 10963, 107803: 10964, 107804: 10965, 107805: 10966, 107678: 10967, 107679: 10968, 107680: 10969, 55011: 10970, 55027: 10971, 55038: 10972, 55028: 10973, 55035: 10974, 55025: 10975, 55023: 10976, 55039: 10977, 55029: 10978, 55019: 10979, 55017: 10980, 55040: 10981, 55034: 10982, 55036: 10983, 55015: 10984, 55022: 10985, 55013: 10986, 55037: 10987, 55016: 10988, 55031: 10989, 55026: 10990, 55012: 10991, 69215: 10992, 69216: 10993, 69217: 10994, 68587: 10995, 68588: 10996, 68589: 10997, 55009: 10998, 69039: 10999, 54996: 11000, 69071: 11001, 69072: 11002, 69073: 11003, 74882: 11004, 74883: 11005, 74884: 11006, 74818: 11007, 74819: 11008, 74820: 11009, 54982: 11010, 54995: 11011, 55004: 11012, 55001: 11013, 55000: 11014, 74830: 11015, 74831: 11016, 74832: 11017, 55005: 11018, 68583: 11019, 68584: 11020, 68585: 11021, 74878: 11022, 74879: 11023, 74880: 11024, 74802: 11025, 74803: 11026, 74804: 11027, 69147: 11028, 69148: 11029, 69149: 11030, 68919: 11031, 68920: 11032, 68921: 11033, 74798: 11034, 74799: 11035, 74800: 11036, 69095: 11037, 69096: 11038, 69097: 11039, 74846: 11040, 74847: 11041, 74848: 11042, 69183: 11043, 69184: 11044, 69185: 11045, 69051: 11046, 69052: 11047, 69053: 11048, 68927: 11049, 68928: 11050, 68929: 11051, 68611: 11052, 68612: 11053, 68613: 11054, 68823: 11055, 68824: 11056, 68825: 11057, 54999: 11058, 54992: 11059, 55007: 11060, 54993: 11061, 54989: 11062, 55006: 11063, 54990: 11064, 54984: 11065, 55010: 11066, 68815: 11067, 68816: 11068, 68817: 11069, 68651: 11070, 68652: 11071, 68653: 11072, 68631: 11073, 68632: 11074, 68633: 11075, 54985: 11076, 69011: 11077, 69012: 11078, 69013: 11079, 68987: 11080, 68988: 11081, 68989: 11082, 54991: 11083, 54994: 11084, 69027: 11085, 69028: 11086, 69029: 11087, 69155: 11088, 69156: 11089, 69157: 11090, 68931: 11091, 68932: 11092, 68933: 11093, 68603: 11094, 68604: 11095, 68605: 11096, 68863: 11097, 68864: 11098, 68865: 11099, 69207: 11100, 69208: 11101, 69209: 11102, 68883: 11103, 68884: 11104, 68885: 11105, 68959: 11106, 68960: 11107, 68961: 11108, 74786: 11109, 74787: 11110, 74788: 11111, 68619: 11112, 68620: 11113, 68621: 11114, 69007: 11115, 69008: 11116, 69009: 11117, 68579: 11118, 68580: 11119, 68581: 11120, 74894: 11121, 74895: 11122, 74896: 11123, 69055: 11124, 69056: 11125, 69057: 11126, 68639: 11127, 68640: 11128, 68641: 11129, 69119: 11130, 69120: 11131, 69121: 11132, 74822: 11133, 74823: 11134, 74824: 11135, 68939: 11136, 68940: 11137, 68941: 11138, 68835: 11139, 68836: 11140, 68837: 11141, 68555: 11142, 68556: 11143, 68557: 11144, 68547: 11145, 68548: 11146, 68549: 11147, 68807: 11148, 68808: 11149, 68809: 11150, 68559: 11151, 68560: 11152, 68561: 11153, 69143: 11154, 69144: 11155, 69145: 11156, 68803: 11157, 68804: 11158, 68805: 11159, 69167: 11160, 69168: 11161, 69169: 11162, 74790: 11163, 74791: 11164, 74792: 11165, 68799: 11166, 68800: 11167, 68801: 11168, 54998: 11169, 68855: 11170, 68856: 11171, 68857: 11172, 55008: 11173, 55003: 11174, 69223: 11175, 69224: 11176, 69225: 11177, 69187: 11178, 69188: 11179, 69189: 11180, 74838: 11181, 74839: 11182, 74840: 11183, 68875: 11184, 68876: 11185, 68877: 11186, 68544: 11187, 68545: 11188, 69040: 11189, 69041: 11190, 68635: 11191, 68636: 11192, 68637: 11193, 69163: 11194, 69164: 11195, 69165: 11196, 69199: 11197, 69200: 11198, 69201: 11199, 55002: 11200, 54983: 11201, 69251: 11202, 69252: 11203, 69253: 11204, 54986: 11205, 69151: 11206, 69152: 11207, 69153: 11208, 69019: 11209, 69020: 11210, 69021: 11211, 68851: 11212, 68595: 11213, 68596: 11214, 68597: 11215, 91778: 11216, 91779: 11217, 58200: 11218, 58201: 11219, 58202: 11220, 58203: 11221, 46822: 11222, 46823: 11223, 57462: 11224, 57463: 11225, 57486: 11226, 57487: 11227, 91780: 11228, 91781: 11229, 91746: 11230, 91747: 11231, 91748: 11232, 91749: 11233, 91790: 11234, 91750: 11235, 91726: 11236, 74483: 11237, 74484: 11238, 74485: 11239, 74486: 11240, 53566: 11241, 53567: 11242, 53568: 11243, 53734: 11244, 53735: 11245, 53736: 11246, 57717: 11247, 57718: 11248, 57702: 11249, 57703: 11250, 57663: 11251, 57664: 11252, 61707: 11253, 61708: 11254, 85412: 11255, 85413: 11256, 85414: 11257, 84756: 11258, 84757: 11259, 91791: 11260, 91792: 11261, 91793: 11262, 58095: 11263, 58096: 11264, 58097: 11265, 58098: 11266, 58230: 11267, 58231: 11268, 58232: 11269, 58233: 11270, 57780: 11271, 57781: 11272, 57782: 11273, 61638: 11274, 61639: 11275, 61506: 11276, 61507: 11277, 71217: 11278, 71219: 11279, 71221: 11280, 71223: 11281, 71225: 11282, 71226: 11283, 91786: 11284, 58180: 11285, 58181: 11286, 58182: 11287, 58183: 11288, 57540: 11289, 57541: 11290, 57573: 11291, 57574: 11292, 46801: 11293, 46802: 11294, 46867: 11295, 46868: 11296, 46810: 11297, 46811: 11298, 47825: 11299, 47826: 11300, 47827: 11301, 47789: 11302, 47790: 11303, 47791: 11304, 47785: 11305, 47786: 11306, 47787: 11307, 46870: 11308, 46871: 11309, 47793: 11310, 47794: 11311, 47795: 11312, 46843: 11313, 46844: 11314, 46831: 11315, 46832: 11316, 74421: 11317, 74422: 11318, 74423: 11319, 53574: 11320, 53575: 11321, 53576: 11322, 47857: 11323, 47858: 11324, 47859: 11325, 71263: 11326, 71264: 11327, 71265: 11328, 71266: 11329, 71267: 11330, 71268: 11331, 58463: 11332, 53674: 11333, 53675: 11334, 53676: 11335, 58185: 11336, 58186: 11337, 58187: 11338, 58188: 11339, 91774: 11340, 80843: 11341, 80844: 11342, 80845: 11343, 47805: 11344, 47806: 11345, 47807: 11346, 47897: 11347, 47898: 11348, 47899: 11349, 47837: 11350, 47838: 11351, 46840: 11352, 46841: 11353, 48119: 11354, 48120: 11355, 48121: 11356, 58543: 11357, 74528: 11358, 74529: 11359, 74530: 11360, 74531: 11361, 47839: 11362, 47801: 11363, 47802: 11364, 47803: 11365, 47813: 11366, 47814: 11367, 61680: 11368, 61681: 11369, 61488: 11370, 61489: 11371, 61614: 11372, 61615: 11373, 71123: 11374, 71124: 11375, 71125: 11376, 71126: 11377, 71127: 11378, 61491: 11379, 61492: 11380, 47815: 11381, 71204: 11382, 57693: 11383, 85511: 11384, 85512: 11385, 85513: 11386, 85420: 11387, 85421: 11388, 85422: 11389, 85467: 11390, 85468: 11391, 85469: 11392, 85278: 11393, 85279: 11394, 57694: 11395, 57684: 11396, 57690: 11397, 57691: 11398, 57685: 11399, 47142: 11400, 47143: 11401, 47070: 11402, 58544: 11403, 57681: 11404, 57682: 11405, 58555: 11406, 58556: 11407, 58537: 11408, 58538: 11409, 58552: 11410, 80699: 11411, 80700: 11412, 80701: 11413, 46804: 11414, 57498: 11415, 57499: 11416, 57549: 11417, 57550: 11418, 57468: 11419, 57469: 11420, 46805: 11421, 46864: 11422, 46865: 11423, 53702: 11424, 53703: 11425, 53704: 11426, 53666: 11427, 53667: 11428, 53668: 11429, 74543: 11430, 74544: 11431, 74545: 11432, 74546: 11433, 74453: 11434, 74454: 11435, 74455: 11436, 74456: 11437, 57546: 11438, 57547: 11439, 46813: 11440, 46814: 11441, 46858: 11442, 46859: 11443, 46873: 11444, 58115: 11445, 58116: 11446, 58117: 11447, 58118: 11448, 58240: 11449, 58241: 11450, 58242: 11451, 58243: 11452, 58120: 11453, 58121: 11454, 58122: 11455, 58123: 11456, 91718: 11457, 91719: 11458, 91720: 11459, 91721: 11460, 91782: 11461, 91738: 11462, 57736: 11463, 57737: 11464, 57738: 11465, 57594: 11466, 57595: 11467, 57537: 11468, 57538: 11469, 57501: 11470, 57502: 11471, 46849: 11472, 46850: 11473, 53698: 11474, 53699: 11475, 53700: 11476, 57591: 11477, 57592: 11478, 57513: 11479, 57514: 11480, 61446: 11481, 61447: 11482, 61479: 11483, 61480: 11484, 61473: 11485, 61474: 11486, 61701: 11487, 61702: 11488, 61440: 11489, 61441: 11490, 61635: 11491, 71242: 11492, 71243: 11493, 71244: 11494, 71245: 11495, 71246: 11496, 71247: 11497, 61636: 11498, 71202: 11499, 71206: 11500, 71208: 11501, 60316: 11502, 74458: 11503, 74459: 11504, 74460: 11505, 74461: 11506, 74518: 11507, 74519: 11508, 74520: 11509, 74521: 11510, 74463: 11511, 74464: 11512, 74465: 11513, 74466: 11514, 80827: 11515, 80828: 11516, 91742: 11517, 58215: 11518, 58216: 11519, 58217: 11520, 58218: 11521, 57588: 11522, 57589: 11523, 53622: 11524, 53623: 11525, 53624: 11526, 57914: 11527, 57915: 11528, 57916: 11529, 57516: 11530, 57517: 11531, 57615: 11532, 57616: 11533, 57474: 11534, 57475: 11535, 91739: 11536, 91740: 11537, 91741: 11538, 91722: 11539, 91723: 11540, 91724: 11541, 91725: 11542, 91770: 11543, 80839: 11544, 80840: 11545, 91771: 11546, 91772: 11547, 91773: 11548, 91754: 11549, 57525: 11550, 57526: 11551, 91751: 11552, 91752: 11553, 91753: 11554, 80841: 11555, 80815: 11556, 80816: 11557, 80817: 11558, 80803: 11559, 80804: 11560, 80805: 11561, 47865: 11562, 47866: 11563, 47867: 11564, 47833: 11565, 47834: 11566, 47835: 11567, 47877: 11568, 47878: 11569, 47879: 11570, 47861: 11571, 47862: 11572, 47863: 11573, 47829: 11574, 47830: 11575, 47831: 11576, 47797: 11577, 47798: 11578, 47799: 11579, 71183: 11580, 71186: 11581, 71188: 11582, 71192: 11583, 71196: 11584, 71198: 11585, 74429: 11586, 74430: 11587, 74431: 11588, 54545: 11589, 54546: 11590, 61656: 11591, 54509: 11592, 54510: 11593, 58528: 11594, 58529: 11595, 57678: 11596, 57679: 11597, 61392: 11598, 61393: 11599, 61394: 11600, 74513: 11601, 74514: 11602, 74515: 11603, 74516: 11604, 58591: 11605, 58592: 11606, 61657: 11607, 61512: 11608, 61513: 11609, 61575: 11610, 61576: 11611, 58522: 11612, 58523: 11613, 58513: 11614, 58514: 11615, 58534: 11616, 58535: 11617, 57720: 11618, 57721: 11619, 57669: 11620, 57670: 11621, 53606: 11622, 53607: 11623, 53608: 11624, 85363: 11625, 85364: 11626, 85365: 11627, 85416: 11628, 85417: 11629, 85418: 11630, 85391: 11631, 85392: 11632, 85393: 11633, 57666: 11634, 57667: 11635, 58594: 11636, 58595: 11637, 85447: 11638, 85448: 11639, 85449: 11640, 57600: 11641, 57601: 11642, 57534: 11643, 57535: 11644, 57558: 11645, 57559: 11646, 46837: 11647, 46838: 11648, 57639: 11649, 57640: 11650, 71162: 11651, 71165: 11652, 71168: 11653, 71171: 11654, 71174: 11655, 71176: 11656, 74433: 11657, 74434: 11658, 74435: 11659, 74468: 11660, 74469: 11661, 74470: 11662, 74471: 11663, 57714: 11664, 57715: 11665, 61698: 11666, 61699: 11667, 74425: 11668, 74426: 11669, 74427: 11670, 74417: 11671, 74418: 11672, 74419: 11673, 58531: 11674, 58532: 11675, 58540: 11676, 58541: 11677, 58558: 11678, 58559: 11679, 57648: 11680, 57649: 11681, 57672: 11682, 57673: 11683, 61458: 11684, 61459: 11685, 69195: 11686, 69196: 11687, 69197: 11688, 68623: 11689, 68624: 11690, 68625: 11691, 74890: 11692, 74891: 11693, 74892: 11694, 47130: 11695, 47131: 11696, 57726: 11697, 57727: 11698, 91734: 11699, 91762: 11700, 91763: 11701, 91764: 11702, 91765: 11703, 91755: 11704, 91756: 11705, 91757: 11706, 58100: 11707, 58101: 11708, 58102: 11709, 58103: 11710, 57748: 11711, 57749: 11712, 57750: 11713, 57555: 11714, 57556: 11715, 46795: 11716, 46796: 11717, 57504: 11718, 57505: 11719, 58062: 11720, 58063: 11721, 58064: 11722, 58034: 11723, 58035: 11724, 58036: 11725, 58038: 11726, 58039: 11727, 58040: 11728, 57884: 11729, 57885: 11730, 57886: 11731, 58150: 11732, 58151: 11733, 58152: 11734, 58153: 11735, 57808: 11736, 57809: 11737, 57810: 11738, 47889: 11739, 47890: 11740, 80735: 11741, 80736: 11742, 80737: 11743, 91766: 11744, 57483: 11745, 57484: 11746, 47893: 11747, 47894: 11748, 47895: 11749, 91730: 11750, 91731: 11751, 91732: 11752, 91733: 11753, 91783: 11754, 91784: 11755, 91785: 11756, 57918: 11757, 57919: 11758, 57920: 11759, 58170: 11760, 58171: 11761, 58172: 11762, 58173: 11763, 58235: 11764, 58236: 11765, 58237: 11766, 58238: 11767, 46852: 11768, 46853: 11769, 58190: 11770, 58191: 11771, 58192: 11772, 58193: 11773, 71277: 11774, 71278: 11775, 71279: 11776, 71280: 11777, 71281: 11778, 71282: 11779, 91767: 11780, 91768: 11781, 91769: 11782, 91758: 11783, 91759: 11784, 91760: 11785, 91761: 11786, 91735: 11787, 91736: 11788, 91737: 11789, 57630: 11790, 57631: 11791, 57480: 11792, 57481: 11793, 58195: 11794, 58196: 11795, 58197: 11796, 58198: 11797, 57609: 11798, 57610: 11799, 47849: 11800, 47850: 11801, 47851: 11802, 69099: 11803, 60212: 11804, 60214: 11805, 60217: 11806, 60219: 11807, 60221: 11808, 61443: 11809, 61444: 11810, 58553: 11811, 53762: 11812, 53763: 11813, 53764: 11814, 74473: 11815, 74474: 11816, 74475: 11817, 74476: 11818, 85302: 11819, 85303: 11820, 91714: 11821, 91715: 11822, 58006: 11823, 58007: 11824, 58008: 11825, 57624: 11826, 57625: 11827, 57552: 11828, 57553: 11829, 58175: 11830, 58176: 11831, 58177: 11832, 58178: 11833, 47881: 11834, 47882: 11835, 47883: 11836, 58030: 11837, 58031: 11838, 58032: 11839, 57954: 11840, 57955: 11841, 57956: 11842, 58018: 11843, 58019: 11844, 58020: 11845, 91743: 11846, 91744: 11847, 91745: 11848, 61548: 11849, 61671: 11850, 61672: 11851, 61503: 11852, 61504: 11853, 61524: 11854, 61525: 11855, 80703: 11856, 80704: 11857, 80705: 11858, 80687: 11859, 80688: 11860, 80689: 11861, 80887: 11862, 80888: 11863, 80889: 11864, 91787: 11865, 91788: 11866, 91789: 11867, 80847: 11868, 80848: 11869, 80849: 11870, 80831: 11871, 80832: 11872, 80833: 11873, 80879: 11874, 80880: 11875, 80881: 11876, 80795: 11877, 80796: 11878, 80797: 11879, 80829: 11880, 80727: 11881, 80728: 11882, 80729: 11883, 80907: 11884, 80908: 11885, 80909: 11886, 108986: 11887, 57627: 11888, 57628: 11889, 46807: 11890, 46808: 11891, 57699: 11892, 57700: 11893, 58573: 11894, 58086: 11895, 58087: 11896, 58088: 11897, 80711: 11898, 80712: 11899, 80713: 11900, 80863: 11901, 80864: 11902, 80865: 11903, 53558: 11904, 53559: 11905, 53560: 11906, 58074: 11907, 80799: 11908, 80800: 11909, 80801: 11910, 80675: 11911, 80676: 11912, 80677: 11913, 84777: 11914, 84778: 11915, 54521: 11916, 54522: 11917, 54464: 11918, 54465: 11919, 54470: 11920, 54471: 11921, 57696: 11922, 57697: 11923, 46879: 11924, 46880: 11925}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_task.to_csv('qm_index.csv')\n",
        "print(len(train_task['new_prob_id']))\n",
        "print(train_task[train_task.duplicated([\"problem_id\"], keep=False)])\n",
        "#train_task = pd.read_csv('/content/qm_index.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SweiqJhu_EQO",
        "outputId": "dc893474-1ad5-466a-d8ba-056885426063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13768\n",
            "       Unnamed: 0  user_id  problem_id  correct  school_id  new_prob_id\n",
            "0            1361    79411       51449        1       5049            1\n",
            "1            1362    79411       51406        1       5049            2\n",
            "2            1363    79414       51412        0       5049            3\n",
            "3            1364    79414       51428        1       5049            4\n",
            "4            1365    79414       51476        1       5049            5\n",
            "...           ...      ...         ...      ...        ...          ...\n",
            "13761      323993    85656       80672        1       1998         6313\n",
            "13762      323994    85656       80673        1       1998         6314\n",
            "13765      327720    86229       54032        0       1998         5884\n",
            "13766      327721    86229       54033        1       1998         5885\n",
            "13767      327722    86229       54034        0       1998         5886\n",
            "\n",
            "[3531 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLhLEVVW8-5t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "4b0ace4c-8e90-4312-adb4-27bb76dc4a3a"
      },
      "source": [
        "'''questions = list(train_df[\"problem_id\"].unique())\n",
        "schools_tot = train_df[\"school_id\"].unique()\n",
        "#schools = comb_df[\"school_id\"].unique()\n",
        "#print(\"Unique Questions:\", questions)\n",
        "n_questions = len(questions)\n",
        "#n_schools = len(schools)\n",
        "#print(\"number questions:\", n_questions)\n",
        "#print(\"Tot num of schools:\", len(schools_tot))\n",
        "#print(\"#of schools = \", n_schools)\n",
        "\n",
        "#print(type(questions))#.shape())\n",
        "\n",
        "\n",
        "fzfn= train_df[train_df[\"school_id\"] == 5049]\n",
        "foos= train_df[train_df[\"school_id\"] == 5117]\n",
        "onne= train_df[train_df[\"school_id\"] == 1998]\n",
        "comb_2 = pd.concat([foos, onne])\n",
        "comb = pd.concat([fzfn, foos, onne])\n",
        "n_questions_5049 = len(fzfn.problem_id.unique())\n",
        "n_questions_5117 = len(foos.problem_id.unique())\n",
        "n_questions_1998 = len(onne.problem_id.unique())\n",
        "n_questions_comb_2 = len(comb_2.problem_id.unique())\n",
        "n_questions_comb = len(comb.problem_id.unique())\n",
        "\n",
        "print(n_questions_5049,n_questions_5117,n_questions_1998,n_questions_comb_2, n_questions_comb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'questions = list(train_df[\"problem_id\"].unique())\\nschools_tot = train_df[\"school_id\"].unique()\\n#schools = comb_df[\"school_id\"].unique()\\n#print(\"Unique Questions:\", questions)\\nn_questions = len(questions)\\n#n_schools = len(schools)\\n#print(\"number questions:\", n_questions)\\n#print(\"Tot num of schools:\", len(schools_tot))\\n#print(\"#of schools = \", n_schools)\\n\\n#print(type(questions))#.shape())\\n\\n\\nfzfn= train_df[train_df[\"school_id\"] == 5049]\\nfoos= train_df[train_df[\"school_id\"] == 5117]\\nonne= train_df[train_df[\"school_id\"] == 1998]\\ncomb_2 = pd.concat([foos, onne])\\ncomb = pd.concat([fzfn, foos, onne])\\nn_questions_5049 = len(fzfn.problem_id.unique())\\nn_questions_5117 = len(foos.problem_id.unique())\\nn_questions_1998 = len(onne.problem_id.unique())\\nn_questions_comb_2 = len(comb_2.problem_id.unique())\\nn_questions_comb = len(comb.problem_id.unique())\\n\\nprint(n_questions_5049,n_questions_5117,n_questions_1998,n_questions_comb_2, n_questions_comb)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "EeTWi1FE85iH",
        "outputId": "0100d7fe-0488-4ba4-d0e9-2387398adb88"
      },
      "source": [
        "'''count = {}\n",
        "#print(questions)\n",
        "for i in range(1,len(questions)+1):\n",
        "    count[questions[i-1]]=i\n",
        "#print(count)\n",
        "train_df['new_prob_id']=0\n",
        "for i in range(len(train_df['problem_id'])):\n",
        "    train_df['new_prob_id'][i]=count[train_df['problem_id'][i]]'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"count = {}\\n#print(questions)\\nfor i in range(1,len(questions)+1):\\n    count[questions[i-1]]=i\\n#print(count)\\ntrain_df['new_prob_id']=0\\nfor i in range(len(train_df['problem_id'])):\\n    train_df['new_prob_id'][i]=count[train_df['problem_id'][i]]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YntVhSkZokYe",
        "outputId": "dc8ad5eb-2385-4892-f5db-f632a1d64a95"
      },
      "source": [
        "group = train_task[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "\n",
        "#pd.set_option('display.max_rows', None)\n",
        "print(\"Group:\",len(group))\n",
        "\n",
        "\n",
        "#Task 1 : students with school id = 5049\n",
        "var= train_task[train_task[\"school_id\"] == 5049]\n",
        "print(\"No of schools with 5049:\",len(var))\n",
        "group1 = var[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group1:\",len(group1))\n",
        "\n",
        "#Task 2 : students with school id = 5117\n",
        "var2= train_task[train_task[\"school_id\"] == 5117]\n",
        "print(\"No of schools with 5117:\",len(var2))\n",
        "group3 = var2[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group1:\",len(group3))\n",
        "\n",
        "#Task 3 : students with school id = 1998\n",
        "var1= train_task[train_task[\"school_id\"] == 1998]\n",
        "print(\"No of schools with 1998:\",len(var1))\n",
        "group2 = var1[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group2:\",len(group2))\n",
        "\n",
        "#Task 4 : students with school id = 5049 & 5117\n",
        "comb_df = pd.concat([var, var2])\n",
        "print(\"No of schools with 5049 & 5117: \",len(comb_df))\n",
        "group_comb = comb_df[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group combined of 5049 and 5117 :\",group_comb)\n",
        "\n",
        "#Task 5 : students with school id = 5117 & 1998\n",
        "comb_df_2 = pd.concat([var2, var1])\n",
        "print(\"No of schools with 5117 & 1998: \",len(comb_df_2))\n",
        "group_comb_2 = comb_df_2[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group combined of 5117 and 1998 tasks :\",group_comb_2)\n",
        "\n",
        "#Task 6 : students with school id = 5049 & 1998\n",
        "comb_df_13 = pd.concat([var, var1])\n",
        "print(\"No of schools with 5117 & 1998: \",len(comb_df_13))\n",
        "group_comb_13 = comb_df_13[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group combined of 5049 & 1998 :\",group_comb_13)\n",
        "\n",
        "#Task 7 : students with school id = 5049 & 1998 $ 5117\n",
        "comb_df3 = pd.concat([var, var1, var2])\n",
        "print(\"No of schools with 5049 & 1998 & 5117: \",len(comb_df3))\n",
        "group_12 = comb_df3[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group combined of 3:\",len(group_12))\n",
        "\n",
        "comb_dffff = pd.concat([comb_df, var1])\n",
        "print(\"No of schools with 5049 & 1998 & 5117: \",len(comb_dffff))\n",
        "group_123 = comb_dffff[['user_id', 'new_prob_id', 'correct']].groupby('user_id').apply(lambda r: (\n",
        "            r['new_prob_id'].values,\n",
        "            r['correct'].values))\n",
        "print(\"Length of group combined of 3:\",len(group_123))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group: 259\n",
            "No of schools with 5049: 7975\n",
            "Length of group1: 93\n",
            "No of schools with 5117: 2728\n",
            "Length of group1: 81\n",
            "No of schools with 1998: 3065\n",
            "Length of group2: 85\n",
            "No of schools with 5049 & 5117:  10703\n",
            "Length of group combined of 5049 and 5117 : user_id\n",
            "74864                                        ([3228], [1])\n",
            "79409    ([586, 714, 715, 1097, 1236, 1237, 1238, 1397,...\n",
            "79410    ([541, 542, 543, 544, 587, 588, 589, 716, 717,...\n",
            "79411    ([1, 2, 238, 333, 334, 335, 336, 337, 468, 469...\n",
            "79412    ([471, 472, 473, 474, 590, 724, 725, 726, 1109...\n",
            "                               ...                        \n",
            "92126                               ([8109, 8110], [1, 1])\n",
            "92127                               ([1232, 8111], [1, 1])\n",
            "92128                                        ([8112], [1])\n",
            "92129                                        ([1221], [1])\n",
            "92225              ([17, 18, 68, 28, 10], [1, 0, 1, 0, 1])\n",
            "Length: 174, dtype: object\n",
            "No of schools with 5117 & 1998:  5793\n",
            "Length of group combined of 5117 and 1998 tasks : user_id\n",
            "76975    ([10229, 10230, 10231, 10232, 10233, 900, 1035...\n",
            "76982                   ([10234, 10358, 10999], [0, 1, 0])\n",
            "76986                                       ([11000], [0])\n",
            "76992    ([10235, 10236, 10237, 10238, 10239, 10335, 10...\n",
            "76998    ([10240, 10337, 906, 923, 10449, 10450, 10451,...\n",
            "                               ...                        \n",
            "92126                               ([8109, 8110], [1, 1])\n",
            "92127                               ([1232, 8111], [1, 1])\n",
            "92128                                        ([8112], [1])\n",
            "92129                                        ([1221], [1])\n",
            "92225              ([17, 18, 68, 28, 10], [1, 0, 1, 0, 1])\n",
            "Length: 166, dtype: object\n",
            "No of schools with 5117 & 1998:  11040\n",
            "Length of group combined of 5049 & 1998 : user_id\n",
            "74864                                        ([3228], [1])\n",
            "76975    ([10229, 10230, 10231, 10232, 10233, 900, 1035...\n",
            "76982                   ([10234, 10358, 10999], [0, 1, 0])\n",
            "76986                                       ([11000], [0])\n",
            "76992    ([10235, 10236, 10237, 10238, 10239, 10335, 10...\n",
            "                               ...                        \n",
            "86557    ([1052, 1078, 1232, 1384, 1385, 1386, 1387, 16...\n",
            "86558    ([205, 206, 207, 208, 209, 210, 1053, 1054, 10...\n",
            "86559    ([211, 212, 213, 214, 215, 216, 217, 218, 219,...\n",
            "87430    ([224, 225, 226, 227, 228, 229, 230, 231, 232,...\n",
            "87599    ([236, 237, 1396, 2194, 2986, 3226, 3227, 3426...\n",
            "Length: 178, dtype: object\n",
            "No of schools with 5049 & 1998 & 5117:  13768\n",
            "Length of group combined of 3: 259\n",
            "No of schools with 5049 & 1998 & 5117:  13768\n",
            "Length of group combined of 3: 259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ij3h97d9T1l",
        "outputId": "e8c2633a-d55c-4429-d2c8-41659cfad459"
      },
      "source": [
        "import random\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8fa6518370>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG-86t7kkLdD",
        "outputId": "bc567009-e54a-46ad-f562-807b72d2e69c"
      },
      "source": [
        "\n",
        "x=0\n",
        "lis=[]\n",
        "for i in range(x,len(group1)):\n",
        "  if(x>len(group1)):\n",
        "    break\n",
        "  lis.append(group1[x:x+int(len(group1)/5)])\n",
        "  x=x+int(len(group1)/5)\n",
        "#train1 = lis[0].append(lis[5][0:1])t#rain1_lis = \n",
        "a = lis[0].append(lis[5][0:1])\n",
        "b = lis[1].append(lis[5][1:2])\n",
        "c = lis[2].append(lis[5][2:3])\n",
        "d = lis[3].append(lis[5][3:4])\n",
        "e = lis[4]\n",
        "train1 = pd.concat([b,c,d,e])\n",
        "#print(len(a),len(b),len(c),len(d),len(e))\n",
        "print(len(train1))\n",
        "test1 = a\n",
        "print(len(test1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeJl56Ws0aOn",
        "outputId": "d69c4815-4708-405b-9c4d-97f7a2d738dd"
      },
      "source": [
        "''' Run this for normal CL\n",
        "x=0\n",
        "lis=[]\n",
        "for i in range(x,len(group2)):\n",
        "  if(x>len(group2)):\n",
        "    break\n",
        "  lis.append(group2[x:x+int(len(group2)/5)])\n",
        "  x=x+int(len(group2)/5)\n",
        "#train1 = lis[0].append(lis[5][0:1])t#rain1_lis = \n",
        "a = lis[0].append(lis[5][0:1])\n",
        "b = lis[1].append(lis[5][1:2])\n",
        "c = lis[2].append(lis[5][2:3])\n",
        "d = lis[3].append(lis[5][3:4])\n",
        "e = lis[4]\n",
        "train2 = pd.concat([b,c,d,e])\n",
        "#print(len(a),len(b),len(c),len(d),len(e))\n",
        "print(len(train2))\n",
        "test2 = a\n",
        "print(len(test2))'''\n",
        "\n",
        "##### Run this for feature incremental learning #####\n",
        "x=0\n",
        "lis=[]\n",
        "for i in range(x,len(group_comb)):\n",
        "  if(x>len(group_comb)):\n",
        "    break\n",
        "  lis.append(group_comb[x:x+int(len(group_comb)/5)])\n",
        "  x=x+int(len(group_comb)/5)\n",
        "#train1 = lis[0].append(lis[5][0:1])t#rain1_lis = \n",
        "a = lis[0].append(lis[5][0:1])\n",
        "b = lis[1].append(lis[5][1:2])\n",
        "c = lis[2].append(lis[5][2:3])\n",
        "d = lis[3].append(lis[5][3:4])\n",
        "e = lis[4]\n",
        "train2 = pd.concat([b,c,d,e])\n",
        "#print(len(a),len(b),len(c),len(d),len(e))\n",
        "print(len(train2))\n",
        "test2 = a\n",
        "print(len(test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136\n",
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9UZ5q13h4Bw",
        "outputId": "03b83af5-80e2-4ec2-d8ec-67c278901fe2"
      },
      "source": [
        "'''x=0\n",
        "lis=[]\n",
        "for i in range(x,len(group3)):\n",
        "  if(x>len(group3)):\n",
        "    break\n",
        "  lis.append(group3[x:x+int(len(group3)/5)])\n",
        "  x=x+int(len(group3)/5)\n",
        "#train1 = lis[0].append(lis[5][0:1])t#rain1_lis = \n",
        "a = lis[0].append(lis[5][0:1])\n",
        "b = lis[1].append(lis[5][1:2])\n",
        "c = lis[2].append(lis[5][2:3])\n",
        "d = lis[3].append(lis[5][3:4])\n",
        "e = lis[4]\n",
        "train3 = pd.concat([b,c,d,e])\n",
        "#print(len(a),len(b),len(c),len(d),len(e))\n",
        "print(len(train3))\n",
        "test3 = a\n",
        "print(len(test3))'''\n",
        "##### Run this for feature incremental learning #####\n",
        "\n",
        "x=0\n",
        "lis=[]\n",
        "for i in range(x,len(group_123)):\n",
        "  if(x>len(group_123)):\n",
        "    break\n",
        "  lis.append(group_123[x:x+int(len(group_123)/5)])\n",
        "  x=x+int(len(group_123)/5)\n",
        "#train1 = lis[0].append(lis[5][0:1])t#rain1_lis = \n",
        "a = lis[0].append(lis[5][0:1])\n",
        "b = lis[1].append(lis[5][1:2])\n",
        "c = lis[2].append(lis[5][2:3])\n",
        "d = lis[3].append(lis[5][3:4])\n",
        "e = lis[4]\n",
        "train3 = pd.concat([b,c,d,e])\n",
        "#print(len(a),len(b),len(c),len(d),len(e))\n",
        "print(len(train3))\n",
        "test3 = a\n",
        "print(len(test3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFnAK_QJokYh"
      },
      "source": [
        "class SAKTDataset(Dataset):\n",
        "    def __init__(self, group, n_questions, max_seq=MAX_SEQ):\n",
        "        super(SAKTDataset, self).__init__()\n",
        "        self.max_seq = max_seq\n",
        "        self.n_questions = n_questions\n",
        "        self.samples = group\n",
        "        \n",
        "        self.user_ids = [] \n",
        "        for schools in group.index:\n",
        "            q, qa = group[schools]\n",
        "            #print(\"Q:\", q)\n",
        "            #print(\"QA:\", qa)\n",
        "            if len(q) < 2:\n",
        "                continue\n",
        "            self.user_ids.append(schools)\n",
        "            \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_ids)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        users= train_task['user_id'].unique()\n",
        "        user_id = self.user_ids[index]\n",
        "\n",
        "        #print(\"Index:\", index)\n",
        "        #print(\"User ID:\", user_id)\n",
        "\n",
        "        q_, qa_ = self.samples[user_id]\n",
        "\n",
        "        #q_, qa_ = self.samples[users]\n",
        "        #print(\"q_, qa_\", q_ , qa_)\n",
        "        \n",
        "        seq_len = len(q_)\n",
        "        #print(\"seq_len\", seq_len)\n",
        "\n",
        "        q = np.zeros(self.max_seq, dtype=int)\n",
        "        qa = np.zeros(self.max_seq, dtype=int)\n",
        "\n",
        "        if seq_len >= self.max_seq:\n",
        "            #if random.random()>0.1:\n",
        "                #start = random.randint(0,(seq_len-self.max_seq))\n",
        "                start = seq_len - self.max_seq\n",
        "                end = start + self.max_seq\n",
        "                q[:] = q_[start:end]\n",
        "                qa[:] = qa_[start:end]\n",
        "            #else:\n",
        "            #   q[:] = q_[-self.max_seq:]\n",
        "            #   qa[:] = qa_[-self.max_seq:]\n",
        "            \n",
        "        else:\n",
        "            '''if random.random()>0.1:\n",
        "                start = 0\n",
        "                end = random.randint(2,seq_len)\n",
        "                seq_len = end - start\n",
        "                q[-seq_len:] = q_[0:seq_len]\n",
        "                qa[-seq_len:] = qa_[0:seq_len]\n",
        "            '''  \n",
        "            #else:\n",
        "                # The previous case: we store all the elements of q\n",
        "            q[-seq_len:] = q_\n",
        "            qa[-seq_len:] = qa_\n",
        "                   \n",
        "        target_id = q[1:]\n",
        "        label = qa[1:]\n",
        "        #print(\"Target:\", target_id)\n",
        "        #print(\"Label:\", label)        \n",
        "        \n",
        "        x = np.zeros(self.max_seq-1, dtype=int)\n",
        "        x = q[:-1].copy()  \n",
        "        x += (qa[:-1] == 1) * self.n_questions\n",
        "\n",
        "        #print(\"X:\",x)\n",
        "        return x, target_id, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym5GrHBu0Eby",
        "outputId": "128e0fe4-11d3-49f6-f53a-7caadf45be8e"
      },
      "source": [
        "#Train dataset and dataloader for 5049\n",
        "train_dataset_1 = SAKTDataset(train1, n_questions)\n",
        "train_dataloader_1 = DataLoader(train_dataset_1, batch_size=10, shuffle=True, num_workers=8)\n",
        "\n",
        "#Train dataset and dataloader for 5049 & 5117\n",
        "train_dataset_2 = SAKTDataset(train2, n_questions)\n",
        "train_dataloader_2 = DataLoader(train_dataset_2, batch_size=10, shuffle=True, num_workers=8)\n",
        "\n",
        "#Train dataset and dataloader for 5049&5117&1998\n",
        "train_dataset_3 = SAKTDataset(train3, n_questions)\n",
        "train_dataloader_3 = DataLoader(train_dataset_3, batch_size=10, shuffle=True, num_workers=8)\n",
        "\n",
        "#Train dataset and dataloader for 5049 & 1998 & 5117\n",
        "#train_dataset_12 = SAKTDataset(train_12, n_questions)\n",
        "#train_dataloader_12 = DataLoader(train_dataset_12, batch_size=10, shuffle=True, num_workers=8)\n",
        "\n",
        "'''\n",
        "#Validation dataset and dataloader for 5049:\n",
        "val_dataset_1 = SAKTDataset(val1, n_questions)\n",
        "val_dataloader_1 = DataLoader(val_dataset_1, batch_size=10, shuffle=True, num_workers=8)\n",
        "\n",
        "#Validation dataset and dataloader for 1998:\n",
        "val_dataset_2 = SAKTDataset(val2, n_questions)\n",
        "val_dataloader_2 = DataLoader(val_dataset_2, batch_size=10, shuffle=True, num_workers=8)\n",
        "\n",
        "#Validation dataset and dataloader for 5049 & 1998:\n",
        "val_dataset_12 = SAKTDataset(val12, n_questions)\n",
        "val_dataloader_12 = DataLoader(val_dataset_12, batch_size=10, shuffle=True, num_workers=8)'''\n",
        "\n",
        "#Test dataset and dataloader for 5049:\n",
        "test_dataset_1 = SAKTDataset(test1, n_questions )\n",
        "test_dataloader_1 = DataLoader(test_dataset_1, batch_size=20, shuffle=False, num_workers=8)\n",
        "\n",
        "#Test dataset and dataloader for 1998:\n",
        "test_dataset_2 = SAKTDataset(test2, n_questions )\n",
        "test_dataloader_2 = DataLoader(test_dataset_2, batch_size=20, shuffle=False, num_workers=8)\n",
        "\n",
        "#Test dataset and dataloader for 5117:\n",
        "test_dataset_3 = SAKTDataset(test3, n_questions )\n",
        "test_dataloader_3 = DataLoader(test_dataset_3, batch_size=20, shuffle=False, num_workers=8)\n",
        "'''\n",
        "print(f'Train dataset for 5049: {next(iter(train_dataset_1))}')\n",
        "print(f'Train dataloader for 5049: {next(iter(train_dataloader_1))}')\n",
        "print(f'Train dataset for 1998: {next(iter(train_dataset_2))}')\n",
        "print(f'Train dataloader for 1998: {next(iter(train_dataloader_2))}')\n",
        "print(f'Test dataset for 5049: {next(iter(test_dataset_1))}')\n",
        "print(f'Test dataloader for 5049: {next(iter(test_dataloader_1))}')\n",
        "print(f'Test dataset for 1998: {next(iter(test_dataset_2))}')\n",
        "print(f'Test dataloader for 1998: {next(iter(test_dataloader_2))}')\n",
        "print(f'Test dataloader for 5117: {len(test_dataloader_2)}')\n",
        "print(\"val:\",len(val_dataset_1))\n",
        "print(\"va2:\",len(val_dataset_2))\n",
        "print(f'Train dataloader for 5049 & 1998: {next(iter(train_dataloader_12))}')'''\n",
        "print(len(train_dataset_1),len(train_dataset_2),len(train_dataset_3),len(train_dataloader_2),len(train_dataloader_1),len(test_dataloader_1),len(test_dataloader_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72 126 185 13 8 1 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A5-upzNokYh"
      },
      "source": [
        "# The first class, FFN, defines a feed-forward network (hence, a MLP with dropout).\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, state_size=200):\n",
        "        # This NN has only 2 layers. They are densely connected.\n",
        "        # The first layer has ReLU as activation function.\n",
        "        # The second layer has Dropout.\n",
        "        \n",
        "        super(FFN, self).__init__()\n",
        "        self.state_size = state_size\n",
        "            # state_size only refers to the number of inputs. Hence we have the same number of inputs as of hidden neurons and output neurons.\n",
        "        \n",
        "        self.lr1 = nn.Linear(state_size, state_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lr2 = nn.Linear(state_size, state_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lr1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lr2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "def future_mask(seq_length):\n",
        "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
        "    return torch.from_numpy(future_mask)      # The we convert the matrix into a tensor (so that PyTorch can process it)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wziivGyokYh"
      },
      "source": [
        "# This defines the whole SAKT model. Last layer is a FFN network.\n",
        "class SAKTModel(nn.Module):\n",
        "    def __init__(self, n_questions, max_seq=120, embed_dim=128):\n",
        "        super(SAKTModel, self).__init__()\n",
        "        self.n_questions = n_questions\n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        # First argument `num_embeddings` is the size of the dictionary of embeddings.\n",
        "        # The second argument `embedding_dim` is the size of each embedding vector.\n",
        "        # This creates the embeddings: observe that all the embedding layers are created with the torch layer nn.Embedding.\n",
        "        # from dictionary of questions to dimension d.\n",
        "\n",
        "        #max_value = comb_df[\"problem_id\"].max()\n",
        "        #max_value = max(ques)\n",
        "        #print(\"MAx:\", max_value)\n",
        "        self.embedding = nn.Embedding(2*n_questions+1, embed_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_seq-1, embed_dim)\n",
        "        self.e_embedding = nn.Embedding(n_questions+1, embed_dim)\n",
        "\n",
        "        # This defines the Multihead Attention as in the paper\n",
        "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
        "        self.ffn = FFN(embed_dim)\n",
        "        \n",
        "        # The output is the linear of the outputs of FFN\n",
        "        self.pred = nn.Linear(embed_dim, 1)\n",
        "    \n",
        "    def forward(self, x, question_ids):\n",
        "        # x is a tensor\n",
        "        # Calling x.device returns device(type='cuda', index=0)\n",
        "        device = x.device\n",
        "        # Transform the tensor using the embedding.\n",
        "\n",
        "        #import pdb; pdb.set_trace()\n",
        "        x = self.embedding(x)\n",
        "       \n",
        "        # This does several things:\n",
        "        # Creates a 1D tensor that goes from 0 to k, where k is the second dimension of x\n",
        "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
        "        \n",
        "        # This creates the embedding of the position\n",
        "        pos_x = self.pos_embedding(pos_id)\n",
        "        # We add the position and the input tensor x \n",
        "        x = x + pos_x\n",
        "        \n",
        "        # Finally, we make an embedding of the question_ids.\n",
        "        e = self.e_embedding(question_ids)\n",
        "        \n",
        "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
        "        e = e.permute(1, 0, 2)\n",
        "        \n",
        "        # Creates the mask in order to avoid using the future to predict the past\n",
        "        att_mask = future_mask(x.size(0)).to(device)\n",
        "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
        "\n",
        "        att_output = self.layer_normal(att_output + e)\n",
        "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
        "\n",
        "        x = self.ffn(att_output)\n",
        "        x = self.layer_normal(x + att_output)\n",
        "        x = self.pred(x)\n",
        "\n",
        "        return x.squeeze(-1), att_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FDWQ5YQwyFIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_QXxBXYokYi"
      },
      "source": [
        "# We define a function that defines each train epoch.\n",
        "def train_epoch(model, dataloader, optim, scheduler, criterion, device=\"cpu\"):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = []\n",
        "    num_corrects = 0\n",
        "    num_total = 0\n",
        "    labels = []\n",
        "    outs = []\n",
        "    \n",
        "    tbar = tqdm(dataloader)\n",
        "\n",
        "    for item in tbar:\n",
        "    #for item, (input, target) in enumerate(train_iterator):\n",
        "        # Gets the first item of train_iterator and sends it to the device and converts it to long type.\n",
        "\n",
        "        x = item[0].to(device).long()\n",
        "        target_id = item[1].to(device).long()\n",
        "        label = item[2].to(device).float()\n",
        "        target_mask = (target_id != 0)\n",
        "\n",
        "        # set the gradients to 0.\n",
        "        optim.zero_grad()\n",
        "        # Get the output and weights of the model.\n",
        "        #output, atten_weight = model(x, target_id)\n",
        "        output, atten_weight = model(x, target_id)\n",
        "        \n",
        "        #print(\"output:\", output)\n",
        "        #print(\"attention_weight:\", atten_weight)      \n",
        "        \n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        scheduler.step()\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "\n",
        "        \n",
        "        output = torch.masked_select(output, target_mask)\n",
        "        label = torch.masked_select(label, target_mask)\n",
        "        \n",
        "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
        "        #print(f'Pred {pred}')\n",
        "\n",
        "        \n",
        "        num_corrects += (pred == label).sum().item()\n",
        "        #num_corrects += (output == label).float().sum()\n",
        "        num_total += len(label)\n",
        "\n",
        "        labels.extend(label.view(-1).data.cpu().numpy())\n",
        "        outs.extend(output.view(-1).data.cpu().numpy())\n",
        "\n",
        "        #tbar.set_description('loss - {:.4f}'.format(loss))\n",
        "    \n",
        "    #print(f'Pred: {pred} LAbel: {label}')\n",
        "    \n",
        "    \n",
        "    # Compute Accuracy\n",
        "    acc = num_corrects / num_total\n",
        "    roc = roc_auc_score(labels, outs)\n",
        "    precision, recall, _ = precision_recall_curve(labels,outs)\n",
        "    auc_score = auc(recall, precision)\n",
        "    loss = np.average(train_loss)\n",
        "\n",
        "    #Printing the confusion matrix \n",
        "    print(metrics.confusion_matrix(label,pred))\n",
        "    #Printing the precision and recall, among other metrics\n",
        "    print(metrics.classification_report(label,pred))\n",
        "\n",
        "    return loss, acc, roc, auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bivsB9HXokYi",
        "outputId": "9ed4a992-5309-4856-bb42-b386c3f3e05b"
      },
      "source": [
        "#Call the SAKT model\n",
        "\n",
        "#### For 5049 task ####\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SAKTModel(n_questions, embed_dim = 128)  #The dimension of embeddings d is 128.\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.99, weight_decay=0.01)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "scheduler_1 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_1), epochs=epochs\n",
        ")\n",
        "\n",
        "scheduler_2 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_2), epochs=epochs\n",
        ")\n",
        "\n",
        "scheduler_3 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_3), epochs=epochs\n",
        ")\n",
        "\n",
        "#scheduler_12 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "#    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_12), epochs=epochs\n",
        "#)\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "print(model)\n",
        "#print(model_5117)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAKTModel(\n",
            "  (embedding): Embedding(23851, 128)\n",
            "  (pos_embedding): Embedding(119, 128)\n",
            "  (e_embedding): Embedding(11926, 128)\n",
            "  (multi_att): MultiheadAttention(\n",
            "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (layer_normal): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (ffn): FFN(\n",
            "    (lr1): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (lr2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (pred): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eYnhMHJokYi",
        "outputId": "247bc4cb-ad59-45d2-b46d-07d275311401"
      },
      "source": [
        "#Function call for Train on 5049\n",
        "best_auc = 0\n",
        "max_steps = 50\n",
        "step = 0\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc, roc, prc_auc = train_epoch(model, train_dataloader_1, optimizer, scheduler_1, criterion, device)\n",
        "  print(\"epoch - {}/{} train_loss - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f} \".format(epoch+1, epochs, train_loss, train_acc, roc, prc_auc))\n",
        "  \n",
        "  if roc > best_auc:\n",
        "    best_auc = roc\n",
        "    step = 0\n",
        "    torch.save(model.state_dict(), \"sakt_model.pt\")\n",
        "  else:\n",
        "    step += 1\n",
        "    if step >= max_steps:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 14]\n",
            " [12 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.42      0.43        24\n",
            "         1.0       0.61      0.65      0.63        34\n",
            "\n",
            "    accuracy                           0.55        58\n",
            "   macro avg       0.53      0.53      0.53        58\n",
            "weighted avg       0.55      0.55      0.55        58\n",
            "\n",
            "epoch - 1/150 train_loss - 0.701 acc - 0.507 roc - 0.492 prc_auc - 0.653 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5  6]\n",
            " [ 8 12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.45      0.42        11\n",
            "         1.0       0.67      0.60      0.63        20\n",
            "\n",
            "    accuracy                           0.55        31\n",
            "   macro avg       0.53      0.53      0.52        31\n",
            "weighted avg       0.57      0.55      0.56        31\n",
            "\n",
            "epoch - 2/150 train_loss - 0.690 acc - 0.515 roc - 0.494 prc_auc - 0.653 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  7]\n",
            " [16 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.53      0.41        15\n",
            "         1.0       0.79      0.63      0.70        43\n",
            "\n",
            "    accuracy                           0.60        58\n",
            "   macro avg       0.56      0.58      0.56        58\n",
            "weighted avg       0.67      0.60      0.63        58\n",
            "\n",
            "epoch - 3/150 train_loss - 0.695 acc - 0.507 roc - 0.491 prc_auc - 0.652 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7  8]\n",
            " [17 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.47      0.36        15\n",
            "         1.0       0.76      0.60      0.68        43\n",
            "\n",
            "    accuracy                           0.57        58\n",
            "   macro avg       0.53      0.54      0.52        58\n",
            "weighted avg       0.64      0.57      0.59        58\n",
            "\n",
            "epoch - 4/150 train_loss - 0.692 acc - 0.507 roc - 0.490 prc_auc - 0.652 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  9]\n",
            " [18 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.05      0.10      0.07        10\n",
            "         1.0       0.77      0.62      0.69        48\n",
            "\n",
            "    accuracy                           0.53        58\n",
            "   macro avg       0.41      0.36      0.38        58\n",
            "weighted avg       0.65      0.53      0.58        58\n",
            "\n",
            "epoch - 5/150 train_loss - 0.691 acc - 0.507 roc - 0.492 prc_auc - 0.655 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  7]\n",
            " [17 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.32      0.53      0.40        15\n",
            "         1.0       0.79      0.60      0.68        43\n",
            "\n",
            "    accuracy                           0.59        58\n",
            "   macro avg       0.55      0.57      0.54        58\n",
            "weighted avg       0.67      0.59      0.61        58\n",
            "\n",
            "epoch - 6/150 train_loss - 0.681 acc - 0.514 roc - 0.498 prc_auc - 0.658 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  0]\n",
            " [18 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      1.00      0.18         2\n",
            "         1.0       1.00      0.45      0.62        33\n",
            "\n",
            "    accuracy                           0.49        35\n",
            "   macro avg       0.55      0.73      0.40        35\n",
            "weighted avg       0.95      0.49      0.60        35\n",
            "\n",
            "epoch - 7/150 train_loss - 0.668 acc - 0.515 roc - 0.496 prc_auc - 0.657 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  6]\n",
            " [18 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.40      0.25        10\n",
            "         1.0       0.83      0.62      0.71        48\n",
            "\n",
            "    accuracy                           0.59        58\n",
            "   macro avg       0.51      0.51      0.48        58\n",
            "weighted avg       0.72      0.59      0.63        58\n",
            "\n",
            "epoch - 8/150 train_loss - 0.676 acc - 0.517 roc - 0.496 prc_auc - 0.657 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 15]\n",
            " [16 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.24      0.25      0.24        20\n",
            "         1.0       0.59      0.58      0.59        38\n",
            "\n",
            "    accuracy                           0.47        58\n",
            "   macro avg       0.42      0.41      0.42        58\n",
            "weighted avg       0.47      0.47      0.47        58\n",
            "\n",
            "epoch - 9/150 train_loss - 0.672 acc - 0.526 roc - 0.500 prc_auc - 0.659 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 14]\n",
            " [15 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.42      0.41        24\n",
            "         1.0       0.58      0.56      0.57        34\n",
            "\n",
            "    accuracy                           0.50        58\n",
            "   macro avg       0.49      0.49      0.49        58\n",
            "weighted avg       0.50      0.50      0.50        58\n",
            "\n",
            "epoch - 10/150 train_loss - 0.662 acc - 0.530 roc - 0.502 prc_auc - 0.661 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  9]\n",
            " [13 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.32      0.40      0.35        15\n",
            "         1.0       0.74      0.67      0.70        39\n",
            "\n",
            "    accuracy                           0.59        54\n",
            "   macro avg       0.53      0.53      0.53        54\n",
            "weighted avg       0.62      0.59      0.61        54\n",
            "\n",
            "epoch - 11/150 train_loss - 0.649 acc - 0.532 roc - 0.508 prc_auc - 0.668 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  9]\n",
            " [10 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.40      0.39        15\n",
            "         1.0       0.55      0.52      0.54        21\n",
            "\n",
            "    accuracy                           0.47        36\n",
            "   macro avg       0.46      0.46      0.46        36\n",
            "weighted avg       0.48      0.47      0.47        36\n",
            "\n",
            "epoch - 12/150 train_loss - 0.634 acc - 0.535 roc - 0.506 prc_auc - 0.664 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 15]\n",
            " [12 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.25      0.27        20\n",
            "         1.0       0.63      0.68      0.66        38\n",
            "\n",
            "    accuracy                           0.53        58\n",
            "   macro avg       0.46      0.47      0.46        58\n",
            "weighted avg       0.52      0.53      0.52        58\n",
            "\n",
            "epoch - 13/150 train_loss - 0.643 acc - 0.549 roc - 0.506 prc_auc - 0.667 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 11]\n",
            " [17 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.39      0.33        18\n",
            "         1.0       0.67      0.56      0.61        39\n",
            "\n",
            "    accuracy                           0.51        57\n",
            "   macro avg       0.48      0.48      0.47        57\n",
            "weighted avg       0.55      0.51      0.52        57\n",
            "\n",
            "epoch - 14/150 train_loss - 0.637 acc - 0.551 roc - 0.512 prc_auc - 0.673 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  3]\n",
            " [20 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.57      0.26         7\n",
            "         1.0       0.86      0.49      0.62        39\n",
            "\n",
            "    accuracy                           0.50        46\n",
            "   macro avg       0.52      0.53      0.44        46\n",
            "weighted avg       0.76      0.50      0.57        46\n",
            "\n",
            "epoch - 15/150 train_loss - 0.622 acc - 0.563 roc - 0.511 prc_auc - 0.670 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 21]\n",
            " [ 7 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.46      0.22      0.30        27\n",
            "         1.0       0.53      0.77      0.63        31\n",
            "\n",
            "    accuracy                           0.52        58\n",
            "   macro avg       0.50      0.50      0.47        58\n",
            "weighted avg       0.50      0.52      0.48        58\n",
            "\n",
            "epoch - 16/150 train_loss - 0.631 acc - 0.571 roc - 0.516 prc_auc - 0.672 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 18]\n",
            " [ 9 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.22      0.27        23\n",
            "         1.0       0.59      0.74      0.66        35\n",
            "\n",
            "    accuracy                           0.53        58\n",
            "   macro avg       0.47      0.48      0.46        58\n",
            "weighted avg       0.50      0.53      0.50        58\n",
            "\n",
            "epoch - 17/150 train_loss - 0.624 acc - 0.575 roc - 0.516 prc_auc - 0.675 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 15]\n",
            " [ 7 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.46      0.29      0.35        21\n",
            "         1.0       0.65      0.80      0.72        35\n",
            "\n",
            "    accuracy                           0.61        56\n",
            "   macro avg       0.56      0.54      0.54        56\n",
            "weighted avg       0.58      0.61      0.58        56\n",
            "\n",
            "epoch - 18/150 train_loss - 0.617 acc - 0.588 roc - 0.521 prc_auc - 0.680 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 17]\n",
            " [ 4 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.29      0.40        24\n",
            "         1.0       0.64      0.88      0.74        34\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.64      0.59      0.57        58\n",
            "weighted avg       0.64      0.64      0.60        58\n",
            "\n",
            "epoch - 19/150 train_loss - 0.617 acc - 0.585 roc - 0.520 prc_auc - 0.677 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 24]\n",
            " [ 5 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.08      0.12        26\n",
            "         1.0       0.53      0.84      0.65        32\n",
            "\n",
            "    accuracy                           0.50        58\n",
            "   macro avg       0.41      0.46      0.39        58\n",
            "weighted avg       0.42      0.50      0.41        58\n",
            "\n",
            "epoch - 20/150 train_loss - 0.617 acc - 0.596 roc - 0.526 prc_auc - 0.682 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 10]\n",
            " [ 7 21]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.29      0.32        14\n",
            "         1.0       0.68      0.75      0.71        28\n",
            "\n",
            "    accuracy                           0.60        42\n",
            "   macro avg       0.52      0.52      0.52        42\n",
            "weighted avg       0.57      0.60      0.58        42\n",
            "\n",
            "epoch - 21/150 train_loss - 0.593 acc - 0.609 roc - 0.530 prc_auc - 0.685 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6 2]\n",
            " [6 6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.75      0.60         8\n",
            "         1.0       0.75      0.50      0.60        12\n",
            "\n",
            "    accuracy                           0.60        20\n",
            "   macro avg       0.62      0.62      0.60        20\n",
            "weighted avg       0.65      0.60      0.60        20\n",
            "\n",
            "epoch - 22/150 train_loss - 0.569 acc - 0.600 roc - 0.532 prc_auc - 0.688 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 20]\n",
            " [ 5 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.20      0.29        25\n",
            "         1.0       0.58      0.85      0.69        33\n",
            "\n",
            "    accuracy                           0.57        58\n",
            "   macro avg       0.54      0.52      0.49        58\n",
            "weighted avg       0.55      0.57      0.52        58\n",
            "\n",
            "epoch - 23/150 train_loss - 0.608 acc - 0.606 roc - 0.531 prc_auc - 0.687 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  1]\n",
            " [ 9 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.75      0.38         4\n",
            "         1.0       0.96      0.74      0.83        34\n",
            "\n",
            "    accuracy                           0.74        38\n",
            "   macro avg       0.61      0.74      0.60        38\n",
            "weighted avg       0.89      0.74      0.79        38\n",
            "\n",
            "epoch - 24/150 train_loss - 0.574 acc - 0.605 roc - 0.537 prc_auc - 0.690 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5  9]\n",
            " [11 13]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.36      0.33        14\n",
            "         1.0       0.59      0.54      0.57        24\n",
            "\n",
            "    accuracy                           0.47        38\n",
            "   macro avg       0.45      0.45      0.45        38\n",
            "weighted avg       0.49      0.47      0.48        38\n",
            "\n",
            "epoch - 25/150 train_loss - 0.585 acc - 0.613 roc - 0.542 prc_auc - 0.693 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 10]\n",
            " [ 7 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.41      0.45        17\n",
            "         1.0       0.77      0.83      0.80        41\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.64      0.62      0.63        58\n",
            "weighted avg       0.69      0.71      0.70        58\n",
            "\n",
            "epoch - 26/150 train_loss - 0.590 acc - 0.620 roc - 0.544 prc_auc - 0.696 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  8]\n",
            " [ 5 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.33      0.38        12\n",
            "         1.0       0.76      0.83      0.79        30\n",
            "\n",
            "    accuracy                           0.69        42\n",
            "   macro avg       0.60      0.58      0.59        42\n",
            "weighted avg       0.67      0.69      0.68        42\n",
            "\n",
            "epoch - 27/150 train_loss - 0.572 acc - 0.629 roc - 0.546 prc_auc - 0.697 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 20]\n",
            " [ 4 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.13      0.20        23\n",
            "         1.0       0.60      0.88      0.71        34\n",
            "\n",
            "    accuracy                           0.58        57\n",
            "   macro avg       0.51      0.51      0.46        57\n",
            "weighted avg       0.53      0.58      0.51        57\n",
            "\n",
            "epoch - 28/150 train_loss - 0.593 acc - 0.621 roc - 0.548 prc_auc - 0.699 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 21]\n",
            " [ 5 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.05      0.07        22\n",
            "         1.0       0.60      0.86      0.70        36\n",
            "\n",
            "    accuracy                           0.55        58\n",
            "   macro avg       0.38      0.45      0.39        58\n",
            "weighted avg       0.43      0.55      0.46        58\n",
            "\n",
            "epoch - 29/150 train_loss - 0.594 acc - 0.623 roc - 0.553 prc_auc - 0.703 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 24]\n",
            " [ 0 33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.04      0.08        25\n",
            "         1.0       0.58      1.00      0.73        33\n",
            "\n",
            "    accuracy                           0.59        58\n",
            "   macro avg       0.79      0.52      0.41        58\n",
            "weighted avg       0.76      0.59      0.45        58\n",
            "\n",
            "epoch - 30/150 train_loss - 0.594 acc - 0.627 roc - 0.552 prc_auc - 0.702 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 23]\n",
            " [ 4 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.23      0.34        30\n",
            "         1.0       0.51      0.86      0.64        28\n",
            "\n",
            "    accuracy                           0.53        58\n",
            "   macro avg       0.57      0.55      0.49        58\n",
            "weighted avg       0.58      0.53      0.49        58\n",
            "\n",
            "epoch - 31/150 train_loss - 0.595 acc - 0.634 roc - 0.559 prc_auc - 0.705 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 18]\n",
            " [ 8 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.22      0.28        23\n",
            "         1.0       0.60      0.77      0.68        35\n",
            "\n",
            "    accuracy                           0.55        58\n",
            "   macro avg       0.49      0.49      0.48        58\n",
            "weighted avg       0.51      0.55      0.52        58\n",
            "\n",
            "epoch - 32/150 train_loss - 0.589 acc - 0.634 roc - 0.564 prc_auc - 0.710 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 10]\n",
            " [ 3 32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.23      0.32        13\n",
            "         1.0       0.76      0.91      0.83        35\n",
            "\n",
            "    accuracy                           0.73        48\n",
            "   macro avg       0.63      0.57      0.57        48\n",
            "weighted avg       0.69      0.73      0.69        48\n",
            "\n",
            "epoch - 33/150 train_loss - 0.572 acc - 0.629 roc - 0.565 prc_auc - 0.709 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 14]\n",
            " [ 6 33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.26      0.33        19\n",
            "         1.0       0.70      0.85      0.77        39\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.58      0.55      0.55        58\n",
            "weighted avg       0.62      0.66      0.63        58\n",
            "\n",
            "epoch - 34/150 train_loss - 0.585 acc - 0.639 roc - 0.569 prc_auc - 0.713 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 17]\n",
            " [ 5 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.06      0.08        18\n",
            "         1.0       0.67      0.87      0.76        39\n",
            "\n",
            "    accuracy                           0.61        57\n",
            "   macro avg       0.42      0.46      0.42        57\n",
            "weighted avg       0.51      0.61      0.54        57\n",
            "\n",
            "epoch - 35/150 train_loss - 0.577 acc - 0.636 roc - 0.569 prc_auc - 0.714 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 6]\n",
            " [4 6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.33      0.38         9\n",
            "         1.0       0.50      0.60      0.55        10\n",
            "\n",
            "    accuracy                           0.47        19\n",
            "   macro avg       0.46      0.47      0.46        19\n",
            "weighted avg       0.47      0.47      0.46        19\n",
            "\n",
            "epoch - 36/150 train_loss - 0.544 acc - 0.642 roc - 0.575 prc_auc - 0.716 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7]\n",
            " [ 4 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.12      0.15         8\n",
            "         1.0       0.87      0.92      0.89        50\n",
            "\n",
            "    accuracy                           0.81        58\n",
            "   macro avg       0.53      0.52      0.52        58\n",
            "weighted avg       0.78      0.81      0.79        58\n",
            "\n",
            "epoch - 37/150 train_loss - 0.563 acc - 0.641 roc - 0.576 prc_auc - 0.718 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 13]\n",
            " [ 6 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.28      0.34        18\n",
            "         1.0       0.72      0.85      0.78        40\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.59      0.56      0.56        58\n",
            "weighted avg       0.64      0.67      0.65        58\n",
            "\n",
            "epoch - 38/150 train_loss - 0.577 acc - 0.639 roc - 0.578 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  8]\n",
            " [ 3 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.27      0.35        11\n",
            "         1.0       0.69      0.86      0.77        21\n",
            "\n",
            "    accuracy                           0.66        32\n",
            "   macro avg       0.60      0.56      0.56        32\n",
            "weighted avg       0.63      0.66      0.62        32\n",
            "\n",
            "epoch - 39/150 train_loss - 0.552 acc - 0.651 roc - 0.581 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  7]\n",
            " [ 4 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.12      0.15         8\n",
            "         1.0       0.87      0.92      0.89        50\n",
            "\n",
            "    accuracy                           0.81        58\n",
            "   macro avg       0.53      0.52      0.52        58\n",
            "weighted avg       0.78      0.81      0.79        58\n",
            "\n",
            "epoch - 40/150 train_loss - 0.559 acc - 0.653 roc - 0.588 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 16]\n",
            " [ 2 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.06      0.10        17\n",
            "         1.0       0.71      0.95      0.81        41\n",
            "\n",
            "    accuracy                           0.69        58\n",
            "   macro avg       0.52      0.51      0.46        58\n",
            "weighted avg       0.60      0.69      0.60        58\n",
            "\n",
            "epoch - 41/150 train_loss - 0.569 acc - 0.648 roc - 0.589 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  5]\n",
            " [ 4 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.38      0.40         8\n",
            "         1.0       0.86      0.88      0.87        34\n",
            "\n",
            "    accuracy                           0.79        42\n",
            "   macro avg       0.64      0.63      0.63        42\n",
            "weighted avg       0.78      0.79      0.78        42\n",
            "\n",
            "epoch - 42/150 train_loss - 0.549 acc - 0.658 roc - 0.587 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 17]\n",
            " [ 2 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.11      0.17        19\n",
            "         1.0       0.69      0.95      0.80        39\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.59      0.53      0.48        58\n",
            "weighted avg       0.62      0.67      0.59        58\n",
            "\n",
            "epoch - 43/150 train_loss - 0.572 acc - 0.650 roc - 0.594 prc_auc - 0.730 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 19]\n",
            " [ 4 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.17      0.26        23\n",
            "         1.0       0.62      0.89      0.73        35\n",
            "\n",
            "    accuracy                           0.60        58\n",
            "   macro avg       0.56      0.53      0.49        58\n",
            "weighted avg       0.57      0.60      0.54        58\n",
            "\n",
            "epoch - 44/150 train_loss - 0.577 acc - 0.653 roc - 0.596 prc_auc - 0.732 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  7]\n",
            " [ 5 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.22      0.25         9\n",
            "         1.0       0.59      0.67      0.62        15\n",
            "\n",
            "    accuracy                           0.50        24\n",
            "   macro avg       0.44      0.44      0.44        24\n",
            "weighted avg       0.47      0.50      0.48        24\n",
            "\n",
            "epoch - 45/150 train_loss - 0.539 acc - 0.657 roc - 0.597 prc_auc - 0.732 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 14]\n",
            " [ 0 43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.07      0.12        15\n",
            "         1.0       0.75      1.00      0.86        43\n",
            "\n",
            "    accuracy                           0.76        58\n",
            "   macro avg       0.88      0.53      0.49        58\n",
            "weighted avg       0.82      0.76      0.67        58\n",
            "\n",
            "epoch - 46/150 train_loss - 0.563 acc - 0.659 roc - 0.598 prc_auc - 0.731 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 10]\n",
            " [ 2 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.17      0.25        12\n",
            "         1.0       0.80      0.95      0.87        42\n",
            "\n",
            "    accuracy                           0.78        54\n",
            "   macro avg       0.65      0.56      0.56        54\n",
            "weighted avg       0.73      0.78      0.73        54\n",
            "\n",
            "epoch - 47/150 train_loss - 0.554 acc - 0.659 roc - 0.600 prc_auc - 0.735 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 15]\n",
            " [ 1 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.17      0.27        18\n",
            "         1.0       0.66      0.97      0.78        30\n",
            "\n",
            "    accuracy                           0.67        48\n",
            "   macro avg       0.70      0.57      0.53        48\n",
            "weighted avg       0.69      0.67      0.59        48\n",
            "\n",
            "epoch - 48/150 train_loss - 0.555 acc - 0.657 roc - 0.602 prc_auc - 0.733 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  9]\n",
            " [ 3 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.31      0.40        13\n",
            "         1.0       0.71      0.88      0.79        25\n",
            "\n",
            "    accuracy                           0.68        38\n",
            "   macro avg       0.64      0.59      0.59        38\n",
            "weighted avg       0.66      0.68      0.65        38\n",
            "\n",
            "epoch - 49/150 train_loss - 0.546 acc - 0.654 roc - 0.601 prc_auc - 0.733 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 16]\n",
            " [ 4 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.20      0.29        20\n",
            "         1.0       0.68      0.89      0.77        38\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.59      0.55      0.53        58\n",
            "weighted avg       0.62      0.66      0.60        58\n",
            "\n",
            "epoch - 50/150 train_loss - 0.563 acc - 0.657 roc - 0.608 prc_auc - 0.739 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 16]\n",
            " [ 4 33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.24      0.33        21\n",
            "         1.0       0.67      0.89      0.77        37\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.61      0.56      0.55        58\n",
            "weighted avg       0.63      0.66      0.61        58\n",
            "\n",
            "epoch - 51/150 train_loss - 0.566 acc - 0.653 roc - 0.609 prc_auc - 0.739 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 24]\n",
            " [ 1 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.08      0.14        26\n",
            "         1.0       0.56      0.97      0.71        32\n",
            "\n",
            "    accuracy                           0.57        58\n",
            "   macro avg       0.62      0.52      0.43        58\n",
            "weighted avg       0.61      0.57      0.46        58\n",
            "\n",
            "epoch - 52/150 train_loss - 0.578 acc - 0.653 roc - 0.609 prc_auc - 0.739 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  6]\n",
            " [ 5 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.33      0.35         9\n",
            "         1.0       0.65      0.69      0.67        16\n",
            "\n",
            "    accuracy                           0.56        25\n",
            "   macro avg       0.51      0.51      0.51        25\n",
            "weighted avg       0.55      0.56      0.55        25\n",
            "\n",
            "epoch - 53/150 train_loss - 0.535 acc - 0.659 roc - 0.613 prc_auc - 0.740 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  6]\n",
            " [ 2 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.25      0.33         8\n",
            "         1.0       0.89      0.96      0.92        50\n",
            "\n",
            "    accuracy                           0.86        58\n",
            "   macro avg       0.69      0.60      0.63        58\n",
            "weighted avg       0.84      0.86      0.84        58\n",
            "\n",
            "epoch - 54/150 train_loss - 0.550 acc - 0.653 roc - 0.614 prc_auc - 0.739 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  7]\n",
            " [ 4 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.22      0.27         9\n",
            "         1.0       0.79      0.87      0.83        31\n",
            "\n",
            "    accuracy                           0.73        40\n",
            "   macro avg       0.56      0.55      0.55        40\n",
            "weighted avg       0.69      0.72      0.70        40\n",
            "\n",
            "epoch - 55/150 train_loss - 0.538 acc - 0.656 roc - 0.615 prc_auc - 0.741 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  9]\n",
            " [ 4 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.10      0.13        10\n",
            "         1.0       0.71      0.85      0.77        26\n",
            "\n",
            "    accuracy                           0.64        36\n",
            "   macro avg       0.45      0.47      0.45        36\n",
            "weighted avg       0.57      0.64      0.59        36\n",
            "\n",
            "epoch - 56/150 train_loss - 0.539 acc - 0.663 roc - 0.617 prc_auc - 0.743 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  9]\n",
            " [ 0 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.31      0.47        13\n",
            "         1.0       0.67      1.00      0.80        18\n",
            "\n",
            "    accuracy                           0.71        31\n",
            "   macro avg       0.83      0.65      0.64        31\n",
            "weighted avg       0.81      0.71      0.66        31\n",
            "\n",
            "epoch - 57/150 train_loss - 0.533 acc - 0.653 roc - 0.619 prc_auc - 0.741 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 26]\n",
            " [ 4 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.19      0.29        32\n",
            "         1.0       0.46      0.85      0.59        26\n",
            "\n",
            "    accuracy                           0.48        58\n",
            "   macro avg       0.53      0.52      0.44        58\n",
            "weighted avg       0.54      0.48      0.42        58\n",
            "\n",
            "epoch - 58/150 train_loss - 0.570 acc - 0.658 roc - 0.617 prc_auc - 0.744 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  9]\n",
            " [ 2 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.18      0.27        11\n",
            "         1.0       0.73      0.92      0.81        26\n",
            "\n",
            "    accuracy                           0.70        37\n",
            "   macro avg       0.61      0.55      0.54        37\n",
            "weighted avg       0.66      0.70      0.65        37\n",
            "\n",
            "epoch - 59/150 train_loss - 0.535 acc - 0.661 roc - 0.618 prc_auc - 0.744 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  8]\n",
            " [ 4 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.20      0.25        10\n",
            "         1.0       0.75      0.86      0.80        28\n",
            "\n",
            "    accuracy                           0.68        38\n",
            "   macro avg       0.54      0.53      0.52        38\n",
            "weighted avg       0.64      0.68      0.66        38\n",
            "\n",
            "epoch - 60/150 train_loss - 0.538 acc - 0.659 roc - 0.621 prc_auc - 0.744 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 13]\n",
            " [ 1 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.24      0.36        17\n",
            "         1.0       0.75      0.98      0.85        41\n",
            "\n",
            "    accuracy                           0.76        58\n",
            "   macro avg       0.78      0.61      0.61        58\n",
            "weighted avg       0.77      0.76      0.71        58\n",
            "\n",
            "epoch - 61/150 train_loss - 0.556 acc - 0.664 roc - 0.623 prc_auc - 0.746 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 14]\n",
            " [ 6 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.12      0.17        16\n",
            "         1.0       0.58      0.76      0.66        25\n",
            "\n",
            "    accuracy                           0.51        41\n",
            "   macro avg       0.41      0.44      0.41        41\n",
            "weighted avg       0.45      0.51      0.46        41\n",
            "\n",
            "epoch - 62/150 train_loss - 0.552 acc - 0.653 roc - 0.622 prc_auc - 0.745 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 15]\n",
            " [ 1 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.06      0.11        16\n",
            "         1.0       0.73      0.98      0.84        42\n",
            "\n",
            "    accuracy                           0.72        58\n",
            "   macro avg       0.62      0.52      0.47        58\n",
            "weighted avg       0.67      0.72      0.64        58\n",
            "\n",
            "epoch - 63/150 train_loss - 0.557 acc - 0.660 roc - 0.626 prc_auc - 0.747 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 10]\n",
            " [ 4 44]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        10\n",
            "         1.0       0.81      0.92      0.86        48\n",
            "\n",
            "    accuracy                           0.76        58\n",
            "   macro avg       0.41      0.46      0.43        58\n",
            "weighted avg       0.67      0.76      0.71        58\n",
            "\n",
            "epoch - 64/150 train_loss - 0.551 acc - 0.662 roc - 0.628 prc_auc - 0.747 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 11]\n",
            " [ 4 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.31      0.40        16\n",
            "         1.0       0.67      0.85      0.75        26\n",
            "\n",
            "    accuracy                           0.64        42\n",
            "   macro avg       0.61      0.58      0.57        42\n",
            "weighted avg       0.62      0.64      0.61        42\n",
            "\n",
            "epoch - 65/150 train_loss - 0.544 acc - 0.665 roc - 0.627 prc_auc - 0.748 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 21]\n",
            " [ 1 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.30      0.45        30\n",
            "         1.0       0.56      0.96      0.71        28\n",
            "\n",
            "    accuracy                           0.62        58\n",
            "   macro avg       0.73      0.63      0.58        58\n",
            "weighted avg       0.74      0.62      0.58        58\n",
            "\n",
            "epoch - 66/150 train_loss - 0.562 acc - 0.662 roc - 0.628 prc_auc - 0.748 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 14]\n",
            " [ 5 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.36      0.46        22\n",
            "         1.0       0.69      0.86      0.77        36\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.65      0.61      0.61        58\n",
            "weighted avg       0.66      0.67      0.65        58\n",
            "\n",
            "epoch - 67/150 train_loss - 0.558 acc - 0.666 roc - 0.630 prc_auc - 0.750 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 15]\n",
            " [ 5 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.17      0.23        18\n",
            "         1.0       0.70      0.88      0.78        40\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.54      0.52      0.50        58\n",
            "weighted avg       0.60      0.66      0.61        58\n",
            "\n",
            "epoch - 68/150 train_loss - 0.559 acc - 0.660 roc - 0.628 prc_auc - 0.746 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  5]\n",
            " [ 1 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         5\n",
            "         1.0       0.87      0.97      0.92        35\n",
            "\n",
            "    accuracy                           0.85        40\n",
            "   macro avg       0.44      0.49      0.46        40\n",
            "weighted avg       0.76      0.85      0.80        40\n",
            "\n",
            "epoch - 69/150 train_loss - 0.525 acc - 0.665 roc - 0.634 prc_auc - 0.751 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  9]\n",
            " [ 2 44]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.18      0.27        11\n",
            "         1.0       0.83      0.96      0.89        46\n",
            "\n",
            "    accuracy                           0.81        57\n",
            "   macro avg       0.67      0.57      0.58        57\n",
            "weighted avg       0.77      0.81      0.77        57\n",
            "\n",
            "epoch - 70/150 train_loss - 0.540 acc - 0.670 roc - 0.637 prc_auc - 0.750 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 14]\n",
            " [ 0 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.18      0.30        17\n",
            "         1.0       0.69      1.00      0.82        31\n",
            "\n",
            "    accuracy                           0.71        48\n",
            "   macro avg       0.84      0.59      0.56        48\n",
            "weighted avg       0.80      0.71      0.63        48\n",
            "\n",
            "epoch - 71/150 train_loss - 0.544 acc - 0.666 roc - 0.633 prc_auc - 0.752 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 22]\n",
            " [ 2 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.12      0.20        25\n",
            "         1.0       0.46      0.90      0.61        21\n",
            "\n",
            "    accuracy                           0.48        46\n",
            "   macro avg       0.53      0.51      0.41        46\n",
            "weighted avg       0.54      0.48      0.39        46\n",
            "\n",
            "epoch - 72/150 train_loss - 0.557 acc - 0.663 roc - 0.634 prc_auc - 0.753 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7  7]\n",
            " [ 1 43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.50      0.64        14\n",
            "         1.0       0.86      0.98      0.91        44\n",
            "\n",
            "    accuracy                           0.86        58\n",
            "   macro avg       0.87      0.74      0.78        58\n",
            "weighted avg       0.86      0.86      0.85        58\n",
            "\n",
            "epoch - 73/150 train_loss - 0.546 acc - 0.665 roc - 0.636 prc_auc - 0.753 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 2]\n",
            " [1 8]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.50      0.57         4\n",
            "         1.0       0.80      0.89      0.84         9\n",
            "\n",
            "    accuracy                           0.77        13\n",
            "   macro avg       0.73      0.69      0.71        13\n",
            "weighted avg       0.76      0.77      0.76        13\n",
            "\n",
            "epoch - 74/150 train_loss - 0.508 acc - 0.665 roc - 0.635 prc_auc - 0.752 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 17]\n",
            " [ 3 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.29      0.41        24\n",
            "         1.0       0.53      0.86      0.66        22\n",
            "\n",
            "    accuracy                           0.57        46\n",
            "   macro avg       0.61      0.58      0.53        46\n",
            "weighted avg       0.62      0.57      0.53        46\n",
            "\n",
            "epoch - 75/150 train_loss - 0.549 acc - 0.665 roc - 0.635 prc_auc - 0.755 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 21]\n",
            " [ 2 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.05      0.08        22\n",
            "         1.0       0.62      0.94      0.75        36\n",
            "\n",
            "    accuracy                           0.60        58\n",
            "   macro avg       0.48      0.49      0.41        58\n",
            "weighted avg       0.51      0.60      0.49        58\n",
            "\n",
            "epoch - 76/150 train_loss - 0.556 acc - 0.666 roc - 0.637 prc_auc - 0.754 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 14]\n",
            " [ 5 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.07      0.10        15\n",
            "         1.0       0.73      0.88      0.80        42\n",
            "\n",
            "    accuracy                           0.67        57\n",
            "   macro avg       0.45      0.47      0.45        57\n",
            "weighted avg       0.58      0.67      0.61        57\n",
            "\n",
            "epoch - 77/150 train_loss - 0.551 acc - 0.665 roc - 0.636 prc_auc - 0.755 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 19]\n",
            " [ 0 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.17      0.30        23\n",
            "         1.0       0.64      1.00      0.78        34\n",
            "\n",
            "    accuracy                           0.67        57\n",
            "   macro avg       0.82      0.59      0.54        57\n",
            "weighted avg       0.79      0.67      0.59        57\n",
            "\n",
            "epoch - 78/150 train_loss - 0.555 acc - 0.668 roc - 0.635 prc_auc - 0.754 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 10]\n",
            " [ 2 14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.38      0.50        16\n",
            "         1.0       0.58      0.88      0.70        16\n",
            "\n",
            "    accuracy                           0.62        32\n",
            "   macro avg       0.67      0.62      0.60        32\n",
            "weighted avg       0.67      0.62      0.60        32\n",
            "\n",
            "epoch - 79/150 train_loss - 0.530 acc - 0.670 roc - 0.639 prc_auc - 0.756 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 13]\n",
            " [ 3 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.19      0.27        16\n",
            "         1.0       0.75      0.93      0.83        42\n",
            "\n",
            "    accuracy                           0.72        58\n",
            "   macro avg       0.62      0.56      0.55        58\n",
            "weighted avg       0.68      0.72      0.68        58\n",
            "\n",
            "epoch - 80/150 train_loss - 0.551 acc - 0.668 roc - 0.639 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 21]\n",
            " [ 4 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.09      0.14        23\n",
            "         1.0       0.60      0.89      0.71        35\n",
            "\n",
            "    accuracy                           0.57        58\n",
            "   macro avg       0.46      0.49      0.43        58\n",
            "weighted avg       0.49      0.57      0.48        58\n",
            "\n",
            "epoch - 81/150 train_loss - 0.560 acc - 0.671 roc - 0.641 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 12]\n",
            " [ 3 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.25      0.35        16\n",
            "         1.0       0.74      0.92      0.82        38\n",
            "\n",
            "    accuracy                           0.72        54\n",
            "   macro avg       0.66      0.59      0.59        54\n",
            "weighted avg       0.69      0.72      0.68        54\n",
            "\n",
            "epoch - 82/150 train_loss - 0.547 acc - 0.670 roc - 0.640 prc_auc - 0.755 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 15]\n",
            " [ 2 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.32      0.45        22\n",
            "         1.0       0.62      0.92      0.74        26\n",
            "\n",
            "    accuracy                           0.65        48\n",
            "   macro avg       0.70      0.62      0.60        48\n",
            "weighted avg       0.69      0.65      0.61        48\n",
            "\n",
            "epoch - 83/150 train_loss - 0.542 acc - 0.671 roc - 0.644 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 14]\n",
            " [ 1 23]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.21        16\n",
            "         1.0       0.62      0.96      0.75        24\n",
            "\n",
            "    accuracy                           0.62        40\n",
            "   macro avg       0.64      0.54      0.48        40\n",
            "weighted avg       0.64      0.62      0.54        40\n",
            "\n",
            "epoch - 84/150 train_loss - 0.539 acc - 0.666 roc - 0.639 prc_auc - 0.756 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 18]\n",
            " [ 1 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.22      0.34        23\n",
            "         1.0       0.65      0.97      0.78        35\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.74      0.59      0.56        58\n",
            "weighted avg       0.73      0.67      0.61        58\n",
            "\n",
            "epoch - 85/150 train_loss - 0.554 acc - 0.669 roc - 0.642 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 13]\n",
            " [ 4 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.28      0.37        18\n",
            "         1.0       0.73      0.90      0.81        40\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.65      0.59      0.59        58\n",
            "weighted avg       0.68      0.71      0.67        58\n",
            "\n",
            "epoch - 86/150 train_loss - 0.546 acc - 0.666 roc - 0.644 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 15]\n",
            " [ 1 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.35      0.50        23\n",
            "         1.0       0.69      0.97      0.81        35\n",
            "\n",
            "    accuracy                           0.72        58\n",
            "   macro avg       0.79      0.66      0.65        58\n",
            "weighted avg       0.77      0.72      0.69        58\n",
            "\n",
            "epoch - 87/150 train_loss - 0.548 acc - 0.668 roc - 0.645 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  3]\n",
            " [ 4 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.40      0.36         5\n",
            "         1.0       0.94      0.92      0.93        53\n",
            "\n",
            "    accuracy                           0.88        58\n",
            "   macro avg       0.64      0.66      0.65        58\n",
            "weighted avg       0.89      0.88      0.88        58\n",
            "\n",
            "epoch - 88/150 train_loss - 0.535 acc - 0.671 roc - 0.648 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  4]\n",
            " [ 4 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.20      0.20         5\n",
            "         1.0       0.73      0.73      0.73        15\n",
            "\n",
            "    accuracy                           0.60        20\n",
            "   macro avg       0.47      0.47      0.47        20\n",
            "weighted avg       0.60      0.60      0.60        20\n",
            "\n",
            "epoch - 89/150 train_loss - 0.512 acc - 0.676 roc - 0.646 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 18]\n",
            " [ 1 38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.05      0.10        19\n",
            "         1.0       0.68      0.97      0.80        39\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.59      0.51      0.45        58\n",
            "weighted avg       0.62      0.67      0.57        58\n",
            "\n",
            "epoch - 90/150 train_loss - 0.550 acc - 0.670 roc - 0.647 prc_auc - 0.761 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 12]\n",
            " [ 2 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.20      0.30        15\n",
            "         1.0       0.72      0.94      0.82        33\n",
            "\n",
            "    accuracy                           0.71        48\n",
            "   macro avg       0.66      0.57      0.56        48\n",
            "weighted avg       0.68      0.71      0.65        48\n",
            "\n",
            "epoch - 91/150 train_loss - 0.535 acc - 0.671 roc - 0.650 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 17]\n",
            " [ 3 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.29      0.41        24\n",
            "         1.0       0.65      0.91      0.76        34\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.67      0.60      0.58        58\n",
            "weighted avg       0.67      0.66      0.61        58\n",
            "\n",
            "epoch - 92/150 train_loss - 0.548 acc - 0.674 roc - 0.650 prc_auc - 0.761 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8  7]\n",
            " [ 1 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.53      0.67        15\n",
            "         1.0       0.70      0.94      0.80        17\n",
            "\n",
            "    accuracy                           0.75        32\n",
            "   macro avg       0.79      0.74      0.73        32\n",
            "weighted avg       0.79      0.75      0.74        32\n",
            "\n",
            "epoch - 93/150 train_loss - 0.523 acc - 0.671 roc - 0.648 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  8]\n",
            " [ 1 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.20      0.31        10\n",
            "         1.0       0.78      0.97      0.87        30\n",
            "\n",
            "    accuracy                           0.78        40\n",
            "   macro avg       0.73      0.58      0.59        40\n",
            "weighted avg       0.75      0.78      0.73        40\n",
            "\n",
            "epoch - 94/150 train_loss - 0.529 acc - 0.669 roc - 0.647 prc_auc - 0.760 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 22]\n",
            " [ 1 33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.08      0.15        24\n",
            "         1.0       0.60      0.97      0.74        34\n",
            "\n",
            "    accuracy                           0.60        58\n",
            "   macro avg       0.63      0.53      0.44        58\n",
            "weighted avg       0.63      0.60      0.50        58\n",
            "\n",
            "epoch - 95/150 train_loss - 0.554 acc - 0.669 roc - 0.650 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 19]\n",
            " [ 2 33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.17      0.28        23\n",
            "         1.0       0.63      0.94      0.76        35\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.65      0.56      0.52        58\n",
            "weighted avg       0.65      0.64      0.57        58\n",
            "\n",
            "epoch - 96/150 train_loss - 0.556 acc - 0.670 roc - 0.651 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  9]\n",
            " [ 4 42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.25      0.32        12\n",
            "         1.0       0.82      0.91      0.87        46\n",
            "\n",
            "    accuracy                           0.78        58\n",
            "   macro avg       0.63      0.58      0.59        58\n",
            "weighted avg       0.74      0.78      0.75        58\n",
            "\n",
            "epoch - 97/150 train_loss - 0.540 acc - 0.663 roc - 0.652 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5  8]\n",
            " [ 0 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.38      0.56        13\n",
            "         1.0       0.69      1.00      0.82        18\n",
            "\n",
            "    accuracy                           0.74        31\n",
            "   macro avg       0.85      0.69      0.69        31\n",
            "weighted avg       0.82      0.74      0.71        31\n",
            "\n",
            "epoch - 98/150 train_loss - 0.521 acc - 0.676 roc - 0.651 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 14]\n",
            " [ 3 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.07      0.11        15\n",
            "         1.0       0.74      0.93      0.82        43\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.50      0.50      0.47        58\n",
            "weighted avg       0.61      0.71      0.64        58\n",
            "\n",
            "epoch - 99/150 train_loss - 0.546 acc - 0.675 roc - 0.650 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 12]\n",
            " [ 1 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.20      0.32        15\n",
            "         1.0       0.67      0.96      0.79        25\n",
            "\n",
            "    accuracy                           0.68        40\n",
            "   macro avg       0.71      0.58      0.55        40\n",
            "weighted avg       0.70      0.68      0.61        40\n",
            "\n",
            "epoch - 100/150 train_loss - 0.530 acc - 0.672 roc - 0.654 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 12]\n",
            " [ 2  9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.20      0.30        15\n",
            "         1.0       0.43      0.82      0.56        11\n",
            "\n",
            "    accuracy                           0.46        26\n",
            "   macro avg       0.51      0.51      0.43        26\n",
            "weighted avg       0.53      0.46      0.41        26\n",
            "\n",
            "epoch - 101/150 train_loss - 0.525 acc - 0.671 roc - 0.652 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3  2]\n",
            " [ 3 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.60      0.55         5\n",
            "         1.0       0.94      0.91      0.92        33\n",
            "\n",
            "    accuracy                           0.87        38\n",
            "   macro avg       0.72      0.75      0.73        38\n",
            "weighted avg       0.88      0.87      0.87        38\n",
            "\n",
            "epoch - 102/150 train_loss - 0.519 acc - 0.673 roc - 0.651 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 17]\n",
            " [ 2 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.15      0.24        20\n",
            "         1.0       0.60      0.93      0.73        28\n",
            "\n",
            "    accuracy                           0.60        48\n",
            "   macro avg       0.60      0.54      0.49        48\n",
            "weighted avg       0.60      0.60      0.53        48\n",
            "\n",
            "epoch - 103/150 train_loss - 0.538 acc - 0.676 roc - 0.656 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 17]\n",
            " [ 2 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.23      0.34        22\n",
            "         1.0       0.67      0.94      0.78        36\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.69      0.59      0.56        58\n",
            "weighted avg       0.68      0.67      0.62        58\n",
            "\n",
            "epoch - 104/150 train_loss - 0.548 acc - 0.672 roc - 0.656 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 25]\n",
            " [ 3 21]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.26      0.39        34\n",
            "         1.0       0.46      0.88      0.60        24\n",
            "\n",
            "    accuracy                           0.52        58\n",
            "   macro avg       0.60      0.57      0.50        58\n",
            "weighted avg       0.63      0.52      0.48        58\n",
            "\n",
            "epoch - 105/150 train_loss - 0.557 acc - 0.670 roc - 0.654 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 17]\n",
            " [ 6 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.32      0.41        25\n",
            "         1.0       0.61      0.82      0.70        33\n",
            "\n",
            "    accuracy                           0.60        58\n",
            "   macro avg       0.59      0.57      0.56        58\n",
            "weighted avg       0.60      0.60      0.58        58\n",
            "\n",
            "epoch - 106/150 train_loss - 0.548 acc - 0.677 roc - 0.654 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 11]\n",
            " [ 1 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.27      0.40        15\n",
            "         1.0       0.79      0.98      0.87        42\n",
            "\n",
            "    accuracy                           0.79        57\n",
            "   macro avg       0.79      0.62      0.64        57\n",
            "weighted avg       0.79      0.79      0.75        57\n",
            "\n",
            "epoch - 107/150 train_loss - 0.535 acc - 0.674 roc - 0.653 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  8]\n",
            " [ 4 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.11      0.14         9\n",
            "         1.0       0.77      0.87      0.82        31\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.49      0.49      0.48        40\n",
            "weighted avg       0.64      0.70      0.67        40\n",
            "\n",
            "epoch - 108/150 train_loss - 0.527 acc - 0.678 roc - 0.653 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 17]\n",
            " [ 4 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        17\n",
            "         1.0       0.69      0.90      0.78        41\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.34      0.45      0.39        58\n",
            "weighted avg       0.48      0.64      0.55        58\n",
            "\n",
            "epoch - 109/150 train_loss - 0.545 acc - 0.675 roc - 0.658 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 22]\n",
            " [ 4 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.08      0.13        24\n",
            "         1.0       0.57      0.88      0.69        33\n",
            "\n",
            "    accuracy                           0.54        57\n",
            "   macro avg       0.45      0.48      0.41        57\n",
            "weighted avg       0.47      0.54      0.46        57\n",
            "\n",
            "epoch - 110/150 train_loss - 0.554 acc - 0.672 roc - 0.658 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 16]\n",
            " [ 1 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.24      0.37        21\n",
            "         1.0       0.69      0.97      0.81        37\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.76      0.61      0.59        58\n",
            "weighted avg       0.74      0.71      0.65        58\n",
            "\n",
            "epoch - 111/150 train_loss - 0.549 acc - 0.675 roc - 0.653 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 11]\n",
            " [ 1 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.21      0.33        14\n",
            "         1.0       0.69      0.96      0.81        26\n",
            "\n",
            "    accuracy                           0.70        40\n",
            "   macro avg       0.72      0.59      0.57        40\n",
            "weighted avg       0.71      0.70      0.64        40\n",
            "\n",
            "epoch - 112/150 train_loss - 0.528 acc - 0.672 roc - 0.655 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 15]\n",
            " [ 2 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.29      0.41        21\n",
            "         1.0       0.62      0.93      0.75        27\n",
            "\n",
            "    accuracy                           0.65        48\n",
            "   macro avg       0.69      0.61      0.58        48\n",
            "weighted avg       0.68      0.65      0.60        48\n",
            "\n",
            "epoch - 113/150 train_loss - 0.539 acc - 0.674 roc - 0.658 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 21]\n",
            " [ 5 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.12      0.19        24\n",
            "         1.0       0.58      0.85      0.69        34\n",
            "\n",
            "    accuracy                           0.55        58\n",
            "   macro avg       0.48      0.49      0.44        58\n",
            "weighted avg       0.50      0.55      0.48        58\n",
            "\n",
            "epoch - 114/150 train_loss - 0.554 acc - 0.677 roc - 0.660 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 19]\n",
            " [ 3 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.21      0.31        24\n",
            "         1.0       0.62      0.91      0.74        34\n",
            "\n",
            "    accuracy                           0.62        58\n",
            "   macro avg       0.62      0.56      0.53        58\n",
            "weighted avg       0.62      0.62      0.56        58\n",
            "\n",
            "epoch - 115/150 train_loss - 0.550 acc - 0.679 roc - 0.659 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 16]\n",
            " [ 3 32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.30      0.42        23\n",
            "         1.0       0.67      0.91      0.77        35\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.68      0.61      0.60        58\n",
            "weighted avg       0.68      0.67      0.63        58\n",
            "\n",
            "epoch - 116/150 train_loss - 0.552 acc - 0.672 roc - 0.656 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 18]\n",
            " [ 3 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.10      0.16        20\n",
            "         1.0       0.66      0.92      0.77        38\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.53      0.51      0.46        58\n",
            "weighted avg       0.57      0.64      0.56        58\n",
            "\n",
            "epoch - 117/150 train_loss - 0.548 acc - 0.676 roc - 0.657 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 15]\n",
            " [ 2 21]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.17      0.26        18\n",
            "         1.0       0.58      0.91      0.71        23\n",
            "\n",
            "    accuracy                           0.59        41\n",
            "   macro avg       0.59      0.54      0.49        41\n",
            "weighted avg       0.59      0.59      0.51        41\n",
            "\n",
            "epoch - 118/150 train_loss - 0.534 acc - 0.678 roc - 0.663 prc_auc - 0.772 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  2]\n",
            " [ 1 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.50      0.57         4\n",
            "         1.0       0.92      0.96      0.94        23\n",
            "\n",
            "    accuracy                           0.89        27\n",
            "   macro avg       0.79      0.73      0.75        27\n",
            "weighted avg       0.88      0.89      0.88        27\n",
            "\n",
            "epoch - 119/150 train_loss - 0.508 acc - 0.675 roc - 0.660 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 17]\n",
            " [ 6 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.15      0.21        20\n",
            "         1.0       0.48      0.73      0.58        22\n",
            "\n",
            "    accuracy                           0.45        42\n",
            "   macro avg       0.41      0.44      0.39        42\n",
            "weighted avg       0.41      0.45      0.40        42\n",
            "\n",
            "epoch - 120/150 train_loss - 0.539 acc - 0.671 roc - 0.661 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 16]\n",
            " [ 5 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.16      0.22        19\n",
            "         1.0       0.66      0.86      0.75        36\n",
            "\n",
            "    accuracy                           0.62        55\n",
            "   macro avg       0.52      0.51      0.48        55\n",
            "weighted avg       0.56      0.62      0.57        55\n",
            "\n",
            "epoch - 121/150 train_loss - 0.546 acc - 0.678 roc - 0.657 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 3]\n",
            " [3 6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.25      0.25         4\n",
            "         1.0       0.67      0.67      0.67         9\n",
            "\n",
            "    accuracy                           0.54        13\n",
            "   macro avg       0.46      0.46      0.46        13\n",
            "weighted avg       0.54      0.54      0.54        13\n",
            "\n",
            "epoch - 122/150 train_loss - 0.502 acc - 0.678 roc - 0.659 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 11]\n",
            " [ 1 43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.21      0.33        14\n",
            "         1.0       0.80      0.98      0.88        44\n",
            "\n",
            "    accuracy                           0.79        58\n",
            "   macro avg       0.77      0.60      0.61        58\n",
            "weighted avg       0.79      0.79      0.75        58\n",
            "\n",
            "epoch - 123/150 train_loss - 0.543 acc - 0.671 roc - 0.657 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 20]\n",
            " [ 3 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.17      0.26        24\n",
            "         1.0       0.57      0.90      0.69        29\n",
            "\n",
            "    accuracy                           0.57        53\n",
            "   macro avg       0.57      0.53      0.48        53\n",
            "weighted avg       0.57      0.57      0.50        53\n",
            "\n",
            "epoch - 124/150 train_loss - 0.547 acc - 0.671 roc - 0.658 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 18]\n",
            " [ 3 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.28      0.40        25\n",
            "         1.0       0.62      0.91      0.74        33\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.66      0.59      0.57        58\n",
            "weighted avg       0.66      0.64      0.59        58\n",
            "\n",
            "epoch - 125/150 train_loss - 0.547 acc - 0.670 roc - 0.663 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 14]\n",
            " [ 6 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.22      0.29        18\n",
            "         1.0       0.69      0.84      0.76        37\n",
            "\n",
            "    accuracy                           0.64        55\n",
            "   macro avg       0.54      0.53      0.52        55\n",
            "weighted avg       0.59      0.64      0.60        55\n",
            "\n",
            "epoch - 126/150 train_loss - 0.546 acc - 0.677 roc - 0.661 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 16]\n",
            " [ 5 23]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.11      0.16        18\n",
            "         1.0       0.59      0.82      0.69        28\n",
            "\n",
            "    accuracy                           0.54        46\n",
            "   macro avg       0.44      0.47      0.42        46\n",
            "weighted avg       0.47      0.54      0.48        46\n",
            "\n",
            "epoch - 127/150 train_loss - 0.539 acc - 0.675 roc - 0.660 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 13]\n",
            " [ 5 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.32      0.40        19\n",
            "         1.0       0.72      0.87      0.79        39\n",
            "\n",
            "    accuracy                           0.69        58\n",
            "   macro avg       0.63      0.59      0.60        58\n",
            "weighted avg       0.67      0.69      0.66        58\n",
            "\n",
            "epoch - 128/150 train_loss - 0.545 acc - 0.672 roc - 0.659 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4  5]\n",
            " [ 4 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.44      0.47         9\n",
            "         1.0       0.83      0.86      0.84        28\n",
            "\n",
            "    accuracy                           0.76        37\n",
            "   macro avg       0.66      0.65      0.66        37\n",
            "weighted avg       0.75      0.76      0.75        37\n",
            "\n",
            "epoch - 129/150 train_loss - 0.516 acc - 0.678 roc - 0.662 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 19]\n",
            " [ 6 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.17      0.24        23\n",
            "         1.0       0.60      0.83      0.70        35\n",
            "\n",
            "    accuracy                           0.57        58\n",
            "   macro avg       0.50      0.50      0.47        58\n",
            "weighted avg       0.52      0.57      0.52        58\n",
            "\n",
            "epoch - 130/150 train_loss - 0.552 acc - 0.675 roc - 0.662 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 16]\n",
            " [ 4 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.20      0.29        20\n",
            "         1.0       0.68      0.89      0.77        38\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.59      0.55      0.53        58\n",
            "weighted avg       0.62      0.66      0.60        58\n",
            "\n",
            "epoch - 131/150 train_loss - 0.547 acc - 0.675 roc - 0.661 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 19]\n",
            " [ 3 32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.17      0.27        23\n",
            "         1.0       0.63      0.91      0.74        35\n",
            "\n",
            "    accuracy                           0.62        58\n",
            "   macro avg       0.60      0.54      0.51        58\n",
            "weighted avg       0.61      0.62      0.55        58\n",
            "\n",
            "epoch - 132/150 train_loss - 0.549 acc - 0.677 roc - 0.660 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 19]\n",
            " [ 6 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.14      0.19        22\n",
            "         1.0       0.61      0.83      0.71        36\n",
            "\n",
            "    accuracy                           0.57        58\n",
            "   macro avg       0.47      0.48      0.45        58\n",
            "weighted avg       0.51      0.57      0.51        58\n",
            "\n",
            "epoch - 133/150 train_loss - 0.548 acc - 0.674 roc - 0.659 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 12]\n",
            " [ 2 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.33      0.46        18\n",
            "         1.0       0.70      0.93      0.80        30\n",
            "\n",
            "    accuracy                           0.71        48\n",
            "   macro avg       0.72      0.63      0.63        48\n",
            "weighted avg       0.72      0.71      0.67        48\n",
            "\n",
            "epoch - 134/150 train_loss - 0.532 acc - 0.679 roc - 0.659 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  6]\n",
            " [ 1 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.14      0.22         7\n",
            "         1.0       0.88      0.98      0.93        47\n",
            "\n",
            "    accuracy                           0.87        54\n",
            "   macro avg       0.69      0.56      0.58        54\n",
            "weighted avg       0.83      0.87      0.84        54\n",
            "\n",
            "epoch - 135/150 train_loss - 0.529 acc - 0.679 roc - 0.660 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 11]\n",
            " [ 3 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.27      0.36        15\n",
            "         1.0       0.62      0.86      0.72        21\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.60      0.56      0.54        36\n",
            "weighted avg       0.60      0.61      0.57        36\n",
            "\n",
            "epoch - 136/150 train_loss - 0.525 acc - 0.673 roc - 0.660 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 17]\n",
            " [ 1 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.15      0.25        20\n",
            "         1.0       0.69      0.97      0.80        38\n",
            "\n",
            "    accuracy                           0.69        58\n",
            "   macro avg       0.72      0.56      0.53        58\n",
            "weighted avg       0.71      0.69      0.61        58\n",
            "\n",
            "epoch - 137/150 train_loss - 0.545 acc - 0.675 roc - 0.659 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 13]\n",
            " [ 4 17]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.13      0.19        15\n",
            "         1.0       0.57      0.81      0.67        21\n",
            "\n",
            "    accuracy                           0.53        36\n",
            "   macro avg       0.45      0.47      0.43        36\n",
            "weighted avg       0.47      0.53      0.47        36\n",
            "\n",
            "epoch - 138/150 train_loss - 0.528 acc - 0.678 roc - 0.661 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 13]\n",
            " [ 1 38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.32      0.46        19\n",
            "         1.0       0.75      0.97      0.84        39\n",
            "\n",
            "    accuracy                           0.76        58\n",
            "   macro avg       0.80      0.65      0.65        58\n",
            "weighted avg       0.78      0.76      0.72        58\n",
            "\n",
            "epoch - 139/150 train_loss - 0.541 acc - 0.679 roc - 0.660 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 18]\n",
            " [ 4 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.22      0.31        23\n",
            "         1.0       0.63      0.89      0.74        35\n",
            "\n",
            "    accuracy                           0.62        58\n",
            "   macro avg       0.59      0.55      0.53        58\n",
            "weighted avg       0.60      0.62      0.57        58\n",
            "\n",
            "epoch - 140/150 train_loss - 0.549 acc - 0.678 roc - 0.661 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 19]\n",
            " [ 2 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.27      0.40        26\n",
            "         1.0       0.61      0.94      0.74        32\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.70      0.60      0.57        58\n",
            "weighted avg       0.69      0.64      0.59        58\n",
            "\n",
            "epoch - 141/150 train_loss - 0.545 acc - 0.676 roc - 0.660 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 16]\n",
            " [ 1 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.11      0.19        18\n",
            "         1.0       0.71      0.97      0.82        40\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.69      0.54      0.51        58\n",
            "weighted avg       0.70      0.71      0.63        58\n",
            "\n",
            "epoch - 142/150 train_loss - 0.537 acc - 0.671 roc - 0.662 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 17]\n",
            " [ 0 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.29      0.45        24\n",
            "         1.0       0.67      1.00      0.80        34\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.83      0.65      0.63        58\n",
            "weighted avg       0.80      0.71      0.66        58\n",
            "\n",
            "epoch - 143/150 train_loss - 0.552 acc - 0.674 roc - 0.660 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 16]\n",
            " [ 3 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.20      0.30        20\n",
            "         1.0       0.69      0.92      0.79        38\n",
            "\n",
            "    accuracy                           0.67        58\n",
            "   macro avg       0.63      0.56      0.54        58\n",
            "weighted avg       0.65      0.67      0.62        58\n",
            "\n",
            "epoch - 144/150 train_loss - 0.548 acc - 0.675 roc - 0.660 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 16]\n",
            " [ 5 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.27      0.36        22\n",
            "         1.0       0.66      0.86      0.75        36\n",
            "\n",
            "    accuracy                           0.64        58\n",
            "   macro avg       0.60      0.57      0.56        58\n",
            "weighted avg       0.62      0.64      0.60        58\n",
            "\n",
            "epoch - 145/150 train_loss - 0.550 acc - 0.678 roc - 0.661 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:02<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  8]\n",
            " [ 4 22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.20      0.25        10\n",
            "         1.0       0.73      0.85      0.79        26\n",
            "\n",
            "    accuracy                           0.67        36\n",
            "   macro avg       0.53      0.52      0.52        36\n",
            "weighted avg       0.62      0.67      0.64        36\n",
            "\n",
            "epoch - 146/150 train_loss - 0.523 acc - 0.673 roc - 0.661 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:02<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 16]\n",
            " [ 4 32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.27      0.37        22\n",
            "         1.0       0.67      0.89      0.76        36\n",
            "\n",
            "    accuracy                           0.66        58\n",
            "   macro avg       0.63      0.58      0.57        58\n",
            "weighted avg       0.64      0.66      0.62        58\n",
            "\n",
            "epoch - 147/150 train_loss - 0.546 acc - 0.676 roc - 0.658 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:02<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 17]\n",
            " [ 6 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.54      0.29      0.38        24\n",
            "         1.0       0.62      0.82      0.71        34\n",
            "\n",
            "    accuracy                           0.60        58\n",
            "   macro avg       0.58      0.56      0.54        58\n",
            "weighted avg       0.59      0.60      0.57        58\n",
            "\n",
            "epoch - 148/150 train_loss - 0.549 acc - 0.673 roc - 0.662 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:02<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2  7]\n",
            " [ 4 43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.22      0.27         9\n",
            "         1.0       0.86      0.91      0.89        47\n",
            "\n",
            "    accuracy                           0.80        56\n",
            "   macro avg       0.60      0.57      0.58        56\n",
            "weighted avg       0.78      0.80      0.79        56\n",
            "\n",
            "epoch - 149/150 train_loss - 0.535 acc - 0.678 roc - 0.660 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 8/8 [00:02<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 12]\n",
            " [ 4 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.20      0.27        15\n",
            "         1.0       0.76      0.91      0.83        43\n",
            "\n",
            "    accuracy                           0.72        58\n",
            "   macro avg       0.60      0.55      0.55        58\n",
            "weighted avg       0.68      0.72      0.69        58\n",
            "\n",
            "epoch - 150/150 train_loss - 0.538 acc - 0.675 roc - 0.659 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z8DvafjokYi"
      },
      "source": [
        "#Test function \n",
        "import psutil\n",
        "def test_epoch(model, test_iterator, criterion, device=\"cpu\"):\n",
        "  model.load_state_dict(torch.load(\"sakt_model.pt\"))\n",
        "  model.eval()\n",
        "  #print(\"inside test_epoch !!\") \n",
        "  test_loss = []\n",
        "  num_corrects = 0\n",
        "  num_total = 0\n",
        "  labels = []\n",
        "  outs = []\n",
        "  preds = []\n",
        "\n",
        "  prev_test_df = None\n",
        "  tbar = tqdm(test_iterator)\n",
        "  for item in tbar:\n",
        "          x = item[0].to(device).long()\n",
        "          target_id = item[1].to(device).long()\n",
        "          label = item[2].to(device).float()\n",
        "          target_mask = (target_id != 0)\n",
        "\n",
        "          with torch.no_grad():\n",
        "            output, att_weight = model(x, target_id)\n",
        "          \n",
        "          \n",
        "          output = torch.masked_select(output, target_mask)\n",
        "          label = torch.masked_select(label, target_mask)\n",
        "\n",
        "          loss = criterion(output, label)\n",
        "          test_loss.append(loss.item())\n",
        "\n",
        "          pred = (torch.sigmoid(output) >= 0.5).long()\n",
        "          num_corrects += (pred == label).sum().item()\n",
        "          num_total += len(label)\n",
        "          print('num_cor:', num_corrects)\n",
        "          print(\"tot:\",num_total)\n",
        "\n",
        "          labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
        "          outs.extend(output.view(-1).data.cpu().numpy())\n",
        "          preds.extend(pred.squeeze(-1).data.cpu().numpy())\n",
        "\n",
        "  \n",
        "  acc = num_corrects / num_total\n",
        "  roc = roc_auc_score(labels, outs)\n",
        "  precision, recall, _ = precision_recall_curve(labels,outs)\n",
        "  auc_score = auc(recall, precision)\n",
        "  loss = np.average(test_loss)\n",
        "  \n",
        "  print(metrics.confusion_matrix(label,pred))\n",
        "  print(metrics.classification_report(label,pred))\n",
        "\n",
        "  return loss, acc, roc, auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYKQube8okYj"
      },
      "source": [
        "#make test epoch =1 \n",
        "epoch_test = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VyrJrseO6cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2548261f-2e48-4628-814b-e34169ea2549"
      },
      "source": [
        "#Testing on 5049\n",
        "for epoch in range(epoch_test):\n",
        "  test_loss_1, test_acc_1, test_roc_1, prc_auc_1 = test_epoch(model, test_dataloader_1, criterion, device)\n",
        "  print(\"Testing on 5049!!!\")\n",
        "  print(\"epoch - {}/{} test - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f}\".format(epoch+1,epoch_test, test_loss_1, test_acc_1, test_roc_1, prc_auc_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cor: 277\n",
            "tot: 490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 31 165]\n",
            " [ 48 246]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.39      0.16      0.23       196\n",
            "         1.0       0.60      0.84      0.70       294\n",
            "\n",
            "    accuracy                           0.57       490\n",
            "   macro avg       0.50      0.50      0.46       490\n",
            "weighted avg       0.52      0.57      0.51       490\n",
            "\n",
            "Testing on 5049!!!\n",
            "epoch - 1/1 test - 0.727 acc - 0.565 roc - 0.487 prc_auc - 0.599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P5MSmqH9_ps"
      },
      "source": [
        "#Load the model weights and test on task3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAVoasYa-z1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfb5efc-cd2b-40c5-c56c-837b3142c27d"
      },
      "source": [
        "#Call the SAKT model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SAKTModel(n_questions, embed_dim = 128)  #The dimension of embeddings d is 128.\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.99, weight_decay=0.01)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "scheduler_1 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_1), epochs=epochs\n",
        ")\n",
        "\n",
        "scheduler_2 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_2), epochs=epochs\n",
        ")\n",
        "\n",
        "scheduler_3 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_3), epochs=epochs\n",
        ")\n",
        "\n",
        "#scheduler_12 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "#    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_12), epochs=epochs\n",
        "#)\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrKA_DxJ_BxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd03d60-1765-4b21-b0c2-b15ba7d267bf"
      },
      "source": [
        "#Function call for Train on 5117\n",
        "best_auc = 0\n",
        "max_steps = 50\n",
        "step = 0\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc, roc, prc_auc = train_epoch(model, train_dataloader_3, optimizer, scheduler_3, criterion, device)\n",
        "  print(\"epoch - {}/{} train_loss - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f} \".format(epoch+1, epochs, train_loss, train_acc, roc, prc_auc))\n",
        "  \n",
        "  if roc > best_auc:\n",
        "    best_auc = roc\n",
        "    step = 0\n",
        "    torch.save(model.state_dict(), \"sakt_task2.pt\")\n",
        "  else:\n",
        "    step += 1\n",
        "    if step >= max_steps:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13 12]\n",
            " [36 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.52      0.35        25\n",
            "         1.0       0.76      0.51      0.61        73\n",
            "\n",
            "    accuracy                           0.51        98\n",
            "   macro avg       0.51      0.51      0.48        98\n",
            "weighted avg       0.63      0.51      0.54        98\n",
            "\n",
            "epoch - 1/150 train_loss - 0.600 acc - 0.502 roc - 0.510 prc_auc - 0.660 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17 19]\n",
            " [34 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.47      0.39        36\n",
            "         1.0       0.61      0.47      0.53        64\n",
            "\n",
            "    accuracy                           0.47       100\n",
            "   macro avg       0.47      0.47      0.46       100\n",
            "weighted avg       0.51      0.47      0.48       100\n",
            "\n",
            "epoch - 2/150 train_loss - 0.583 acc - 0.500 roc - 0.510 prc_auc - 0.660 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16 11]\n",
            " [37 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.30      0.59      0.40        27\n",
            "         1.0       0.77      0.49      0.60        73\n",
            "\n",
            "    accuracy                           0.52       100\n",
            "   macro avg       0.53      0.54      0.50       100\n",
            "weighted avg       0.64      0.52      0.55       100\n",
            "\n",
            "epoch - 3/150 train_loss - 0.563 acc - 0.501 roc - 0.509 prc_auc - 0.660 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16 21]\n",
            " [32 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.43      0.38        37\n",
            "         1.0       0.54      0.44      0.49        57\n",
            "\n",
            "    accuracy                           0.44        94\n",
            "   macro avg       0.44      0.44      0.43        94\n",
            "weighted avg       0.46      0.44      0.44        94\n",
            "\n",
            "epoch - 4/150 train_loss - 0.546 acc - 0.502 roc - 0.509 prc_auc - 0.661 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20 22]\n",
            " [20 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.48      0.49        42\n",
            "         1.0       0.42      0.44      0.43        36\n",
            "\n",
            "    accuracy                           0.46        78\n",
            "   macro avg       0.46      0.46      0.46        78\n",
            "weighted avg       0.46      0.46      0.46        78\n",
            "\n",
            "epoch - 5/150 train_loss - 0.533 acc - 0.497 roc - 0.508 prc_auc - 0.661 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 16]\n",
            " [28 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.54      0.46        35\n",
            "         1.0       0.50      0.36      0.42        44\n",
            "\n",
            "    accuracy                           0.44        79\n",
            "   macro avg       0.45      0.45      0.44        79\n",
            "weighted avg       0.46      0.44      0.44        79\n",
            "\n",
            "epoch - 6/150 train_loss - 0.524 acc - 0.510 roc - 0.507 prc_auc - 0.661 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7  6]\n",
            " [50 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.54      0.20        13\n",
            "         1.0       0.91      0.56      0.70       114\n",
            "\n",
            "    accuracy                           0.56       127\n",
            "   macro avg       0.52      0.55      0.45       127\n",
            "weighted avg       0.83      0.56      0.64       127\n",
            "\n",
            "epoch - 7/150 train_loss - 0.519 acc - 0.519 roc - 0.513 prc_auc - 0.664 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 19]\n",
            " [30 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.37      0.31        30\n",
            "         1.0       0.70      0.60      0.65        75\n",
            "\n",
            "    accuracy                           0.53       105\n",
            "   macro avg       0.49      0.48      0.48       105\n",
            "weighted avg       0.58      0.53      0.55       105\n",
            "\n",
            "epoch - 8/150 train_loss - 0.509 acc - 0.526 roc - 0.510 prc_auc - 0.663 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 25]\n",
            " [25 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.22      0.22        32\n",
            "         1.0       0.54      0.54      0.54        54\n",
            "\n",
            "    accuracy                           0.42        86\n",
            "   macro avg       0.38      0.38      0.38        86\n",
            "weighted avg       0.42      0.42      0.42        86\n",
            "\n",
            "epoch - 9/150 train_loss - 0.501 acc - 0.534 roc - 0.510 prc_auc - 0.663 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 24]\n",
            " [23 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.34      0.33      0.34        36\n",
            "         1.0       0.68      0.68      0.68        73\n",
            "\n",
            "    accuracy                           0.57       109\n",
            "   macro avg       0.51      0.51      0.51       109\n",
            "weighted avg       0.57      0.57      0.57       109\n",
            "\n",
            "epoch - 10/150 train_loss - 0.496 acc - 0.551 roc - 0.515 prc_auc - 0.667 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 32]\n",
            " [29 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.27      0.28        44\n",
            "         1.0       0.56      0.58      0.57        69\n",
            "\n",
            "    accuracy                           0.46       113\n",
            "   macro avg       0.42      0.43      0.42       113\n",
            "weighted avg       0.45      0.46      0.46       113\n",
            "\n",
            "epoch - 11/150 train_loss - 0.491 acc - 0.558 roc - 0.515 prc_auc - 0.666 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 19]\n",
            " [24 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.27      0.25        26\n",
            "         1.0       0.72      0.67      0.70        73\n",
            "\n",
            "    accuracy                           0.57        99\n",
            "   macro avg       0.47      0.47      0.47        99\n",
            "weighted avg       0.59      0.57      0.58        99\n",
            "\n",
            "epoch - 12/150 train_loss - 0.482 acc - 0.571 roc - 0.516 prc_auc - 0.668 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 13]\n",
            " [20 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.19      0.15        16\n",
            "         1.0       0.74      0.65      0.69        57\n",
            "\n",
            "    accuracy                           0.55        73\n",
            "   macro avg       0.44      0.42      0.42        73\n",
            "weighted avg       0.61      0.55      0.57        73\n",
            "\n",
            "epoch - 13/150 train_loss - 0.475 acc - 0.581 roc - 0.518 prc_auc - 0.669 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 21]\n",
            " [15 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.30      0.33        30\n",
            "         1.0       0.72      0.78      0.75        69\n",
            "\n",
            "    accuracy                           0.64        99\n",
            "   macro avg       0.55      0.54      0.54        99\n",
            "weighted avg       0.62      0.64      0.62        99\n",
            "\n",
            "epoch - 14/150 train_loss - 0.474 acc - 0.597 roc - 0.519 prc_auc - 0.670 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 25]\n",
            " [19 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.17      0.19        30\n",
            "         1.0       0.67      0.72      0.69        69\n",
            "\n",
            "    accuracy                           0.56        99\n",
            "   macro avg       0.44      0.45      0.44        99\n",
            "weighted avg       0.53      0.56      0.54        99\n",
            "\n",
            "epoch - 15/150 train_loss - 0.470 acc - 0.593 roc - 0.522 prc_auc - 0.672 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13 25]\n",
            " [12 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.52      0.34      0.41        38\n",
            "         1.0       0.66      0.80      0.73        61\n",
            "\n",
            "    accuracy                           0.63        99\n",
            "   macro avg       0.59      0.57      0.57        99\n",
            "weighted avg       0.61      0.63      0.61        99\n",
            "\n",
            "epoch - 16/150 train_loss - 0.466 acc - 0.602 roc - 0.523 prc_auc - 0.673 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 21]\n",
            " [11 58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.30      0.36        30\n",
            "         1.0       0.73      0.84      0.78        69\n",
            "\n",
            "    accuracy                           0.68        99\n",
            "   macro avg       0.59      0.57      0.57        99\n",
            "weighted avg       0.65      0.68      0.66        99\n",
            "\n",
            "epoch - 17/150 train_loss - 0.462 acc - 0.618 roc - 0.529 prc_auc - 0.677 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 38]\n",
            " [11 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.35      0.14      0.20        44\n",
            "         1.0       0.52      0.79      0.63        52\n",
            "\n",
            "    accuracy                           0.49        96\n",
            "   macro avg       0.44      0.46      0.41        96\n",
            "weighted avg       0.44      0.49      0.43        96\n",
            "\n",
            "epoch - 18/150 train_loss - 0.464 acc - 0.616 roc - 0.525 prc_auc - 0.675 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 28]\n",
            " [ 6 63]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.54      0.20      0.29        35\n",
            "         1.0       0.69      0.91      0.79        69\n",
            "\n",
            "    accuracy                           0.67       104\n",
            "   macro avg       0.62      0.56      0.54       104\n",
            "weighted avg       0.64      0.67      0.62       104\n",
            "\n",
            "epoch - 19/150 train_loss - 0.459 acc - 0.617 roc - 0.530 prc_auc - 0.679 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 49]\n",
            " [10 60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.20      0.29        61\n",
            "         1.0       0.55      0.86      0.67        70\n",
            "\n",
            "    accuracy                           0.55       131\n",
            "   macro avg       0.55      0.53      0.48       131\n",
            "weighted avg       0.55      0.55      0.49       131\n",
            "\n",
            "epoch - 20/150 train_loss - 0.463 acc - 0.622 roc - 0.530 prc_auc - 0.679 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 20]\n",
            " [ 8 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.17      0.22        24\n",
            "         1.0       0.76      0.89      0.82        72\n",
            "\n",
            "    accuracy                           0.71        96\n",
            "   macro avg       0.55      0.53      0.52        96\n",
            "weighted avg       0.65      0.71      0.67        96\n",
            "\n",
            "epoch - 21/150 train_loss - 0.455 acc - 0.620 roc - 0.533 prc_auc - 0.680 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 52]\n",
            " [11 62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.39      0.12      0.18        59\n",
            "         1.0       0.54      0.85      0.66        73\n",
            "\n",
            "    accuracy                           0.52       132\n",
            "   macro avg       0.47      0.48      0.42       132\n",
            "weighted avg       0.47      0.52      0.45       132\n",
            "\n",
            "epoch - 22/150 train_loss - 0.461 acc - 0.626 roc - 0.536 prc_auc - 0.684 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 32]\n",
            " [ 9 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.18      0.25        39\n",
            "         1.0       0.56      0.82      0.67        50\n",
            "\n",
            "    accuracy                           0.54        89\n",
            "   macro avg       0.50      0.50      0.46        89\n",
            "weighted avg       0.51      0.54      0.49        89\n",
            "\n",
            "epoch - 23/150 train_loss - 0.454 acc - 0.629 roc - 0.536 prc_auc - 0.683 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 35]\n",
            " [ 8 80]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.12      0.19        40\n",
            "         1.0       0.70      0.91      0.79        88\n",
            "\n",
            "    accuracy                           0.66       128\n",
            "   macro avg       0.54      0.52      0.49       128\n",
            "weighted avg       0.60      0.66      0.60       128\n",
            "\n",
            "epoch - 24/150 train_loss - 0.456 acc - 0.629 roc - 0.538 prc_auc - 0.685 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 30]\n",
            " [ 8 56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.09      0.14        33\n",
            "         1.0       0.65      0.88      0.75        64\n",
            "\n",
            "    accuracy                           0.61        97\n",
            "   macro avg       0.46      0.48      0.44        97\n",
            "weighted avg       0.52      0.61      0.54        97\n",
            "\n",
            "epoch - 25/150 train_loss - 0.453 acc - 0.631 roc - 0.538 prc_auc - 0.686 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 22]\n",
            " [ 9 95]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.15      0.21        26\n",
            "         1.0       0.81      0.91      0.86       104\n",
            "\n",
            "    accuracy                           0.76       130\n",
            "   macro avg       0.56      0.53      0.53       130\n",
            "weighted avg       0.71      0.76      0.73       130\n",
            "\n",
            "epoch - 26/150 train_loss - 0.452 acc - 0.633 roc - 0.542 prc_auc - 0.688 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 21]\n",
            " [ 4 37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.05      0.07        22\n",
            "         1.0       0.64      0.90      0.75        41\n",
            "\n",
            "    accuracy                           0.60        63\n",
            "   macro avg       0.42      0.47      0.41        63\n",
            "weighted avg       0.49      0.60      0.51        63\n",
            "\n",
            "epoch - 27/150 train_loss - 0.444 acc - 0.636 roc - 0.545 prc_auc - 0.690 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 28]\n",
            " [ 4 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.12      0.20        32\n",
            "         1.0       0.56      0.90      0.69        39\n",
            "\n",
            "    accuracy                           0.55        71\n",
            "   macro avg       0.53      0.51      0.44        71\n",
            "weighted avg       0.53      0.55      0.47        71\n",
            "\n",
            "epoch - 28/150 train_loss - 0.446 acc - 0.634 roc - 0.545 prc_auc - 0.692 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 25]\n",
            " [ 9 44]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.04      0.06        26\n",
            "         1.0       0.64      0.83      0.72        53\n",
            "\n",
            "    accuracy                           0.57        79\n",
            "   macro avg       0.37      0.43      0.39        79\n",
            "weighted avg       0.46      0.57      0.50        79\n",
            "\n",
            "epoch - 29/150 train_loss - 0.446 acc - 0.636 roc - 0.546 prc_auc - 0.692 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 25]\n",
            " [ 4 47]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.04      0.06        26\n",
            "         1.0       0.65      0.92      0.76        51\n",
            "\n",
            "    accuracy                           0.62        77\n",
            "   macro avg       0.43      0.48      0.41        77\n",
            "weighted avg       0.50      0.62      0.53        77\n",
            "\n",
            "epoch - 30/150 train_loss - 0.444 acc - 0.636 roc - 0.547 prc_auc - 0.693 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 39]\n",
            " [ 7 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.05      0.08        41\n",
            "         1.0       0.65      0.91      0.76        78\n",
            "\n",
            "    accuracy                           0.61       119\n",
            "   macro avg       0.43      0.48      0.42       119\n",
            "weighted avg       0.50      0.61      0.52       119\n",
            "\n",
            "epoch - 31/150 train_loss - 0.448 acc - 0.640 roc - 0.548 prc_auc - 0.694 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 34]\n",
            " [ 7 60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.30      0.08      0.13        37\n",
            "         1.0       0.64      0.90      0.75        67\n",
            "\n",
            "    accuracy                           0.61       104\n",
            "   macro avg       0.47      0.49      0.44       104\n",
            "weighted avg       0.52      0.61      0.53       104\n",
            "\n",
            "epoch - 32/150 train_loss - 0.446 acc - 0.639 roc - 0.550 prc_auc - 0.694 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 32]\n",
            " [ 9 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.09      0.13        35\n",
            "         1.0       0.67      0.88      0.76        74\n",
            "\n",
            "    accuracy                           0.62       109\n",
            "   macro avg       0.46      0.48      0.44       109\n",
            "weighted avg       0.54      0.62      0.56       109\n",
            "\n",
            "epoch - 33/150 train_loss - 0.447 acc - 0.640 roc - 0.551 prc_auc - 0.694 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 43]\n",
            " [ 4 66]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.17      0.28        52\n",
            "         1.0       0.61      0.94      0.74        70\n",
            "\n",
            "    accuracy                           0.61       122\n",
            "   macro avg       0.65      0.56      0.51       122\n",
            "weighted avg       0.64      0.61      0.54       122\n",
            "\n",
            "epoch - 34/150 train_loss - 0.449 acc - 0.641 roc - 0.552 prc_auc - 0.696 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 21]\n",
            " [ 5 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.22      0.32        27\n",
            "         1.0       0.69      0.90      0.78        51\n",
            "\n",
            "    accuracy                           0.67        78\n",
            "   macro avg       0.62      0.56      0.55        78\n",
            "weighted avg       0.64      0.67      0.62        78\n",
            "\n",
            "epoch - 35/150 train_loss - 0.440 acc - 0.640 roc - 0.556 prc_auc - 0.698 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 25]\n",
            " [ 5 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.17      0.25        30\n",
            "         1.0       0.66      0.91      0.76        53\n",
            "\n",
            "    accuracy                           0.64        83\n",
            "   macro avg       0.58      0.54      0.51        83\n",
            "weighted avg       0.60      0.64      0.58        83\n",
            "\n",
            "epoch - 36/150 train_loss - 0.441 acc - 0.645 roc - 0.557 prc_auc - 0.700 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 22]\n",
            " [ 4 42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.08      0.13        24\n",
            "         1.0       0.66      0.91      0.76        46\n",
            "\n",
            "    accuracy                           0.63        70\n",
            "   macro avg       0.49      0.50      0.45        70\n",
            "weighted avg       0.55      0.63      0.55        70\n",
            "\n",
            "epoch - 37/150 train_loss - 0.440 acc - 0.640 roc - 0.557 prc_auc - 0.700 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 20]\n",
            " [ 2 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.20      0.31        25\n",
            "         1.0       0.67      0.95      0.79        43\n",
            "\n",
            "    accuracy                           0.68        68\n",
            "   macro avg       0.69      0.58      0.55        68\n",
            "weighted avg       0.69      0.68      0.61        68\n",
            "\n",
            "epoch - 38/150 train_loss - 0.438 acc - 0.643 roc - 0.560 prc_auc - 0.701 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 25]\n",
            " [ 7 66]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.07      0.11        27\n",
            "         1.0       0.73      0.90      0.80        73\n",
            "\n",
            "    accuracy                           0.68       100\n",
            "   macro avg       0.47      0.49      0.46       100\n",
            "weighted avg       0.59      0.68      0.62       100\n",
            "\n",
            "epoch - 39/150 train_loss - 0.441 acc - 0.641 roc - 0.562 prc_auc - 0.703 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 22]\n",
            " [ 4 38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.15      0.24        26\n",
            "         1.0       0.63      0.90      0.75        42\n",
            "\n",
            "    accuracy                           0.62        68\n",
            "   macro avg       0.57      0.53      0.49        68\n",
            "weighted avg       0.58      0.62      0.55        68\n",
            "\n",
            "epoch - 40/150 train_loss - 0.437 acc - 0.646 roc - 0.564 prc_auc - 0.704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 31]\n",
            " [ 4 53]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.18      0.29        38\n",
            "         1.0       0.63      0.93      0.75        57\n",
            "\n",
            "    accuracy                           0.63        95\n",
            "   macro avg       0.63      0.56      0.52        95\n",
            "weighted avg       0.63      0.63      0.57        95\n",
            "\n",
            "epoch - 41/150 train_loss - 0.441 acc - 0.646 roc - 0.562 prc_auc - 0.704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 29]\n",
            " [ 8 40]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.09      0.14        32\n",
            "         1.0       0.58      0.83      0.68        48\n",
            "\n",
            "    accuracy                           0.54        80\n",
            "   macro avg       0.43      0.46      0.41        80\n",
            "weighted avg       0.46      0.54      0.47        80\n",
            "\n",
            "epoch - 42/150 train_loss - 0.438 acc - 0.642 roc - 0.565 prc_auc - 0.706 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 12.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 45]\n",
            " [ 7 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.17      0.26        54\n",
            "         1.0       0.56      0.89      0.69        64\n",
            "\n",
            "    accuracy                           0.56       118\n",
            "   macro avg       0.56      0.53      0.47       118\n",
            "weighted avg       0.56      0.56      0.49       118\n",
            "\n",
            "epoch - 43/150 train_loss - 0.444 acc - 0.642 roc - 0.565 prc_auc - 0.705 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 32]\n",
            " [10 70]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.47      0.22      0.30        41\n",
            "         1.0       0.69      0.88      0.77        80\n",
            "\n",
            "    accuracy                           0.65       121\n",
            "   macro avg       0.58      0.55      0.53       121\n",
            "weighted avg       0.61      0.65      0.61       121\n",
            "\n",
            "epoch - 44/150 train_loss - 0.442 acc - 0.644 roc - 0.566 prc_auc - 0.706 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 25]\n",
            " [ 6 66]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.17      0.24        30\n",
            "         1.0       0.73      0.92      0.81        72\n",
            "\n",
            "    accuracy                           0.70       102\n",
            "   macro avg       0.59      0.54      0.53       102\n",
            "weighted avg       0.65      0.70      0.64       102\n",
            "\n",
            "epoch - 45/150 train_loss - 0.438 acc - 0.644 roc - 0.570 prc_auc - 0.707 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 36]\n",
            " [ 9 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.16      0.24        43\n",
            "         1.0       0.67      0.89      0.76        82\n",
            "\n",
            "    accuracy                           0.64       125\n",
            "   macro avg       0.55      0.53      0.50       125\n",
            "weighted avg       0.59      0.64      0.58       125\n",
            "\n",
            "epoch - 46/150 train_loss - 0.441 acc - 0.642 roc - 0.570 prc_auc - 0.709 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 21]\n",
            " [ 4 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.16      0.24        25\n",
            "         1.0       0.62      0.89      0.73        38\n",
            "\n",
            "    accuracy                           0.60        63\n",
            "   macro avg       0.56      0.53      0.49        63\n",
            "weighted avg       0.57      0.60      0.54        63\n",
            "\n",
            "epoch - 47/150 train_loss - 0.435 acc - 0.647 roc - 0.569 prc_auc - 0.708 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 36]\n",
            " [ 8 55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.14      0.21        42\n",
            "         1.0       0.60      0.87      0.71        63\n",
            "\n",
            "    accuracy                           0.58       105\n",
            "   macro avg       0.52      0.51      0.46       105\n",
            "weighted avg       0.53      0.58      0.51       105\n",
            "\n",
            "epoch - 48/150 train_loss - 0.440 acc - 0.648 roc - 0.571 prc_auc - 0.709 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 26]\n",
            " [ 2 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        26\n",
            "         1.0       0.74      0.97      0.84        76\n",
            "\n",
            "    accuracy                           0.73       102\n",
            "   macro avg       0.37      0.49      0.42       102\n",
            "weighted avg       0.55      0.73      0.63       102\n",
            "\n",
            "epoch - 49/150 train_loss - 0.437 acc - 0.644 roc - 0.571 prc_auc - 0.709 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 21]\n",
            " [ 4 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.19      0.29        26\n",
            "         1.0       0.70      0.92      0.79        52\n",
            "\n",
            "    accuracy                           0.68        78\n",
            "   macro avg       0.63      0.56      0.54        78\n",
            "weighted avg       0.65      0.68      0.62        78\n",
            "\n",
            "epoch - 50/150 train_loss - 0.435 acc - 0.645 roc - 0.573 prc_auc - 0.711 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 21]\n",
            " [ 6 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.16      0.23        25\n",
            "         1.0       0.70      0.89      0.79        56\n",
            "\n",
            "    accuracy                           0.67        81\n",
            "   macro avg       0.55      0.53      0.51        81\n",
            "weighted avg       0.61      0.67      0.61        81\n",
            "\n",
            "epoch - 51/150 train_loss - 0.434 acc - 0.644 roc - 0.573 prc_auc - 0.712 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 36]\n",
            " [ 5 63]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.10      0.16        40\n",
            "         1.0       0.64      0.93      0.75        68\n",
            "\n",
            "    accuracy                           0.62       108\n",
            "   macro avg       0.54      0.51      0.46       108\n",
            "weighted avg       0.57      0.62      0.54       108\n",
            "\n",
            "epoch - 52/150 train_loss - 0.438 acc - 0.646 roc - 0.576 prc_auc - 0.714 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 27]\n",
            " [ 9 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.21      0.28        34\n",
            "         1.0       0.71      0.88      0.78        74\n",
            "\n",
            "    accuracy                           0.67       108\n",
            "   macro avg       0.57      0.54      0.53       108\n",
            "weighted avg       0.62      0.67      0.62       108\n",
            "\n",
            "epoch - 53/150 train_loss - 0.437 acc - 0.648 roc - 0.574 prc_auc - 0.713 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 19]\n",
            " [ 6 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.24      0.32        25\n",
            "         1.0       0.71      0.88      0.79        52\n",
            "\n",
            "    accuracy                           0.68        77\n",
            "   macro avg       0.60      0.56      0.56        77\n",
            "weighted avg       0.64      0.68      0.64        77\n",
            "\n",
            "epoch - 54/150 train_loss - 0.434 acc - 0.647 roc - 0.575 prc_auc - 0.713 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 26]\n",
            " [ 6 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.10      0.16        29\n",
            "         1.0       0.71      0.92      0.80        71\n",
            "\n",
            "    accuracy                           0.68       100\n",
            "   macro avg       0.52      0.51      0.48       100\n",
            "weighted avg       0.60      0.68      0.62       100\n",
            "\n",
            "epoch - 55/150 train_loss - 0.436 acc - 0.648 roc - 0.579 prc_auc - 0.714 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 50]\n",
            " [ 3 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.09      0.16        55\n",
            "         1.0       0.56      0.96      0.71        67\n",
            "\n",
            "    accuracy                           0.57       122\n",
            "   macro avg       0.59      0.52      0.43       122\n",
            "weighted avg       0.59      0.57      0.46       122\n",
            "\n",
            "epoch - 56/150 train_loss - 0.441 acc - 0.649 roc - 0.577 prc_auc - 0.714 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 27]\n",
            " [ 5 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.13      0.20        31\n",
            "         1.0       0.73      0.94      0.82        78\n",
            "\n",
            "    accuracy                           0.71       109\n",
            "   macro avg       0.59      0.53      0.51       109\n",
            "weighted avg       0.65      0.71      0.64       109\n",
            "\n",
            "epoch - 57/150 train_loss - 0.437 acc - 0.649 roc - 0.578 prc_auc - 0.715 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 32]\n",
            " [12 58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.22      0.29        41\n",
            "         1.0       0.64      0.83      0.73        70\n",
            "\n",
            "    accuracy                           0.60       111\n",
            "   macro avg       0.54      0.52      0.51       111\n",
            "weighted avg       0.56      0.60      0.56       111\n",
            "\n",
            "epoch - 58/150 train_loss - 0.437 acc - 0.647 roc - 0.579 prc_auc - 0.716 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 25]\n",
            " [ 5 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.11      0.17        28\n",
            "         1.0       0.61      0.89      0.72        44\n",
            "\n",
            "    accuracy                           0.58        72\n",
            "   macro avg       0.49      0.50      0.44        72\n",
            "weighted avg       0.52      0.58      0.51        72\n",
            "\n",
            "epoch - 59/150 train_loss - 0.433 acc - 0.647 roc - 0.578 prc_auc - 0.714 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 33]\n",
            " [ 9 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.15      0.22        39\n",
            "         1.0       0.73      0.91      0.81        98\n",
            "\n",
            "    accuracy                           0.69       137\n",
            "   macro avg       0.56      0.53      0.52       137\n",
            "weighted avg       0.64      0.69      0.64       137\n",
            "\n",
            "epoch - 60/150 train_loss - 0.439 acc - 0.647 roc - 0.580 prc_auc - 0.716 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 41]\n",
            " [ 4 55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.07      0.12        44\n",
            "         1.0       0.57      0.93      0.71        59\n",
            "\n",
            "    accuracy                           0.56       103\n",
            "   macro avg       0.50      0.50      0.41       103\n",
            "weighted avg       0.51      0.56      0.46       103\n",
            "\n",
            "epoch - 61/150 train_loss - 0.437 acc - 0.649 roc - 0.582 prc_auc - 0.717 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 37]\n",
            " [ 8 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.12      0.18        42\n",
            "         1.0       0.59      0.87      0.71        62\n",
            "\n",
            "    accuracy                           0.57       104\n",
            "   macro avg       0.49      0.50      0.44       104\n",
            "weighted avg       0.51      0.57      0.49       104\n",
            "\n",
            "epoch - 62/150 train_loss - 0.437 acc - 0.648 roc - 0.581 prc_auc - 0.716 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14 39]\n",
            " [ 2 53]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.26      0.41        53\n",
            "         1.0       0.58      0.96      0.72        55\n",
            "\n",
            "    accuracy                           0.62       108\n",
            "   macro avg       0.73      0.61      0.56       108\n",
            "weighted avg       0.72      0.62      0.57       108\n",
            "\n",
            "epoch - 63/150 train_loss - 0.436 acc - 0.652 roc - 0.581 prc_auc - 0.717 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 37]\n",
            " [ 3 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.23      0.35        48\n",
            "         1.0       0.67      0.96      0.79        77\n",
            "\n",
            "    accuracy                           0.68       125\n",
            "   macro avg       0.73      0.60      0.57       125\n",
            "weighted avg       0.71      0.68      0.62       125\n",
            "\n",
            "epoch - 64/150 train_loss - 0.437 acc - 0.649 roc - 0.583 prc_auc - 0.717 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 16]\n",
            " [ 1 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.06      0.11        17\n",
            "         1.0       0.66      0.97      0.78        32\n",
            "\n",
            "    accuracy                           0.65        49\n",
            "   macro avg       0.58      0.51      0.45        49\n",
            "weighted avg       0.60      0.65      0.55        49\n",
            "\n",
            "epoch - 65/150 train_loss - 0.429 acc - 0.648 roc - 0.582 prc_auc - 0.718 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 32]\n",
            " [ 5 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.11      0.18        36\n",
            "         1.0       0.64      0.92      0.75        62\n",
            "\n",
            "    accuracy                           0.62        98\n",
            "   macro avg       0.54      0.52      0.47        98\n",
            "weighted avg       0.57      0.62      0.54        98\n",
            "\n",
            "epoch - 66/150 train_loss - 0.435 acc - 0.647 roc - 0.583 prc_auc - 0.718 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 43]\n",
            " [ 9 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.09      0.13        47\n",
            "         1.0       0.54      0.85      0.66        59\n",
            "\n",
            "    accuracy                           0.51       106\n",
            "   macro avg       0.42      0.47      0.40       106\n",
            "weighted avg       0.44      0.51      0.43       106\n",
            "\n",
            "epoch - 67/150 train_loss - 0.436 acc - 0.648 roc - 0.584 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 17]\n",
            " [ 6 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.23      0.30        22\n",
            "         1.0       0.65      0.84      0.73        37\n",
            "\n",
            "    accuracy                           0.61        59\n",
            "   macro avg       0.55      0.53      0.52        59\n",
            "weighted avg       0.57      0.61      0.57        59\n",
            "\n",
            "epoch - 68/150 train_loss - 0.430 acc - 0.651 roc - 0.583 prc_auc - 0.718 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00,  9.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 28]\n",
            " [ 2 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.15      0.25        33\n",
            "         1.0       0.56      0.95      0.70        37\n",
            "\n",
            "    accuracy                           0.57        70\n",
            "   macro avg       0.63      0.55      0.48        70\n",
            "weighted avg       0.63      0.57      0.49        70\n",
            "\n",
            "epoch - 69/150 train_loss - 0.431 acc - 0.649 roc - 0.584 prc_auc - 0.719 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 29]\n",
            " [ 7 66]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.22      0.31        37\n",
            "         1.0       0.69      0.90      0.79        73\n",
            "\n",
            "    accuracy                           0.67       110\n",
            "   macro avg       0.61      0.56      0.55       110\n",
            "weighted avg       0.64      0.67      0.62       110\n",
            "\n",
            "epoch - 70/150 train_loss - 0.434 acc - 0.649 roc - 0.587 prc_auc - 0.721 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 26]\n",
            " [ 9 53]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.13      0.19        30\n",
            "         1.0       0.67      0.85      0.75        62\n",
            "\n",
            "    accuracy                           0.62        92\n",
            "   macro avg       0.49      0.49      0.47        92\n",
            "weighted avg       0.55      0.62      0.57        92\n",
            "\n",
            "epoch - 71/150 train_loss - 0.433 acc - 0.647 roc - 0.585 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 31]\n",
            " [ 2 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.03      0.06        32\n",
            "         1.0       0.70      0.97      0.81        73\n",
            "\n",
            "    accuracy                           0.69       105\n",
            "   macro avg       0.51      0.50      0.43       105\n",
            "weighted avg       0.59      0.69      0.58       105\n",
            "\n",
            "epoch - 72/150 train_loss - 0.434 acc - 0.649 roc - 0.584 prc_auc - 0.717 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 16]\n",
            " [ 0 47]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.16      0.27        19\n",
            "         1.0       0.75      1.00      0.85        47\n",
            "\n",
            "    accuracy                           0.76        66\n",
            "   macro avg       0.87      0.58      0.56        66\n",
            "weighted avg       0.82      0.76      0.69        66\n",
            "\n",
            "epoch - 73/150 train_loss - 0.428 acc - 0.650 roc - 0.589 prc_auc - 0.721 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 35]\n",
            " [ 7 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.03      0.05        36\n",
            "         1.0       0.62      0.89      0.73        64\n",
            "\n",
            "    accuracy                           0.58       100\n",
            "   macro avg       0.37      0.46      0.39       100\n",
            "weighted avg       0.44      0.58      0.48       100\n",
            "\n",
            "epoch - 74/150 train_loss - 0.434 acc - 0.649 roc - 0.587 prc_auc - 0.722 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 20]\n",
            " [ 5 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.20      0.29        25\n",
            "         1.0       0.71      0.91      0.80        54\n",
            "\n",
            "    accuracy                           0.68        79\n",
            "   macro avg       0.61      0.55      0.54        79\n",
            "weighted avg       0.64      0.68      0.64        79\n",
            "\n",
            "epoch - 75/150 train_loss - 0.430 acc - 0.648 roc - 0.587 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 47]\n",
            " [ 5 59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.11      0.19        53\n",
            "         1.0       0.56      0.92      0.69        64\n",
            "\n",
            "    accuracy                           0.56       117\n",
            "   macro avg       0.55      0.52      0.44       117\n",
            "weighted avg       0.55      0.56      0.46       117\n",
            "\n",
            "epoch - 76/150 train_loss - 0.437 acc - 0.653 roc - 0.588 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 48]\n",
            " [ 1 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.04      0.08        50\n",
            "         1.0       0.46      0.98      0.63        42\n",
            "\n",
            "    accuracy                           0.47        92\n",
            "   macro avg       0.56      0.51      0.35        92\n",
            "weighted avg       0.57      0.47      0.33        92\n",
            "\n",
            "epoch - 77/150 train_loss - 0.435 acc - 0.648 roc - 0.587 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 31]\n",
            " [ 2 51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.16      0.27        37\n",
            "         1.0       0.62      0.96      0.76        53\n",
            "\n",
            "    accuracy                           0.63        90\n",
            "   macro avg       0.69      0.56      0.51        90\n",
            "weighted avg       0.67      0.63      0.55        90\n",
            "\n",
            "epoch - 78/150 train_loss - 0.433 acc - 0.647 roc - 0.586 prc_auc - 0.719 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 11]\n",
            " [ 3 63]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.21      0.30        14\n",
            "         1.0       0.85      0.95      0.90        66\n",
            "\n",
            "    accuracy                           0.82        80\n",
            "   macro avg       0.68      0.58      0.60        80\n",
            "weighted avg       0.79      0.82      0.80        80\n",
            "\n",
            "epoch - 79/150 train_loss - 0.428 acc - 0.650 roc - 0.590 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 30]\n",
            " [10 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.17      0.23        36\n",
            "         1.0       0.70      0.88      0.78        81\n",
            "\n",
            "    accuracy                           0.66       117\n",
            "   macro avg       0.54      0.52      0.51       117\n",
            "weighted avg       0.60      0.66      0.61       117\n",
            "\n",
            "epoch - 80/150 train_loss - 0.434 acc - 0.650 roc - 0.590 prc_auc - 0.722 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 35]\n",
            " [ 6 63]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.24      0.35        46\n",
            "         1.0       0.64      0.91      0.75        69\n",
            "\n",
            "    accuracy                           0.64       115\n",
            "   macro avg       0.64      0.58      0.55       115\n",
            "weighted avg       0.64      0.64      0.59       115\n",
            "\n",
            "epoch - 81/150 train_loss - 0.435 acc - 0.653 roc - 0.587 prc_auc - 0.721 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 27]\n",
            " [ 3 56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.10      0.17        30\n",
            "         1.0       0.67      0.95      0.79        59\n",
            "\n",
            "    accuracy                           0.66        89\n",
            "   macro avg       0.59      0.52      0.48        89\n",
            "weighted avg       0.62      0.66      0.58        89\n",
            "\n",
            "epoch - 82/150 train_loss - 0.431 acc - 0.651 roc - 0.588 prc_auc - 0.722 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 24]\n",
            " [10 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.08      0.11        26\n",
            "         1.0       0.76      0.89      0.82        88\n",
            "\n",
            "    accuracy                           0.70       114\n",
            "   macro avg       0.47      0.48      0.46       114\n",
            "weighted avg       0.63      0.70      0.66       114\n",
            "\n",
            "epoch - 83/150 train_loss - 0.433 acc - 0.653 roc - 0.589 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 37]\n",
            " [ 5 81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.05      0.09        39\n",
            "         1.0       0.69      0.94      0.79        86\n",
            "\n",
            "    accuracy                           0.66       125\n",
            "   macro avg       0.49      0.50      0.44       125\n",
            "weighted avg       0.56      0.66      0.57       125\n",
            "\n",
            "epoch - 84/150 train_loss - 0.435 acc - 0.652 roc - 0.588 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 55]\n",
            " [ 5 58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.10      0.17        61\n",
            "         1.0       0.51      0.92      0.66        63\n",
            "\n",
            "    accuracy                           0.52       124\n",
            "   macro avg       0.53      0.51      0.41       124\n",
            "weighted avg       0.53      0.52      0.42       124\n",
            "\n",
            "epoch - 85/150 train_loss - 0.438 acc - 0.648 roc - 0.587 prc_auc - 0.722 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 31]\n",
            " [ 3 62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.14      0.23        36\n",
            "         1.0       0.67      0.95      0.78        65\n",
            "\n",
            "    accuracy                           0.66       101\n",
            "   macro avg       0.65      0.55      0.51       101\n",
            "weighted avg       0.65      0.66      0.59       101\n",
            "\n",
            "epoch - 86/150 train_loss - 0.434 acc - 0.654 roc - 0.586 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 37]\n",
            " [ 7 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.10      0.15        41\n",
            "         1.0       0.62      0.90      0.73        68\n",
            "\n",
            "    accuracy                           0.60       109\n",
            "   macro avg       0.49      0.50      0.44       109\n",
            "weighted avg       0.53      0.60      0.52       109\n",
            "\n",
            "epoch - 87/150 train_loss - 0.434 acc - 0.651 roc - 0.590 prc_auc - 0.722 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17 38]\n",
            " [ 9 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.31      0.42        55\n",
            "         1.0       0.66      0.89      0.76        82\n",
            "\n",
            "    accuracy                           0.66       137\n",
            "   macro avg       0.66      0.60      0.59       137\n",
            "weighted avg       0.66      0.66      0.62       137\n",
            "\n",
            "epoch - 88/150 train_loss - 0.436 acc - 0.651 roc - 0.591 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 34]\n",
            " [ 1 59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.13      0.22        39\n",
            "         1.0       0.63      0.98      0.77        60\n",
            "\n",
            "    accuracy                           0.65        99\n",
            "   macro avg       0.73      0.56      0.50        99\n",
            "weighted avg       0.71      0.65      0.55        99\n",
            "\n",
            "epoch - 89/150 train_loss - 0.433 acc - 0.649 roc - 0.590 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 19]\n",
            " [ 5 46]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.17      0.25        23\n",
            "         1.0       0.71      0.90      0.79        51\n",
            "\n",
            "    accuracy                           0.68        74\n",
            "   macro avg       0.58      0.54      0.52        74\n",
            "weighted avg       0.63      0.68      0.62        74\n",
            "\n",
            "epoch - 90/150 train_loss - 0.429 acc - 0.650 roc - 0.589 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 26]\n",
            " [ 6 47]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.54      0.21      0.30        33\n",
            "         1.0       0.64      0.89      0.75        53\n",
            "\n",
            "    accuracy                           0.63        86\n",
            "   macro avg       0.59      0.55      0.53        86\n",
            "weighted avg       0.60      0.63      0.58        86\n",
            "\n",
            "epoch - 91/150 train_loss - 0.430 acc - 0.651 roc - 0.591 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 12]\n",
            " [ 6 47]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.14      0.18        14\n",
            "         1.0       0.80      0.89      0.84        53\n",
            "\n",
            "    accuracy                           0.73        67\n",
            "   macro avg       0.52      0.51      0.51        67\n",
            "weighted avg       0.68      0.73      0.70        67\n",
            "\n",
            "epoch - 92/150 train_loss - 0.428 acc - 0.653 roc - 0.591 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 23]\n",
            " [ 3 34]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.12      0.19        26\n",
            "         1.0       0.60      0.92      0.72        37\n",
            "\n",
            "    accuracy                           0.59        63\n",
            "   macro avg       0.55      0.52      0.46        63\n",
            "weighted avg       0.56      0.59      0.50        63\n",
            "\n",
            "epoch - 93/150 train_loss - 0.428 acc - 0.654 roc - 0.591 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 24]\n",
            " [ 8 72]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.08      0.11        26\n",
            "         1.0       0.75      0.90      0.82        80\n",
            "\n",
            "    accuracy                           0.70       106\n",
            "   macro avg       0.47      0.49      0.46       106\n",
            "weighted avg       0.62      0.70      0.64       106\n",
            "\n",
            "epoch - 94/150 train_loss - 0.431 acc - 0.653 roc - 0.593 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 30]\n",
            " [ 5 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.12      0.19        34\n",
            "         1.0       0.72      0.94      0.82        83\n",
            "\n",
            "    accuracy                           0.70       117\n",
            "   macro avg       0.58      0.53      0.50       117\n",
            "weighted avg       0.64      0.70      0.63       117\n",
            "\n",
            "epoch - 95/150 train_loss - 0.433 acc - 0.652 roc - 0.592 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 29]\n",
            " [ 6 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.15      0.22        34\n",
            "         1.0       0.63      0.89      0.74        56\n",
            "\n",
            "    accuracy                           0.61        90\n",
            "   macro avg       0.54      0.52      0.48        90\n",
            "weighted avg       0.57      0.61      0.54        90\n",
            "\n",
            "epoch - 96/150 train_loss - 0.431 acc - 0.649 roc - 0.592 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 29]\n",
            " [ 4 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.09      0.15        32\n",
            "         1.0       0.65      0.93      0.77        58\n",
            "\n",
            "    accuracy                           0.63        90\n",
            "   macro avg       0.54      0.51      0.46        90\n",
            "weighted avg       0.57      0.63      0.55        90\n",
            "\n",
            "epoch - 97/150 train_loss - 0.430 acc - 0.652 roc - 0.592 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 43]\n",
            " [ 4 59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.17      0.28        52\n",
            "         1.0       0.58      0.94      0.72        63\n",
            "\n",
            "    accuracy                           0.59       115\n",
            "   macro avg       0.64      0.55      0.50       115\n",
            "weighted avg       0.63      0.59      0.52       115\n",
            "\n",
            "epoch - 98/150 train_loss - 0.435 acc - 0.651 roc - 0.592 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 29]\n",
            " [ 4 58]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.17      0.27        35\n",
            "         1.0       0.67      0.94      0.78        62\n",
            "\n",
            "    accuracy                           0.66        97\n",
            "   macro avg       0.63      0.55      0.52        97\n",
            "weighted avg       0.64      0.66      0.59        97\n",
            "\n",
            "epoch - 99/150 train_loss - 0.431 acc - 0.655 roc - 0.592 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 29]\n",
            " [ 2 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.03      0.06        30\n",
            "         1.0       0.69      0.97      0.81        67\n",
            "\n",
            "    accuracy                           0.68        97\n",
            "   macro avg       0.51      0.50      0.43        97\n",
            "weighted avg       0.58      0.68      0.58        97\n",
            "\n",
            "epoch - 100/150 train_loss - 0.430 acc - 0.653 roc - 0.592 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 26]\n",
            " [ 6 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.07      0.11        28\n",
            "         1.0       0.74      0.93      0.82        80\n",
            "\n",
            "    accuracy                           0.70       108\n",
            "   macro avg       0.49      0.50      0.47       108\n",
            "weighted avg       0.61      0.70      0.64       108\n",
            "\n",
            "epoch - 101/150 train_loss - 0.432 acc - 0.648 roc - 0.592 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 27]\n",
            " [ 4 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.13      0.21        31\n",
            "         1.0       0.62      0.92      0.74        49\n",
            "\n",
            "    accuracy                           0.61        80\n",
            "   macro avg       0.56      0.52      0.47        80\n",
            "weighted avg       0.58      0.61      0.54        80\n",
            "\n",
            "epoch - 102/150 train_loss - 0.430 acc - 0.650 roc - 0.591 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 31]\n",
            " [ 6 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.11      0.18        35\n",
            "         1.0       0.67      0.91      0.78        70\n",
            "\n",
            "    accuracy                           0.65       105\n",
            "   macro avg       0.54      0.51      0.48       105\n",
            "weighted avg       0.58      0.65      0.58       105\n",
            "\n",
            "epoch - 103/150 train_loss - 0.432 acc - 0.652 roc - 0.592 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 27]\n",
            " [ 8 91]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.10      0.15        30\n",
            "         1.0       0.77      0.92      0.84        99\n",
            "\n",
            "    accuracy                           0.73       129\n",
            "   macro avg       0.52      0.51      0.49       129\n",
            "weighted avg       0.66      0.73      0.68       129\n",
            "\n",
            "epoch - 104/150 train_loss - 0.433 acc - 0.653 roc - 0.593 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 21]\n",
            " [ 8 88]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.05      0.06        22\n",
            "         1.0       0.81      0.92      0.86        96\n",
            "\n",
            "    accuracy                           0.75       118\n",
            "   macro avg       0.46      0.48      0.46       118\n",
            "weighted avg       0.68      0.75      0.71       118\n",
            "\n",
            "epoch - 105/150 train_loss - 0.431 acc - 0.652 roc - 0.593 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 39]\n",
            " [ 8 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.07      0.11        42\n",
            "         1.0       0.70      0.92      0.79        97\n",
            "\n",
            "    accuracy                           0.66       139\n",
            "   macro avg       0.48      0.49      0.45       139\n",
            "weighted avg       0.57      0.66      0.59       139\n",
            "\n",
            "epoch - 106/150 train_loss - 0.436 acc - 0.650 roc - 0.592 prc_auc - 0.724 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 22]\n",
            " [ 7 80]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.08      0.12        24\n",
            "         1.0       0.78      0.92      0.85        87\n",
            "\n",
            "    accuracy                           0.74       111\n",
            "   macro avg       0.50      0.50      0.48       111\n",
            "weighted avg       0.66      0.74      0.69       111\n",
            "\n",
            "epoch - 107/150 train_loss - 0.431 acc - 0.656 roc - 0.594 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 30]\n",
            " [ 5 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.17      0.26        36\n",
            "         1.0       0.71      0.94      0.81        78\n",
            "\n",
            "    accuracy                           0.69       114\n",
            "   macro avg       0.63      0.55      0.53       114\n",
            "weighted avg       0.66      0.69      0.63       114\n",
            "\n",
            "epoch - 108/150 train_loss - 0.432 acc - 0.654 roc - 0.594 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 23]\n",
            " [ 1 52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.28      0.43        32\n",
            "         1.0       0.69      0.98      0.81        53\n",
            "\n",
            "    accuracy                           0.72        85\n",
            "   macro avg       0.80      0.63      0.62        85\n",
            "weighted avg       0.77      0.72      0.67        85\n",
            "\n",
            "epoch - 109/150 train_loss - 0.429 acc - 0.652 roc - 0.593 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 54]\n",
            " [ 7 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.18      0.28        66\n",
            "         1.0       0.45      0.87      0.60        52\n",
            "\n",
            "    accuracy                           0.48       118\n",
            "   macro avg       0.54      0.52      0.44       118\n",
            "weighted avg       0.55      0.48      0.42       118\n",
            "\n",
            "epoch - 110/150 train_loss - 0.436 acc - 0.652 roc - 0.592 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 37]\n",
            " [ 8 70]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.14      0.21        43\n",
            "         1.0       0.65      0.90      0.76        78\n",
            "\n",
            "    accuracy                           0.63       121\n",
            "   macro avg       0.54      0.52      0.48       121\n",
            "weighted avg       0.57      0.63      0.56       121\n",
            "\n",
            "epoch - 111/150 train_loss - 0.434 acc - 0.653 roc - 0.594 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 23]\n",
            " [ 2 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.08      0.14        25\n",
            "         1.0       0.63      0.95      0.76        41\n",
            "\n",
            "    accuracy                           0.62        66\n",
            "   macro avg       0.56      0.52      0.45        66\n",
            "weighted avg       0.58      0.62      0.52        66\n",
            "\n",
            "epoch - 112/150 train_loss - 0.427 acc - 0.652 roc - 0.595 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 30]\n",
            " [ 2 67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.20        34\n",
            "         1.0       0.69      0.97      0.81        69\n",
            "\n",
            "    accuracy                           0.69       103\n",
            "   macro avg       0.68      0.54      0.50       103\n",
            "weighted avg       0.68      0.69      0.61       103\n",
            "\n",
            "epoch - 113/150 train_loss - 0.431 acc - 0.653 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 45]\n",
            " [ 6 67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.12      0.19        51\n",
            "         1.0       0.60      0.92      0.72        73\n",
            "\n",
            "    accuracy                           0.59       124\n",
            "   macro avg       0.55      0.52      0.46       124\n",
            "weighted avg       0.56      0.59      0.50       124\n",
            "\n",
            "epoch - 114/150 train_loss - 0.434 acc - 0.654 roc - 0.596 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 34]\n",
            " [ 2 56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.11      0.18        38\n",
            "         1.0       0.62      0.97      0.76        58\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.64      0.54      0.47        96\n",
            "weighted avg       0.64      0.62      0.53        96\n",
            "\n",
            "epoch - 115/150 train_loss - 0.431 acc - 0.654 roc - 0.594 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 31]\n",
            " [ 7 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.03      0.05        32\n",
            "         1.0       0.64      0.89      0.74        61\n",
            "\n",
            "    accuracy                           0.59        93\n",
            "   macro avg       0.38      0.46      0.39        93\n",
            "weighted avg       0.46      0.59      0.50        93\n",
            "\n",
            "epoch - 116/150 train_loss - 0.430 acc - 0.653 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 27]\n",
            " [ 3 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.13      0.21        31\n",
            "         1.0       0.64      0.94      0.77        52\n",
            "\n",
            "    accuracy                           0.64        83\n",
            "   macro avg       0.61      0.54      0.49        83\n",
            "weighted avg       0.62      0.64      0.56        83\n",
            "\n",
            "epoch - 117/150 train_loss - 0.429 acc - 0.653 roc - 0.594 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 37]\n",
            " [ 4 60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.05      0.09        39\n",
            "         1.0       0.62      0.94      0.75        64\n",
            "\n",
            "    accuracy                           0.60       103\n",
            "   macro avg       0.48      0.49      0.42       103\n",
            "weighted avg       0.51      0.60      0.50       103\n",
            "\n",
            "epoch - 118/150 train_loss - 0.431 acc - 0.654 roc - 0.596 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 30]\n",
            " [ 6 92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.14      0.22        35\n",
            "         1.0       0.75      0.94      0.84        98\n",
            "\n",
            "    accuracy                           0.73       133\n",
            "   macro avg       0.60      0.54      0.53       133\n",
            "weighted avg       0.68      0.73      0.67       133\n",
            "\n",
            "epoch - 119/150 train_loss - 0.433 acc - 0.651 roc - 0.596 prc_auc - 0.729 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 13]\n",
            " [ 2 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.07      0.12        14\n",
            "         1.0       0.79      0.96      0.87        52\n",
            "\n",
            "    accuracy                           0.77        66\n",
            "   macro avg       0.56      0.52      0.49        66\n",
            "weighted avg       0.70      0.77      0.71        66\n",
            "\n",
            "epoch - 120/150 train_loss - 0.426 acc - 0.655 roc - 0.595 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 27]\n",
            " [ 4 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.23      0.34        35\n",
            "         1.0       0.62      0.92      0.74        49\n",
            "\n",
            "    accuracy                           0.63        84\n",
            "   macro avg       0.65      0.57      0.54        84\n",
            "weighted avg       0.64      0.63      0.58        84\n",
            "\n",
            "epoch - 121/150 train_loss - 0.428 acc - 0.654 roc - 0.598 prc_auc - 0.730 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 23]\n",
            " [ 2 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.08      0.14        25\n",
            "         1.0       0.74      0.97      0.84        66\n",
            "\n",
            "    accuracy                           0.73        91\n",
            "   macro avg       0.62      0.52      0.49        91\n",
            "weighted avg       0.67      0.73      0.64        91\n",
            "\n",
            "epoch - 122/150 train_loss - 0.429 acc - 0.654 roc - 0.594 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 12]\n",
            " [ 8 72]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.20      0.23        15\n",
            "         1.0       0.86      0.90      0.88        80\n",
            "\n",
            "    accuracy                           0.79        95\n",
            "   macro avg       0.56      0.55      0.55        95\n",
            "weighted avg       0.76      0.79      0.78        95\n",
            "\n",
            "epoch - 123/150 train_loss - 0.428 acc - 0.655 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  7]\n",
            " [ 3 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         7\n",
            "         1.0       0.85      0.93      0.89        42\n",
            "\n",
            "    accuracy                           0.80        49\n",
            "   macro avg       0.42      0.46      0.44        49\n",
            "weighted avg       0.73      0.80      0.76        49\n",
            "\n",
            "epoch - 124/150 train_loss - 0.424 acc - 0.651 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 17]\n",
            " [ 1 47]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.11      0.18        19\n",
            "         1.0       0.73      0.98      0.84        48\n",
            "\n",
            "    accuracy                           0.73        67\n",
            "   macro avg       0.70      0.54      0.51        67\n",
            "weighted avg       0.72      0.73      0.65        67\n",
            "\n",
            "epoch - 125/150 train_loss - 0.426 acc - 0.657 roc - 0.596 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 17]\n",
            " [ 2 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.06      0.10        18\n",
            "         1.0       0.60      0.93      0.73        28\n",
            "\n",
            "    accuracy                           0.59        46\n",
            "   macro avg       0.47      0.49      0.41        46\n",
            "weighted avg       0.50      0.59      0.48        46\n",
            "\n",
            "epoch - 126/150 train_loss - 0.425 acc - 0.654 roc - 0.594 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 29]\n",
            " [ 4 88]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.12      0.20        33\n",
            "         1.0       0.75      0.96      0.84        92\n",
            "\n",
            "    accuracy                           0.74       125\n",
            "   macro avg       0.63      0.54      0.52       125\n",
            "weighted avg       0.69      0.74      0.67       125\n",
            "\n",
            "epoch - 127/150 train_loss - 0.432 acc - 0.655 roc - 0.594 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 26]\n",
            " [ 4 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.19      0.29        32\n",
            "         1.0       0.70      0.94      0.80        65\n",
            "\n",
            "    accuracy                           0.69        97\n",
            "   macro avg       0.65      0.56      0.54        97\n",
            "weighted avg       0.67      0.69      0.63        97\n",
            "\n",
            "epoch - 128/150 train_loss - 0.430 acc - 0.654 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 31]\n",
            " [ 9 66]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.14      0.20        36\n",
            "         1.0       0.68      0.88      0.77        75\n",
            "\n",
            "    accuracy                           0.64       111\n",
            "   macro avg       0.52      0.51      0.48       111\n",
            "weighted avg       0.58      0.64      0.58       111\n",
            "\n",
            "epoch - 129/150 train_loss - 0.432 acc - 0.654 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 31]\n",
            " [ 5 51]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.28      0.40        43\n",
            "         1.0       0.62      0.91      0.74        56\n",
            "\n",
            "    accuracy                           0.64        99\n",
            "   macro avg       0.66      0.59      0.57        99\n",
            "weighted avg       0.66      0.64      0.59        99\n",
            "\n",
            "epoch - 130/150 train_loss - 0.431 acc - 0.655 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 37]\n",
            " [ 5 77]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.10      0.16        41\n",
            "         1.0       0.68      0.94      0.79        82\n",
            "\n",
            "    accuracy                           0.66       123\n",
            "   macro avg       0.56      0.52      0.47       123\n",
            "weighted avg       0.60      0.66      0.58       123\n",
            "\n",
            "epoch - 131/150 train_loss - 0.434 acc - 0.657 roc - 0.594 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 39]\n",
            " [ 6 55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.07      0.12        42\n",
            "         1.0       0.59      0.90      0.71        61\n",
            "\n",
            "    accuracy                           0.56       103\n",
            "   macro avg       0.46      0.49      0.41       103\n",
            "weighted avg       0.48      0.56      0.47       103\n",
            "\n",
            "epoch - 132/150 train_loss - 0.432 acc - 0.652 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 26]\n",
            " [ 4 68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.07      0.12        28\n",
            "         1.0       0.72      0.94      0.82        72\n",
            "\n",
            "    accuracy                           0.70       100\n",
            "   macro avg       0.53      0.51      0.47       100\n",
            "weighted avg       0.61      0.70      0.62       100\n",
            "\n",
            "epoch - 133/150 train_loss - 0.430 acc - 0.655 roc - 0.596 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 30]\n",
            " [ 2 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.14      0.24        35\n",
            "         1.0       0.62      0.96      0.75        50\n",
            "\n",
            "    accuracy                           0.62        85\n",
            "   macro avg       0.66      0.55      0.49        85\n",
            "weighted avg       0.66      0.62      0.54        85\n",
            "\n",
            "epoch - 134/150 train_loss - 0.429 acc - 0.654 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 37]\n",
            " [ 7 52]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.05      0.08        39\n",
            "         1.0       0.58      0.88      0.70        59\n",
            "\n",
            "    accuracy                           0.55        98\n",
            "   macro avg       0.40      0.47      0.39        98\n",
            "weighted avg       0.44      0.55      0.46        98\n",
            "\n",
            "epoch - 135/150 train_loss - 0.431 acc - 0.653 roc - 0.596 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 33]\n",
            " [ 7 83]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.23      0.33        43\n",
            "         1.0       0.72      0.92      0.81        90\n",
            "\n",
            "    accuracy                           0.70       133\n",
            "   macro avg       0.65      0.58      0.57       133\n",
            "weighted avg       0.67      0.70      0.65       133\n",
            "\n",
            "epoch - 136/150 train_loss - 0.432 acc - 0.654 roc - 0.596 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 30]\n",
            " [ 2 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.20        34\n",
            "         1.0       0.62      0.96      0.76        52\n",
            "\n",
            "    accuracy                           0.63        86\n",
            "   macro avg       0.65      0.54      0.48        86\n",
            "weighted avg       0.64      0.63      0.54        86\n",
            "\n",
            "epoch - 137/150 train_loss - 0.429 acc - 0.654 roc - 0.594 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 12]\n",
            " [ 1 60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.14      0.24        14\n",
            "         1.0       0.83      0.98      0.90        61\n",
            "\n",
            "    accuracy                           0.83        75\n",
            "   macro avg       0.75      0.56      0.57        75\n",
            "weighted avg       0.80      0.83      0.78        75\n",
            "\n",
            "epoch - 138/150 train_loss - 0.426 acc - 0.653 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 24]\n",
            " [ 6 62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.11      0.17        27\n",
            "         1.0       0.72      0.91      0.81        68\n",
            "\n",
            "    accuracy                           0.68        95\n",
            "   macro avg       0.53      0.51      0.49        95\n",
            "weighted avg       0.61      0.68      0.62        95\n",
            "\n",
            "epoch - 139/150 train_loss - 0.430 acc - 0.654 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 20]\n",
            " [ 3 39]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        20\n",
            "         1.0       0.66      0.93      0.77        42\n",
            "\n",
            "    accuracy                           0.63        62\n",
            "   macro avg       0.33      0.46      0.39        62\n",
            "weighted avg       0.45      0.63      0.52        62\n",
            "\n",
            "epoch - 140/150 train_loss - 0.426 acc - 0.654 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 25]\n",
            " [ 4 55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.14      0.22        29\n",
            "         1.0       0.69      0.93      0.79        59\n",
            "\n",
            "    accuracy                           0.67        88\n",
            "   macro avg       0.59      0.54      0.50        88\n",
            "weighted avg       0.63      0.67      0.60        88\n",
            "\n",
            "epoch - 141/150 train_loss - 0.429 acc - 0.654 roc - 0.596 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 14]\n",
            " [ 5 60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.30      0.39        20\n",
            "         1.0       0.81      0.92      0.86        65\n",
            "\n",
            "    accuracy                           0.78        85\n",
            "   macro avg       0.68      0.61      0.63        85\n",
            "weighted avg       0.75      0.78      0.75        85\n",
            "\n",
            "epoch - 142/150 train_loss - 0.427 acc - 0.654 roc - 0.596 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 23]\n",
            " [ 3 68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.18      0.28        28\n",
            "         1.0       0.75      0.96      0.84        71\n",
            "\n",
            "    accuracy                           0.74        99\n",
            "   macro avg       0.69      0.57      0.56        99\n",
            "weighted avg       0.71      0.74      0.68        99\n",
            "\n",
            "epoch - 143/150 train_loss - 0.430 acc - 0.652 roc - 0.595 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 40]\n",
            " [ 5 77]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      0.15      0.24        47\n",
            "         1.0       0.66      0.94      0.77        82\n",
            "\n",
            "    accuracy                           0.65       129\n",
            "   macro avg       0.62      0.54      0.51       129\n",
            "weighted avg       0.63      0.65      0.58       129\n",
            "\n",
            "epoch - 144/150 train_loss - 0.433 acc - 0.653 roc - 0.598 prc_auc - 0.729 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 30]\n",
            " [ 3 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.12      0.20        34\n",
            "         1.0       0.70      0.96      0.81        74\n",
            "\n",
            "    accuracy                           0.69       108\n",
            "   macro avg       0.64      0.54      0.50       108\n",
            "weighted avg       0.66      0.69      0.62       108\n",
            "\n",
            "epoch - 145/150 train_loss - 0.431 acc - 0.653 roc - 0.597 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 23]\n",
            " [ 2 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.12      0.19        26\n",
            "         1.0       0.71      0.97      0.82        59\n",
            "\n",
            "    accuracy                           0.71        85\n",
            "   macro avg       0.66      0.54      0.51        85\n",
            "weighted avg       0.68      0.71      0.63        85\n",
            "\n",
            "epoch - 146/150 train_loss - 0.429 acc - 0.653 roc - 0.593 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 32]\n",
            " [ 4 75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.14      0.22        37\n",
            "         1.0       0.70      0.95      0.81        79\n",
            "\n",
            "    accuracy                           0.69       116\n",
            "   macro avg       0.63      0.54      0.51       116\n",
            "weighted avg       0.65      0.69      0.62       116\n",
            "\n",
            "epoch - 147/150 train_loss - 0.431 acc - 0.656 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 46]\n",
            " [ 1 84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.06      0.11        49\n",
            "         1.0       0.65      0.99      0.78        85\n",
            "\n",
            "    accuracy                           0.65       134\n",
            "   macro avg       0.70      0.52      0.45       134\n",
            "weighted avg       0.68      0.65      0.54       134\n",
            "\n",
            "epoch - 148/150 train_loss - 0.435 acc - 0.651 roc - 0.594 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 20]\n",
            " [ 6 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.38      0.48        32\n",
            "         1.0       0.76      0.91      0.83        70\n",
            "\n",
            "    accuracy                           0.75       102\n",
            "   macro avg       0.71      0.64      0.66       102\n",
            "weighted avg       0.73      0.75      0.72       102\n",
            "\n",
            "epoch - 149/150 train_loss - 0.429 acc - 0.655 roc - 0.596 prc_auc - 0.727 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 19/19 [00:01<00:00, 11.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 35]\n",
            " [ 4 56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.10      0.17        39\n",
            "         1.0       0.62      0.93      0.74        60\n",
            "\n",
            "    accuracy                           0.61        99\n",
            "   macro avg       0.56      0.52      0.46        99\n",
            "weighted avg       0.57      0.61      0.52        99\n",
            "\n",
            "epoch - 150/150 train_loss - 0.430 acc - 0.653 roc - 0.595 prc_auc - 0.728 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahwm9A6I-0NP"
      },
      "source": [
        "#Test function \n",
        "import psutil\n",
        "def test_epoch(model, test_iterator, criterion, device=\"cpu\"):\n",
        "  model.load_state_dict(torch.load(\"sakt_task2.pt\"))\n",
        "  model.eval()\n",
        "  #print(\"inside test_epoch !!\") \n",
        "  test_loss = []\n",
        "  num_corrects = 0\n",
        "  num_total = 0\n",
        "  labels = []\n",
        "  outs = []\n",
        "  preds = []\n",
        "\n",
        "  prev_test_df = None\n",
        "  tbar = tqdm(test_iterator)\n",
        "  for item in tbar:\n",
        "          x = item[0].to(device).long()\n",
        "          target_id = item[1].to(device).long()\n",
        "          label = item[2].to(device).float()\n",
        "          target_mask = (target_id != 0)\n",
        "\n",
        "          with torch.no_grad():\n",
        "            output, att_weight = model(x, target_id)\n",
        "          \n",
        "          \n",
        "          output = torch.masked_select(output, target_mask)\n",
        "          label = torch.masked_select(label, target_mask)\n",
        "\n",
        "          loss = criterion(output, label)\n",
        "          test_loss.append(loss.item())\n",
        "\n",
        "          pred = (torch.sigmoid(output) >= 0.5).long()\n",
        "          num_corrects += (pred == label).sum().item()\n",
        "          num_total += len(label)\n",
        "          print('num_cor:', num_corrects)\n",
        "          print(\"tot:\",num_total)\n",
        "\n",
        "          labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
        "          outs.extend(output.view(-1).data.cpu().numpy())\n",
        "          preds.extend(pred.squeeze(-1).data.cpu().numpy())\n",
        "\n",
        "  \n",
        "  acc = num_corrects / num_total\n",
        "  roc = roc_auc_score(labels, outs)\n",
        "  precision, recall, _ = precision_recall_curve(labels,outs)\n",
        "  auc_score = auc(recall, precision)\n",
        "  loss = np.average(test_loss)\n",
        "  \n",
        "  print(metrics.confusion_matrix(label,pred))\n",
        "  print(metrics.classification_report(label,pred))\n",
        "\n",
        "  return loss, acc, roc, auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXNFOHNZ-0NQ"
      },
      "source": [
        "#make test epoch =1 \n",
        "epoch_test = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KydKkbpR-0NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cdd646-8950-4c1f-8080-b1f7bfe5f8f2"
      },
      "source": [
        "#Test on 5049\n",
        "for epoch in range(epoch_test):\n",
        "  test_loss_1, test_acc_1, test_roc_1, prc_auc_1 = test_epoch(model, test_dataloader_1, criterion, device)\n",
        "  print(\"Testing on 5049!!!\")\n",
        "  print(\"epoch - {}/{} test - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f}\".format(epoch+1,epoch_test, test_loss_1, test_acc_1, test_roc_1, prc_auc_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cor: 294\n",
            "tot: 490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 27 169]\n",
            " [ 27 267]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.14      0.22       196\n",
            "         1.0       0.61      0.91      0.73       294\n",
            "\n",
            "    accuracy                           0.60       490\n",
            "   macro avg       0.56      0.52      0.47       490\n",
            "weighted avg       0.57      0.60      0.53       490\n",
            "\n",
            "Testing on 5049!!!\n",
            "epoch - 1/1 test - 0.709 acc - 0.600 roc - 0.502 prc_auc - 0.596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35fevWFO-0NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a924b4ca-0211-4855-d3ad-454aa6b86039"
      },
      "source": [
        "#Test on 5117\n",
        "for epoch in range(epoch_test):\n",
        "  test_loss_3, test_acc_3, test_roc_3, prc_auc_3 = test_epoch(model, test_dataloader_3, criterion, device)\n",
        "  print(\"Testing on 5117!!!!\")\n",
        "  print(\"epoch - {}/{} test - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f}\".format(epoch+1,epoch_test, test_loss_3, test_acc_3, test_roc_3, prc_auc_3))\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            " 33%|███▎      | 1/3 [00:00<00:01,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cor: 294\n",
            "tot: 501\n",
            "num_cor: 479\n",
            "tot: 863\n",
            "num_cor: 539\n",
            "tot: 974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 3/3 [00:00<00:00,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 37]\n",
            " [14 55]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.12      0.16        42\n",
            "         1.0       0.60      0.80      0.68        69\n",
            "\n",
            "    accuracy                           0.54       111\n",
            "   macro avg       0.43      0.46      0.42       111\n",
            "weighted avg       0.47      0.54      0.49       111\n",
            "\n",
            "Testing on 5117!!!!\n",
            "epoch - 1/1 test - 0.735 acc - 0.553 roc - 0.505 prc_auc - 0.567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Z8N1aI0hR0"
      },
      "source": [
        "#Load the model weights and test on task2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDfisR010hR7",
        "outputId": "f8a668fb-b946-43d5-ce5c-02580597e397"
      },
      "source": [
        "#Call the SAKT model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SAKTModel(n_questions, embed_dim = 128)  #The dimension of embeddings d is 128.\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.99, weight_decay=0.01)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "scheduler_1 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_1), epochs=epochs\n",
        ")\n",
        "\n",
        "scheduler_2 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_2), epochs=epochs\n",
        ")\n",
        "\n",
        "#scheduler_12 = torch.optim.lr_scheduler.OneCycleLR(\n",
        "#    optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_dataloader_12), epochs=epochs\n",
        "#)\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuscryF90hR7",
        "outputId": "307b9d62-fdce-4120-dcf1-cfe15132a349"
      },
      "source": [
        "#Function call for Train on 1998\n",
        "best_auc = 0\n",
        "max_steps = 50\n",
        "step = 0\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc, roc, prc_auc = train_epoch(model, train_dataloader_2, optimizer, scheduler_2, criterion, device)\n",
        "  print(\"epoch - {}/{} train_loss - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f} \".format(epoch+1, epochs, train_loss, train_acc, roc, prc_auc))\n",
        "  \n",
        "  if roc > best_auc:\n",
        "    best_auc = roc\n",
        "    step = 0\n",
        "    torch.save(model.state_dict(), \"sakt_task2.pt\")\n",
        "  else:\n",
        "    step += 1\n",
        "    if step >= max_steps:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[33 29]\n",
            " [55 44]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.53      0.44        62\n",
            "         1.0       0.60      0.44      0.51        99\n",
            "\n",
            "    accuracy                           0.48       161\n",
            "   macro avg       0.49      0.49      0.48       161\n",
            "weighted avg       0.52      0.48      0.48       161\n",
            "\n",
            "epoch - 1/150 train_loss - 0.650 acc - 0.509 roc - 0.509 prc_auc - 0.703 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 23]\n",
            " [52 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.45      0.34        42\n",
            "         1.0       0.70      0.51      0.59       106\n",
            "\n",
            "    accuracy                           0.49       148\n",
            "   macro avg       0.48      0.48      0.46       148\n",
            "weighted avg       0.58      0.49      0.52       148\n",
            "\n",
            "epoch - 2/150 train_loss - 0.637 acc - 0.506 roc - 0.506 prc_auc - 0.703 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[23 27]\n",
            " [51 45]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.46      0.37        50\n",
            "         1.0       0.62      0.47      0.54        96\n",
            "\n",
            "    accuracy                           0.47       146\n",
            "   macro avg       0.47      0.46      0.45       146\n",
            "weighted avg       0.52      0.47      0.48       146\n",
            "\n",
            "epoch - 3/150 train_loss - 0.618 acc - 0.500 roc - 0.509 prc_auc - 0.704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[24 23]\n",
            " [37 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.39      0.51      0.44        47\n",
            "         1.0       0.68      0.57      0.62        86\n",
            "\n",
            "    accuracy                           0.55       133\n",
            "   macro avg       0.54      0.54      0.53       133\n",
            "weighted avg       0.58      0.55      0.56       133\n",
            "\n",
            "epoch - 4/150 train_loss - 0.599 acc - 0.507 roc - 0.507 prc_auc - 0.702 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 19]\n",
            " [50 63]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.28      0.50      0.36        38\n",
            "         1.0       0.77      0.56      0.65       113\n",
            "\n",
            "    accuracy                           0.54       151\n",
            "   macro avg       0.52      0.53      0.50       151\n",
            "weighted avg       0.64      0.54      0.57       151\n",
            "\n",
            "epoch - 5/150 train_loss - 0.585 acc - 0.498 roc - 0.504 prc_auc - 0.703 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30 15]\n",
            " [57 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.34      0.67      0.45        45\n",
            "         1.0       0.77      0.46      0.58       106\n",
            "\n",
            "    accuracy                           0.52       151\n",
            "   macro avg       0.56      0.56      0.52       151\n",
            "weighted avg       0.64      0.52      0.54       151\n",
            "\n",
            "epoch - 6/150 train_loss - 0.574 acc - 0.496 roc - 0.501 prc_auc - 0.698 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 20]\n",
            " [39 42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.49      0.39        39\n",
            "         1.0       0.68      0.52      0.59        81\n",
            "\n",
            "    accuracy                           0.51       120\n",
            "   macro avg       0.50      0.50      0.49       120\n",
            "weighted avg       0.56      0.51      0.52       120\n",
            "\n",
            "epoch - 7/150 train_loss - 0.559 acc - 0.504 roc - 0.501 prc_auc - 0.698 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[21 20]\n",
            " [50 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.30      0.51      0.38        41\n",
            "         1.0       0.73      0.52      0.61       104\n",
            "\n",
            "    accuracy                           0.52       145\n",
            "   macro avg       0.51      0.52      0.49       145\n",
            "weighted avg       0.61      0.52      0.54       145\n",
            "\n",
            "epoch - 8/150 train_loss - 0.552 acc - 0.513 roc - 0.503 prc_auc - 0.699 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15 25]\n",
            " [42 62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.38      0.31        40\n",
            "         1.0       0.71      0.60      0.65       104\n",
            "\n",
            "    accuracy                           0.53       144\n",
            "   macro avg       0.49      0.49      0.48       144\n",
            "weighted avg       0.59      0.53      0.55       144\n",
            "\n",
            "epoch - 9/150 train_loss - 0.543 acc - 0.523 roc - 0.501 prc_auc - 0.700 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 26]\n",
            " [42 69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.32      0.26        38\n",
            "         1.0       0.73      0.62      0.67       111\n",
            "\n",
            "    accuracy                           0.54       149\n",
            "   macro avg       0.47      0.47      0.47       149\n",
            "weighted avg       0.60      0.54      0.57       149\n",
            "\n",
            "epoch - 10/150 train_loss - 0.532 acc - 0.540 roc - 0.508 prc_auc - 0.704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 16]\n",
            " [25 56]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.41      0.35        27\n",
            "         1.0       0.78      0.69      0.73        81\n",
            "\n",
            "    accuracy                           0.62       108\n",
            "   macro avg       0.54      0.55      0.54       108\n",
            "weighted avg       0.66      0.62      0.64       108\n",
            "\n",
            "epoch - 11/150 train_loss - 0.520 acc - 0.559 roc - 0.507 prc_auc - 0.704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 16]\n",
            " [32 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.27      0.20        22\n",
            "         1.0       0.82      0.70      0.75       105\n",
            "\n",
            "    accuracy                           0.62       127\n",
            "   macro avg       0.49      0.48      0.48       127\n",
            "weighted avg       0.71      0.62      0.66       127\n",
            "\n",
            "epoch - 12/150 train_loss - 0.512 acc - 0.579 roc - 0.510 prc_auc - 0.704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 21]\n",
            " [12 50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.48      0.34      0.40        32\n",
            "         1.0       0.70      0.81      0.75        62\n",
            "\n",
            "    accuracy                           0.65        94\n",
            "   macro avg       0.59      0.58      0.58        94\n",
            "weighted avg       0.63      0.65      0.63        94\n",
            "\n",
            "epoch - 13/150 train_loss - 0.503 acc - 0.595 roc - 0.511 prc_auc - 0.706 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 20]\n",
            " [25 80]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.31      0.29        29\n",
            "         1.0       0.80      0.76      0.78       105\n",
            "\n",
            "    accuracy                           0.66       134\n",
            "   macro avg       0.53      0.54      0.53       134\n",
            "weighted avg       0.68      0.66      0.67       134\n",
            "\n",
            "epoch - 14/150 train_loss - 0.498 acc - 0.605 roc - 0.512 prc_auc - 0.708 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13 22]\n",
            " [17 60]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.37      0.40        35\n",
            "         1.0       0.73      0.78      0.75        77\n",
            "\n",
            "    accuracy                           0.65       112\n",
            "   macro avg       0.58      0.58      0.58       112\n",
            "weighted avg       0.64      0.65      0.64       112\n",
            "\n",
            "epoch - 15/150 train_loss - 0.491 acc - 0.625 roc - 0.516 prc_auc - 0.708 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 34]\n",
            " [13 88]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.41      0.21      0.28        43\n",
            "         1.0       0.72      0.87      0.79       101\n",
            "\n",
            "    accuracy                           0.67       144\n",
            "   macro avg       0.57      0.54      0.53       144\n",
            "weighted avg       0.63      0.67      0.64       144\n",
            "\n",
            "epoch - 16/150 train_loss - 0.489 acc - 0.633 roc - 0.516 prc_auc - 0.708 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 18]\n",
            " [ 5 54]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.18      0.26        22\n",
            "         1.0       0.75      0.92      0.82        59\n",
            "\n",
            "    accuracy                           0.72        81\n",
            "   macro avg       0.60      0.55      0.54        81\n",
            "weighted avg       0.67      0.72      0.67        81\n",
            "\n",
            "epoch - 17/150 train_loss - 0.479 acc - 0.636 roc - 0.517 prc_auc - 0.710 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13 24]\n",
            " [19 75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.41      0.35      0.38        37\n",
            "         1.0       0.76      0.80      0.78        94\n",
            "\n",
            "    accuracy                           0.67       131\n",
            "   macro avg       0.58      0.57      0.58       131\n",
            "weighted avg       0.66      0.67      0.66       131\n",
            "\n",
            "epoch - 18/150 train_loss - 0.481 acc - 0.650 roc - 0.518 prc_auc - 0.710 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 27]\n",
            " [ 4 75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.07      0.11        29\n",
            "         1.0       0.74      0.95      0.83        79\n",
            "\n",
            "    accuracy                           0.71       108\n",
            "   macro avg       0.53      0.51      0.47       108\n",
            "weighted avg       0.63      0.71      0.64       108\n",
            "\n",
            "epoch - 19/150 train_loss - 0.476 acc - 0.651 roc - 0.519 prc_auc - 0.712 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 24]\n",
            " [17 90]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.20      0.23        30\n",
            "         1.0       0.79      0.84      0.81       107\n",
            "\n",
            "    accuracy                           0.70       137\n",
            "   macro avg       0.53      0.52      0.52       137\n",
            "weighted avg       0.67      0.70      0.69       137\n",
            "\n",
            "epoch - 20/150 train_loss - 0.474 acc - 0.654 roc - 0.522 prc_auc - 0.714 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 41]\n",
            " [13 75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.35      0.15      0.21        48\n",
            "         1.0       0.65      0.85      0.74        88\n",
            "\n",
            "    accuracy                           0.60       136\n",
            "   macro avg       0.50      0.50      0.47       136\n",
            "weighted avg       0.54      0.60      0.55       136\n",
            "\n",
            "epoch - 21/150 train_loss - 0.474 acc - 0.660 roc - 0.524 prc_auc - 0.715 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  7  39]\n",
            " [ 14 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.15      0.21        46\n",
            "         1.0       0.73      0.88      0.80       119\n",
            "\n",
            "    accuracy                           0.68       165\n",
            "   macro avg       0.53      0.52      0.50       165\n",
            "weighted avg       0.62      0.68      0.63       165\n",
            "\n",
            "epoch - 22/150 train_loss - 0.473 acc - 0.663 roc - 0.529 prc_auc - 0.718 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 43]\n",
            " [ 4 67]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.12      0.20        49\n",
            "         1.0       0.61      0.94      0.74        71\n",
            "\n",
            "    accuracy                           0.61       120\n",
            "   macro avg       0.60      0.53      0.47       120\n",
            "weighted avg       0.61      0.61      0.52       120\n",
            "\n",
            "epoch - 23/150 train_loss - 0.470 acc - 0.666 roc - 0.526 prc_auc - 0.716 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 36]\n",
            " [10 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.14      0.21        42\n",
            "         1.0       0.71      0.90      0.79        99\n",
            "\n",
            "    accuracy                           0.67       141\n",
            "   macro avg       0.54      0.52      0.50       141\n",
            "weighted avg       0.61      0.67      0.62       141\n",
            "\n",
            "epoch - 24/150 train_loss - 0.468 acc - 0.667 roc - 0.531 prc_auc - 0.717 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13 44]\n",
            " [12 87]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.52      0.23      0.32        57\n",
            "         1.0       0.66      0.88      0.76        99\n",
            "\n",
            "    accuracy                           0.64       156\n",
            "   macro avg       0.59      0.55      0.54       156\n",
            "weighted avg       0.61      0.64      0.60       156\n",
            "\n",
            "epoch - 25/150 train_loss - 0.469 acc - 0.670 roc - 0.530 prc_auc - 0.719 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 38]\n",
            " [ 6 42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.05      0.08        40\n",
            "         1.0       0.53      0.88      0.66        48\n",
            "\n",
            "    accuracy                           0.50        88\n",
            "   macro avg       0.39      0.46      0.37        88\n",
            "weighted avg       0.40      0.50      0.40        88\n",
            "\n",
            "epoch - 26/150 train_loss - 0.462 acc - 0.671 roc - 0.534 prc_auc - 0.721 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 28]\n",
            " [ 4 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.15      0.24        33\n",
            "         1.0       0.67      0.93      0.78        61\n",
            "\n",
            "    accuracy                           0.66        94\n",
            "   macro avg       0.61      0.54      0.51        94\n",
            "weighted avg       0.63      0.66      0.59        94\n",
            "\n",
            "epoch - 27/150 train_loss - 0.459 acc - 0.674 roc - 0.535 prc_auc - 0.721 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2  31]\n",
            " [  6 106]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.06      0.10        33\n",
            "         1.0       0.77      0.95      0.85       112\n",
            "\n",
            "    accuracy                           0.74       145\n",
            "   macro avg       0.51      0.50      0.47       145\n",
            "weighted avg       0.65      0.74      0.68       145\n",
            "\n",
            "epoch - 28/150 train_loss - 0.461 acc - 0.675 roc - 0.535 prc_auc - 0.720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 29]\n",
            " [ 4 57]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.12      0.20        33\n",
            "         1.0       0.66      0.93      0.78        61\n",
            "\n",
            "    accuracy                           0.65        94\n",
            "   macro avg       0.58      0.53      0.49        94\n",
            "weighted avg       0.61      0.65      0.57        94\n",
            "\n",
            "epoch - 29/150 train_loss - 0.457 acc - 0.675 roc - 0.542 prc_auc - 0.723 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 35]\n",
            " [ 6 85]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.19      0.28        43\n",
            "         1.0       0.71      0.93      0.81        91\n",
            "\n",
            "    accuracy                           0.69       134\n",
            "   macro avg       0.64      0.56      0.54       134\n",
            "weighted avg       0.66      0.69      0.64       134\n",
            "\n",
            "epoch - 30/150 train_loss - 0.460 acc - 0.679 roc - 0.541 prc_auc - 0.721 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 33]\n",
            " [ 6 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.45      0.13      0.20        38\n",
            "         1.0       0.73      0.94      0.82        95\n",
            "\n",
            "    accuracy                           0.71       133\n",
            "   macro avg       0.59      0.53      0.51       133\n",
            "weighted avg       0.65      0.71      0.64       133\n",
            "\n",
            "epoch - 31/150 train_loss - 0.458 acc - 0.679 roc - 0.544 prc_auc - 0.725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 36]\n",
            " [ 2 68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.08      0.14        39\n",
            "         1.0       0.65      0.97      0.78        70\n",
            "\n",
            "    accuracy                           0.65       109\n",
            "   macro avg       0.63      0.52      0.46       109\n",
            "weighted avg       0.63      0.65      0.55       109\n",
            "\n",
            "epoch - 32/150 train_loss - 0.455 acc - 0.678 roc - 0.546 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 21]\n",
            " [ 7 85]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.16      0.22        25\n",
            "         1.0       0.80      0.92      0.86        92\n",
            "\n",
            "    accuracy                           0.76       117\n",
            "   macro avg       0.58      0.54      0.54       117\n",
            "weighted avg       0.71      0.76      0.72       117\n",
            "\n",
            "epoch - 33/150 train_loss - 0.453 acc - 0.681 roc - 0.547 prc_auc - 0.726 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 47]\n",
            " [ 3 97]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.06      0.11        50\n",
            "         1.0       0.67      0.97      0.80       100\n",
            "\n",
            "    accuracy                           0.67       150\n",
            "   macro avg       0.59      0.52      0.45       150\n",
            "weighted avg       0.62      0.67      0.57       150\n",
            "\n",
            "epoch - 34/150 train_loss - 0.458 acc - 0.681 roc - 0.547 prc_auc - 0.729 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 35]\n",
            " [ 6 96]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        35\n",
            "         1.0       0.73      0.94      0.82       102\n",
            "\n",
            "    accuracy                           0.70       137\n",
            "   macro avg       0.37      0.47      0.41       137\n",
            "weighted avg       0.55      0.70      0.61       137\n",
            "\n",
            "epoch - 35/150 train_loss - 0.455 acc - 0.684 roc - 0.550 prc_auc - 0.729 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15 55]\n",
            " [ 9 91]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.21      0.32        70\n",
            "         1.0       0.62      0.91      0.74       100\n",
            "\n",
            "    accuracy                           0.62       170\n",
            "   macro avg       0.62      0.56      0.53       170\n",
            "weighted avg       0.62      0.62      0.57       170\n",
            "\n",
            "epoch - 36/150 train_loss - 0.461 acc - 0.683 roc - 0.552 prc_auc - 0.730 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 26]\n",
            " [ 3 59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.04      0.06        27\n",
            "         1.0       0.69      0.95      0.80        62\n",
            "\n",
            "    accuracy                           0.67        89\n",
            "   macro avg       0.47      0.49      0.43        89\n",
            "weighted avg       0.56      0.67      0.58        89\n",
            "\n",
            "epoch - 37/150 train_loss - 0.448 acc - 0.685 roc - 0.556 prc_auc - 0.732 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 42]\n",
            " [11 75]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.39      0.14      0.21        49\n",
            "         1.0       0.64      0.87      0.74        86\n",
            "\n",
            "    accuracy                           0.61       135\n",
            "   macro avg       0.51      0.51      0.47       135\n",
            "weighted avg       0.55      0.61      0.55       135\n",
            "\n",
            "epoch - 38/150 train_loss - 0.454 acc - 0.684 roc - 0.557 prc_auc - 0.733 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6  39]\n",
            " [ 12 113]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.13      0.19        45\n",
            "         1.0       0.74      0.90      0.82       125\n",
            "\n",
            "    accuracy                           0.70       170\n",
            "   macro avg       0.54      0.52      0.50       170\n",
            "weighted avg       0.63      0.70      0.65       170\n",
            "\n",
            "epoch - 39/150 train_loss - 0.456 acc - 0.683 roc - 0.559 prc_auc - 0.734 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  7  42]\n",
            " [  8 117]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.47      0.14      0.22        49\n",
            "         1.0       0.74      0.94      0.82       125\n",
            "\n",
            "    accuracy                           0.71       174\n",
            "   macro avg       0.60      0.54      0.52       174\n",
            "weighted avg       0.66      0.71      0.65       174\n",
            "\n",
            "epoch - 40/150 train_loss - 0.454 acc - 0.685 roc - 0.561 prc_auc - 0.734 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 11  37]\n",
            " [  7 106]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.23      0.33        48\n",
            "         1.0       0.74      0.94      0.83       113\n",
            "\n",
            "    accuracy                           0.73       161\n",
            "   macro avg       0.68      0.58      0.58       161\n",
            "weighted avg       0.70      0.73      0.68       161\n",
            "\n",
            "epoch - 41/150 train_loss - 0.453 acc - 0.690 roc - 0.561 prc_auc - 0.735 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 26]\n",
            " [ 4 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.19      0.29        32\n",
            "         1.0       0.71      0.94      0.81        69\n",
            "\n",
            "    accuracy                           0.70       101\n",
            "   macro avg       0.66      0.56      0.55       101\n",
            "weighted avg       0.68      0.70      0.65       101\n",
            "\n",
            "epoch - 42/150 train_loss - 0.445 acc - 0.689 roc - 0.566 prc_auc - 0.738 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 45]\n",
            " [ 4 95]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.10      0.17        50\n",
            "         1.0       0.68      0.96      0.79        99\n",
            "\n",
            "    accuracy                           0.67       149\n",
            "   macro avg       0.62      0.53      0.48       149\n",
            "weighted avg       0.64      0.67      0.59       149\n",
            "\n",
            "epoch - 43/150 train_loss - 0.452 acc - 0.689 roc - 0.564 prc_auc - 0.735 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 20]\n",
            " [ 6 95]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.09      0.13        22\n",
            "         1.0       0.83      0.94      0.88       101\n",
            "\n",
            "    accuracy                           0.79       123\n",
            "   macro avg       0.54      0.52      0.51       123\n",
            "weighted avg       0.72      0.79      0.75       123\n",
            "\n",
            "epoch - 44/150 train_loss - 0.446 acc - 0.693 roc - 0.564 prc_auc - 0.737 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 15]\n",
            " [ 1 43]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        15\n",
            "         1.0       0.74      0.98      0.84        44\n",
            "\n",
            "    accuracy                           0.73        59\n",
            "   macro avg       0.37      0.49      0.42        59\n",
            "weighted avg       0.55      0.73      0.63        59\n",
            "\n",
            "epoch - 45/150 train_loss - 0.440 acc - 0.691 roc - 0.567 prc_auc - 0.737 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 33]\n",
            " [ 5 70]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.06      0.10        35\n",
            "         1.0       0.68      0.93      0.79        75\n",
            "\n",
            "    accuracy                           0.65       110\n",
            "   macro avg       0.48      0.50      0.44       110\n",
            "weighted avg       0.55      0.65      0.57       110\n",
            "\n",
            "epoch - 46/150 train_loss - 0.444 acc - 0.687 roc - 0.571 prc_auc - 0.740 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 32]\n",
            " [ 6 96]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.20      0.30        40\n",
            "         1.0       0.75      0.94      0.83       102\n",
            "\n",
            "    accuracy                           0.73       142\n",
            "   macro avg       0.66      0.57      0.57       142\n",
            "weighted avg       0.70      0.73      0.68       142\n",
            "\n",
            "epoch - 47/150 train_loss - 0.446 acc - 0.692 roc - 0.571 prc_auc - 0.740 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0  28]\n",
            " [  5 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        28\n",
            "         1.0       0.78      0.95      0.86       106\n",
            "\n",
            "    accuracy                           0.75       134\n",
            "   macro avg       0.39      0.48      0.43       134\n",
            "weighted avg       0.62      0.75      0.68       134\n",
            "\n",
            "epoch - 48/150 train_loss - 0.444 acc - 0.692 roc - 0.575 prc_auc - 0.743 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 42]\n",
            " [ 9 77]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.47      0.16      0.24        50\n",
            "         1.0       0.65      0.90      0.75        86\n",
            "\n",
            "    accuracy                           0.62       136\n",
            "   macro avg       0.56      0.53      0.50       136\n",
            "weighted avg       0.58      0.62      0.56       136\n",
            "\n",
            "epoch - 49/150 train_loss - 0.446 acc - 0.691 roc - 0.577 prc_auc - 0.744 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 29]\n",
            " [ 8 97]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.15      0.21        34\n",
            "         1.0       0.77      0.92      0.84       105\n",
            "\n",
            "    accuracy                           0.73       139\n",
            "   macro avg       0.58      0.54      0.53       139\n",
            "weighted avg       0.68      0.73      0.69       139\n",
            "\n",
            "epoch - 50/150 train_loss - 0.444 acc - 0.690 roc - 0.577 prc_auc - 0.744 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 27]\n",
            " [10 93]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.09      0.04      0.05        28\n",
            "         1.0       0.78      0.90      0.83       103\n",
            "\n",
            "    accuracy                           0.72       131\n",
            "   macro avg       0.43      0.47      0.44       131\n",
            "weighted avg       0.63      0.72      0.67       131\n",
            "\n",
            "epoch - 51/150 train_loss - 0.443 acc - 0.691 roc - 0.579 prc_auc - 0.745 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 16]\n",
            " [ 7 68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.30      0.16      0.21        19\n",
            "         1.0       0.81      0.91      0.86        75\n",
            "\n",
            "    accuracy                           0.76        94\n",
            "   macro avg       0.55      0.53      0.53        94\n",
            "weighted avg       0.71      0.76      0.72        94\n",
            "\n",
            "epoch - 52/150 train_loss - 0.438 acc - 0.691 roc - 0.581 prc_auc - 0.747 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 40]\n",
            " [10 79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.13      0.19        46\n",
            "         1.0       0.66      0.89      0.76        89\n",
            "\n",
            "    accuracy                           0.63       135\n",
            "   macro avg       0.52      0.51      0.48       135\n",
            "weighted avg       0.57      0.63      0.57       135\n",
            "\n",
            "epoch - 53/150 train_loss - 0.445 acc - 0.689 roc - 0.580 prc_auc - 0.746 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 28]\n",
            " [ 6 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.12      0.19        32\n",
            "         1.0       0.72      0.92      0.81        79\n",
            "\n",
            "    accuracy                           0.69       111\n",
            "   macro avg       0.56      0.52      0.50       111\n",
            "weighted avg       0.63      0.69      0.63       111\n",
            "\n",
            "epoch - 54/150 train_loss - 0.439 acc - 0.691 roc - 0.582 prc_auc - 0.747 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8 32]\n",
            " [ 4 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.20      0.31        40\n",
            "         1.0       0.69      0.95      0.80        75\n",
            "\n",
            "    accuracy                           0.69       115\n",
            "   macro avg       0.68      0.57      0.55       115\n",
            "weighted avg       0.68      0.69      0.63       115\n",
            "\n",
            "epoch - 55/150 train_loss - 0.441 acc - 0.693 roc - 0.584 prc_auc - 0.747 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  3  45]\n",
            " [  5 102]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.06      0.11        48\n",
            "         1.0       0.69      0.95      0.80       107\n",
            "\n",
            "    accuracy                           0.68       155\n",
            "   macro avg       0.53      0.51      0.46       155\n",
            "weighted avg       0.60      0.68      0.59       155\n",
            "\n",
            "epoch - 56/150 train_loss - 0.443 acc - 0.689 roc - 0.587 prc_auc - 0.749 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12 31]\n",
            " [ 3 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.28      0.41        43\n",
            "         1.0       0.70      0.96      0.81        74\n",
            "\n",
            "    accuracy                           0.71       117\n",
            "   macro avg       0.75      0.62      0.61       117\n",
            "weighted avg       0.73      0.71      0.66       117\n",
            "\n",
            "epoch - 57/150 train_loss - 0.440 acc - 0.694 roc - 0.587 prc_auc - 0.748 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 24]\n",
            " [ 5 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.11      0.17        27\n",
            "         1.0       0.75      0.93      0.83        76\n",
            "\n",
            "    accuracy                           0.72       103\n",
            "   macro avg       0.56      0.52      0.50       103\n",
            "weighted avg       0.65      0.72      0.66       103\n",
            "\n",
            "epoch - 58/150 train_loss - 0.438 acc - 0.693 roc - 0.587 prc_auc - 0.750 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 21]\n",
            " [ 5 69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.09      0.13        23\n",
            "         1.0       0.77      0.93      0.84        74\n",
            "\n",
            "    accuracy                           0.73        97\n",
            "   macro avg       0.53      0.51      0.49        97\n",
            "weighted avg       0.65      0.73      0.67        97\n",
            "\n",
            "epoch - 59/150 train_loss - 0.436 acc - 0.694 roc - 0.591 prc_auc - 0.752 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 52]\n",
            " [ 4 90]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.12      0.20        59\n",
            "         1.0       0.63      0.96      0.76        94\n",
            "\n",
            "    accuracy                           0.63       153\n",
            "   macro avg       0.64      0.54      0.48       153\n",
            "weighted avg       0.63      0.63      0.55       153\n",
            "\n",
            "epoch - 60/150 train_loss - 0.444 acc - 0.694 roc - 0.587 prc_auc - 0.748 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 32]\n",
            " [ 8 86]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        32\n",
            "         1.0       0.73      0.91      0.81        94\n",
            "\n",
            "    accuracy                           0.68       126\n",
            "   macro avg       0.36      0.46      0.41       126\n",
            "weighted avg       0.54      0.68      0.61       126\n",
            "\n",
            "epoch - 61/150 train_loss - 0.440 acc - 0.692 roc - 0.590 prc_auc - 0.751 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 31]\n",
            " [ 3 80]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.14      0.23        36\n",
            "         1.0       0.72      0.96      0.82        83\n",
            "\n",
            "    accuracy                           0.71       119\n",
            "   macro avg       0.67      0.55      0.53       119\n",
            "weighted avg       0.69      0.71      0.64       119\n",
            "\n",
            "epoch - 62/150 train_loss - 0.438 acc - 0.693 roc - 0.591 prc_auc - 0.752 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6  33]\n",
            " [  8 112]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.15      0.23        39\n",
            "         1.0       0.77      0.93      0.85       120\n",
            "\n",
            "    accuracy                           0.74       159\n",
            "   macro avg       0.60      0.54      0.54       159\n",
            "weighted avg       0.69      0.74      0.69       159\n",
            "\n",
            "epoch - 63/150 train_loss - 0.441 acc - 0.693 roc - 0.593 prc_auc - 0.755 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 14]\n",
            " [ 4 81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.30      0.40        20\n",
            "         1.0       0.85      0.95      0.90        85\n",
            "\n",
            "    accuracy                           0.83       105\n",
            "   macro avg       0.73      0.63      0.65       105\n",
            "weighted avg       0.80      0.83      0.80       105\n",
            "\n",
            "epoch - 64/150 train_loss - 0.434 acc - 0.691 roc - 0.593 prc_auc - 0.754 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 29]\n",
            " [ 7 59]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.06      0.10        31\n",
            "         1.0       0.67      0.89      0.77        66\n",
            "\n",
            "    accuracy                           0.63        97\n",
            "   macro avg       0.45      0.48      0.43        97\n",
            "weighted avg       0.53      0.63      0.55        97\n",
            "\n",
            "epoch - 65/150 train_loss - 0.436 acc - 0.689 roc - 0.593 prc_auc - 0.754 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 24]\n",
            " [ 2 73]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.08      0.13        26\n",
            "         1.0       0.75      0.97      0.85        75\n",
            "\n",
            "    accuracy                           0.74       101\n",
            "   macro avg       0.63      0.53      0.49       101\n",
            "weighted avg       0.69      0.74      0.66       101\n",
            "\n",
            "epoch - 66/150 train_loss - 0.436 acc - 0.694 roc - 0.592 prc_auc - 0.753 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 26]\n",
            " [ 5 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.07      0.11        28\n",
            "         1.0       0.75      0.94      0.83        81\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.52      0.50      0.47       109\n",
            "weighted avg       0.63      0.72      0.65       109\n",
            "\n",
            "epoch - 67/150 train_loss - 0.435 acc - 0.696 roc - 0.596 prc_auc - 0.755 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 50]\n",
            " [ 9 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.15      0.23        59\n",
            "         1.0       0.60      0.89      0.72        85\n",
            "\n",
            "    accuracy                           0.59       144\n",
            "   macro avg       0.55      0.52      0.48       144\n",
            "weighted avg       0.56      0.59      0.52       144\n",
            "\n",
            "epoch - 68/150 train_loss - 0.440 acc - 0.694 roc - 0.600 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 32]\n",
            " [ 3 91]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.03      0.05        33\n",
            "         1.0       0.74      0.97      0.84        94\n",
            "\n",
            "    accuracy                           0.72       127\n",
            "   macro avg       0.49      0.50      0.45       127\n",
            "weighted avg       0.61      0.72      0.63       127\n",
            "\n",
            "epoch - 69/150 train_loss - 0.436 acc - 0.696 roc - 0.599 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 29]\n",
            " [ 9 72]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.12      0.17        33\n",
            "         1.0       0.71      0.89      0.79        81\n",
            "\n",
            "    accuracy                           0.67       114\n",
            "   macro avg       0.51      0.51      0.48       114\n",
            "weighted avg       0.60      0.67      0.61       114\n",
            "\n",
            "epoch - 70/150 train_loss - 0.436 acc - 0.695 roc - 0.596 prc_auc - 0.754 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 22]\n",
            " [ 2 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.08      0.14        24\n",
            "         1.0       0.80      0.98      0.88        91\n",
            "\n",
            "    accuracy                           0.79       115\n",
            "   macro avg       0.65      0.53      0.51       115\n",
            "weighted avg       0.74      0.79      0.73       115\n",
            "\n",
            "epoch - 71/150 train_loss - 0.434 acc - 0.693 roc - 0.598 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 28]\n",
            " [ 5 90]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.07      0.11        30\n",
            "         1.0       0.76      0.95      0.85        95\n",
            "\n",
            "    accuracy                           0.74       125\n",
            "   macro avg       0.52      0.51      0.48       125\n",
            "weighted avg       0.65      0.74      0.67       125\n",
            "\n",
            "epoch - 72/150 train_loss - 0.435 acc - 0.697 roc - 0.599 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 37]\n",
            " [ 5 69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.10      0.16        41\n",
            "         1.0       0.65      0.93      0.77        74\n",
            "\n",
            "    accuracy                           0.63       115\n",
            "   macro avg       0.55      0.51      0.46       115\n",
            "weighted avg       0.58      0.63      0.55       115\n",
            "\n",
            "epoch - 73/150 train_loss - 0.435 acc - 0.699 roc - 0.601 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 31]\n",
            " [ 7 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.42      0.14      0.21        36\n",
            "         1.0       0.74      0.93      0.82        96\n",
            "\n",
            "    accuracy                           0.71       132\n",
            "   macro avg       0.58      0.53      0.52       132\n",
            "weighted avg       0.65      0.71      0.66       132\n",
            "\n",
            "epoch - 74/150 train_loss - 0.436 acc - 0.693 roc - 0.600 prc_auc - 0.757 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 57]\n",
            " [ 2 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.03      0.06        59\n",
            "         1.0       0.58      0.97      0.73        80\n",
            "\n",
            "    accuracy                           0.58       139\n",
            "   macro avg       0.54      0.50      0.39       139\n",
            "weighted avg       0.54      0.58      0.44       139\n",
            "\n",
            "epoch - 75/150 train_loss - 0.439 acc - 0.696 roc - 0.602 prc_auc - 0.758 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 34]\n",
            " [ 3 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.15      0.24        40\n",
            "         1.0       0.72      0.97      0.83        92\n",
            "\n",
            "    accuracy                           0.72       132\n",
            "   macro avg       0.70      0.56      0.54       132\n",
            "weighted avg       0.71      0.72      0.65       132\n",
            "\n",
            "epoch - 76/150 train_loss - 0.436 acc - 0.695 roc - 0.602 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 54]\n",
            " [ 4 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.14      0.24        63\n",
            "         1.0       0.53      0.94      0.68        65\n",
            "\n",
            "    accuracy                           0.55       128\n",
            "   macro avg       0.61      0.54      0.46       128\n",
            "weighted avg       0.61      0.55      0.46       128\n",
            "\n",
            "epoch - 77/150 train_loss - 0.439 acc - 0.694 roc - 0.602 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 23]\n",
            " [ 4 91]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.08      0.13        25\n",
            "         1.0       0.80      0.96      0.87        95\n",
            "\n",
            "    accuracy                           0.78       120\n",
            "   macro avg       0.57      0.52      0.50       120\n",
            "weighted avg       0.70      0.78      0.72       120\n",
            "\n",
            "epoch - 78/150 train_loss - 0.433 acc - 0.695 roc - 0.603 prc_auc - 0.758 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 37]\n",
            " [ 4 69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.07      0.13        40\n",
            "         1.0       0.65      0.95      0.77        73\n",
            "\n",
            "    accuracy                           0.64       113\n",
            "   macro avg       0.54      0.51      0.45       113\n",
            "weighted avg       0.57      0.64      0.54       113\n",
            "\n",
            "epoch - 79/150 train_loss - 0.434 acc - 0.698 roc - 0.604 prc_auc - 0.759 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  4  19]\n",
            " [ 11 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.17      0.21        23\n",
            "         1.0       0.86      0.91      0.88       125\n",
            "\n",
            "    accuracy                           0.80       148\n",
            "   macro avg       0.56      0.54      0.55       148\n",
            "weighted avg       0.77      0.80      0.78       148\n",
            "\n",
            "epoch - 80/150 train_loss - 0.434 acc - 0.697 roc - 0.608 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 28]\n",
            " [ 3 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.15      0.24        33\n",
            "         1.0       0.76      0.97      0.85        92\n",
            "\n",
            "    accuracy                           0.75       125\n",
            "   macro avg       0.69      0.56      0.55       125\n",
            "weighted avg       0.72      0.75      0.69       125\n",
            "\n",
            "epoch - 81/150 train_loss - 0.433 acc - 0.696 roc - 0.604 prc_auc - 0.760 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 25]\n",
            " [ 4 48]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        25\n",
            "         1.0       0.66      0.92      0.77        52\n",
            "\n",
            "    accuracy                           0.62        77\n",
            "   macro avg       0.33      0.46      0.38        77\n",
            "weighted avg       0.44      0.62      0.52        77\n",
            "\n",
            "epoch - 82/150 train_loss - 0.430 acc - 0.697 roc - 0.606 prc_auc - 0.760 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  3  32]\n",
            " [  3 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.09      0.15        35\n",
            "         1.0       0.76      0.97      0.85       104\n",
            "\n",
            "    accuracy                           0.75       139\n",
            "   macro avg       0.63      0.53      0.50       139\n",
            "weighted avg       0.69      0.75      0.67       139\n",
            "\n",
            "epoch - 83/150 train_loss - 0.434 acc - 0.696 roc - 0.607 prc_auc - 0.761 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 40]\n",
            " [ 4 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.15      0.24        47\n",
            "         1.0       0.66      0.95      0.78        82\n",
            "\n",
            "    accuracy                           0.66       129\n",
            "   macro avg       0.65      0.55      0.51       129\n",
            "weighted avg       0.65      0.66      0.58       129\n",
            "\n",
            "epoch - 84/150 train_loss - 0.436 acc - 0.694 roc - 0.607 prc_auc - 0.761 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 31]\n",
            " [ 9 98]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.03      0.05        32\n",
            "         1.0       0.76      0.92      0.83       107\n",
            "\n",
            "    accuracy                           0.71       139\n",
            "   macro avg       0.43      0.47      0.44       139\n",
            "weighted avg       0.61      0.71      0.65       139\n",
            "\n",
            "epoch - 85/150 train_loss - 0.435 acc - 0.699 roc - 0.606 prc_auc - 0.761 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 44]\n",
            " [ 2 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.14      0.23        51\n",
            "         1.0       0.63      0.97      0.76        76\n",
            "\n",
            "    accuracy                           0.64       127\n",
            "   macro avg       0.70      0.56      0.50       127\n",
            "weighted avg       0.69      0.64      0.55       127\n",
            "\n",
            "epoch - 86/150 train_loss - 0.436 acc - 0.696 roc - 0.608 prc_auc - 0.761 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 27]\n",
            " [ 3 83]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.07      0.12        29\n",
            "         1.0       0.75      0.97      0.85        86\n",
            "\n",
            "    accuracy                           0.74       115\n",
            "   macro avg       0.58      0.52      0.48       115\n",
            "weighted avg       0.67      0.74      0.66       115\n",
            "\n",
            "epoch - 87/150 train_loss - 0.431 acc - 0.699 roc - 0.610 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 28]\n",
            " [ 2 80]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.21        32\n",
            "         1.0       0.74      0.98      0.84        82\n",
            "\n",
            "    accuracy                           0.74       114\n",
            "   macro avg       0.70      0.55      0.53       114\n",
            "weighted avg       0.72      0.74      0.66       114\n",
            "\n",
            "epoch - 88/150 train_loss - 0.431 acc - 0.697 roc - 0.610 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 27]\n",
            " [ 4 92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.07      0.11        29\n",
            "         1.0       0.77      0.96      0.86        96\n",
            "\n",
            "    accuracy                           0.75       125\n",
            "   macro avg       0.55      0.51      0.49       125\n",
            "weighted avg       0.67      0.75      0.68       125\n",
            "\n",
            "epoch - 89/150 train_loss - 0.432 acc - 0.699 roc - 0.609 prc_auc - 0.760 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9 60]\n",
            " [ 8 84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.13      0.21        69\n",
            "         1.0       0.58      0.91      0.71        92\n",
            "\n",
            "    accuracy                           0.58       161\n",
            "   macro avg       0.56      0.52      0.46       161\n",
            "weighted avg       0.56      0.58      0.50       161\n",
            "\n",
            "epoch - 90/150 train_loss - 0.439 acc - 0.697 roc - 0.611 prc_auc - 0.762 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 28]\n",
            " [ 0 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.10      0.18        31\n",
            "         1.0       0.74      1.00      0.85        78\n",
            "\n",
            "    accuracy                           0.74       109\n",
            "   macro avg       0.87      0.55      0.51       109\n",
            "weighted avg       0.81      0.74      0.66       109\n",
            "\n",
            "epoch - 91/150 train_loss - 0.430 acc - 0.699 roc - 0.611 prc_auc - 0.764 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  4  58]\n",
            " [  7 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.36      0.06      0.11        62\n",
            "         1.0       0.64      0.94      0.76       108\n",
            "\n",
            "    accuracy                           0.62       170\n",
            "   macro avg       0.50      0.50      0.43       170\n",
            "weighted avg       0.54      0.62      0.52       170\n",
            "\n",
            "epoch - 92/150 train_loss - 0.439 acc - 0.698 roc - 0.611 prc_auc - 0.763 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 30]\n",
            " [ 1 99]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.17      0.28        36\n",
            "         1.0       0.77      0.99      0.86       100\n",
            "\n",
            "    accuracy                           0.77       136\n",
            "   macro avg       0.81      0.58      0.57       136\n",
            "weighted avg       0.79      0.77      0.71       136\n",
            "\n",
            "epoch - 93/150 train_loss - 0.433 acc - 0.695 roc - 0.612 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 43]\n",
            " [ 4 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.10      0.18        48\n",
            "         1.0       0.67      0.96      0.79        93\n",
            "\n",
            "    accuracy                           0.67       141\n",
            "   macro avg       0.61      0.53      0.48       141\n",
            "weighted avg       0.63      0.67      0.58       141\n",
            "\n",
            "epoch - 94/150 train_loss - 0.435 acc - 0.697 roc - 0.612 prc_auc - 0.764 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 21]\n",
            " [ 3 79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.25      0.37        28\n",
            "         1.0       0.79      0.96      0.87        82\n",
            "\n",
            "    accuracy                           0.78       110\n",
            "   macro avg       0.74      0.61      0.62       110\n",
            "weighted avg       0.77      0.78      0.74       110\n",
            "\n",
            "epoch - 95/150 train_loss - 0.429 acc - 0.697 roc - 0.612 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 35]\n",
            " [ 8 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.38      0.12      0.19        40\n",
            "         1.0       0.68      0.90      0.78        84\n",
            "\n",
            "    accuracy                           0.65       124\n",
            "   macro avg       0.53      0.51      0.48       124\n",
            "weighted avg       0.59      0.65      0.59       124\n",
            "\n",
            "epoch - 96/150 train_loss - 0.433 acc - 0.696 roc - 0.613 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 28]\n",
            " [ 5 64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.12      0.20        32\n",
            "         1.0       0.70      0.93      0.80        69\n",
            "\n",
            "    accuracy                           0.67       101\n",
            "   macro avg       0.57      0.53      0.50       101\n",
            "weighted avg       0.62      0.67      0.60       101\n",
            "\n",
            "epoch - 97/150 train_loss - 0.430 acc - 0.696 roc - 0.613 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 25]\n",
            " [ 5 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.07      0.12        27\n",
            "         1.0       0.71      0.92      0.80        66\n",
            "\n",
            "    accuracy                           0.68        93\n",
            "   macro avg       0.50      0.50      0.46        93\n",
            "weighted avg       0.59      0.68      0.60        93\n",
            "\n",
            "epoch - 98/150 train_loss - 0.428 acc - 0.699 roc - 0.614 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  5  38]\n",
            " [  3 100]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.12      0.20        43\n",
            "         1.0       0.72      0.97      0.83       103\n",
            "\n",
            "    accuracy                           0.72       146\n",
            "   macro avg       0.67      0.54      0.51       146\n",
            "weighted avg       0.70      0.72      0.64       146\n",
            "\n",
            "epoch - 99/150 train_loss - 0.433 acc - 0.696 roc - 0.618 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  3  41]\n",
            " [  6 103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.07      0.11        44\n",
            "         1.0       0.72      0.94      0.81       109\n",
            "\n",
            "    accuracy                           0.69       153\n",
            "   macro avg       0.52      0.51      0.46       153\n",
            "weighted avg       0.61      0.69      0.61       153\n",
            "\n",
            "epoch - 100/150 train_loss - 0.435 acc - 0.699 roc - 0.616 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 25]\n",
            " [ 6 92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.07      0.11        27\n",
            "         1.0       0.79      0.94      0.86        98\n",
            "\n",
            "    accuracy                           0.75       125\n",
            "   macro avg       0.52      0.51      0.49       125\n",
            "weighted avg       0.67      0.75      0.70       125\n",
            "\n",
            "epoch - 101/150 train_loss - 0.430 acc - 0.698 roc - 0.614 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 29]\n",
            " [ 3 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.26      0.38        39\n",
            "         1.0       0.72      0.96      0.82        77\n",
            "\n",
            "    accuracy                           0.72       116\n",
            "   macro avg       0.74      0.61      0.60       116\n",
            "weighted avg       0.74      0.72      0.68       116\n",
            "\n",
            "epoch - 102/150 train_loss - 0.430 acc - 0.698 roc - 0.613 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.72it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 32]\n",
            " [ 0 68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        32\n",
            "         1.0       0.68      1.00      0.81        68\n",
            "\n",
            "    accuracy                           0.68       100\n",
            "   macro avg       0.34      0.50      0.40       100\n",
            "weighted avg       0.46      0.68      0.55       100\n",
            "\n",
            "epoch - 103/150 train_loss - 0.428 acc - 0.701 roc - 0.615 prc_auc - 0.766 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 38]\n",
            " [ 6 72]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.14      0.21        44\n",
            "         1.0       0.65      0.92      0.77        78\n",
            "\n",
            "    accuracy                           0.64       122\n",
            "   macro avg       0.58      0.53      0.49       122\n",
            "weighted avg       0.60      0.64      0.57       122\n",
            "\n",
            "epoch - 104/150 train_loss - 0.432 acc - 0.699 roc - 0.616 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  7  36]\n",
            " [  1 102]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.16      0.27        43\n",
            "         1.0       0.74      0.99      0.85       103\n",
            "\n",
            "    accuracy                           0.75       146\n",
            "   macro avg       0.81      0.58      0.56       146\n",
            "weighted avg       0.78      0.75      0.68       146\n",
            "\n",
            "epoch - 105/150 train_loss - 0.433 acc - 0.698 roc - 0.615 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 36]\n",
            " [ 5 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.14      0.23        42\n",
            "         1.0       0.63      0.92      0.75        66\n",
            "\n",
            "    accuracy                           0.62       108\n",
            "   macro avg       0.59      0.53      0.49       108\n",
            "weighted avg       0.60      0.62      0.55       108\n",
            "\n",
            "epoch - 106/150 train_loss - 0.431 acc - 0.698 roc - 0.616 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 45]\n",
            " [ 4 74]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.02      0.04        46\n",
            "         1.0       0.62      0.95      0.75        78\n",
            "\n",
            "    accuracy                           0.60       124\n",
            "   macro avg       0.41      0.49      0.40       124\n",
            "weighted avg       0.47      0.60      0.49       124\n",
            "\n",
            "epoch - 107/150 train_loss - 0.433 acc - 0.700 roc - 0.614 prc_auc - 0.765 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 37]\n",
            " [ 1 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.16      0.27        44\n",
            "         1.0       0.67      0.99      0.80        77\n",
            "\n",
            "    accuracy                           0.69       121\n",
            "   macro avg       0.77      0.57      0.53       121\n",
            "weighted avg       0.75      0.69      0.61       121\n",
            "\n",
            "epoch - 108/150 train_loss - 0.431 acc - 0.699 roc - 0.618 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 21]\n",
            " [ 4 88]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.05      0.07        22\n",
            "         1.0       0.81      0.96      0.88        92\n",
            "\n",
            "    accuracy                           0.78       114\n",
            "   macro avg       0.50      0.50      0.47       114\n",
            "weighted avg       0.69      0.78      0.72       114\n",
            "\n",
            "epoch - 109/150 train_loss - 0.428 acc - 0.698 roc - 0.615 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 37]\n",
            " [ 7 92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.21      0.31        47\n",
            "         1.0       0.71      0.93      0.81        99\n",
            "\n",
            "    accuracy                           0.70       146\n",
            "   macro avg       0.65      0.57      0.56       146\n",
            "weighted avg       0.67      0.70      0.65       146\n",
            "\n",
            "epoch - 110/150 train_loss - 0.431 acc - 0.700 roc - 0.620 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  3  50]\n",
            " [  8 107]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.06      0.09        53\n",
            "         1.0       0.68      0.93      0.79       115\n",
            "\n",
            "    accuracy                           0.65       168\n",
            "   macro avg       0.48      0.49      0.44       168\n",
            "weighted avg       0.55      0.65      0.57       168\n",
            "\n",
            "epoch - 111/150 train_loss - 0.435 acc - 0.697 roc - 0.616 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 35]\n",
            " [ 3 79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.25      0.03      0.05        36\n",
            "         1.0       0.69      0.96      0.81        82\n",
            "\n",
            "    accuracy                           0.68       118\n",
            "   macro avg       0.47      0.50      0.43       118\n",
            "weighted avg       0.56      0.68      0.58       118\n",
            "\n",
            "epoch - 112/150 train_loss - 0.430 acc - 0.698 roc - 0.617 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 41]\n",
            " [ 3 76]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.07      0.12        44\n",
            "         1.0       0.65      0.96      0.78        79\n",
            "\n",
            "    accuracy                           0.64       123\n",
            "   macro avg       0.57      0.52      0.45       123\n",
            "weighted avg       0.60      0.64      0.54       123\n",
            "\n",
            "epoch - 113/150 train_loss - 0.430 acc - 0.698 roc - 0.619 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 27]\n",
            " [ 2 83]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.13      0.22        31\n",
            "         1.0       0.75      0.98      0.85        85\n",
            "\n",
            "    accuracy                           0.75       116\n",
            "   macro avg       0.71      0.55      0.53       116\n",
            "weighted avg       0.73      0.75      0.68       116\n",
            "\n",
            "epoch - 114/150 train_loss - 0.428 acc - 0.699 roc - 0.619 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 25]\n",
            " [ 5 79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06        26\n",
            "         1.0       0.76      0.94      0.84        84\n",
            "\n",
            "    accuracy                           0.73       110\n",
            "   macro avg       0.46      0.49      0.45       110\n",
            "weighted avg       0.62      0.73      0.66       110\n",
            "\n",
            "epoch - 115/150 train_loss - 0.428 acc - 0.701 roc - 0.619 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 37]\n",
            " [ 4 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.12      0.20        42\n",
            "         1.0       0.68      0.95      0.79        82\n",
            "\n",
            "    accuracy                           0.67       124\n",
            "   macro avg       0.62      0.54      0.49       124\n",
            "weighted avg       0.64      0.67      0.59       124\n",
            "\n",
            "epoch - 116/150 train_loss - 0.431 acc - 0.701 roc - 0.618 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  5  51]\n",
            " [  4 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.09      0.15        56\n",
            "         1.0       0.66      0.96      0.79       105\n",
            "\n",
            "    accuracy                           0.66       161\n",
            "   macro avg       0.61      0.53      0.47       161\n",
            "weighted avg       0.63      0.66      0.57       161\n",
            "\n",
            "epoch - 117/150 train_loss - 0.435 acc - 0.699 roc - 0.617 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 39]\n",
            " [ 3 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.15      0.25        46\n",
            "         1.0       0.62      0.96      0.76        68\n",
            "\n",
            "    accuracy                           0.63       114\n",
            "   macro avg       0.66      0.55      0.50       114\n",
            "weighted avg       0.66      0.63      0.55       114\n",
            "\n",
            "epoch - 118/150 train_loss - 0.430 acc - 0.703 roc - 0.619 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6  39]\n",
            " [  4 101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.13      0.22        45\n",
            "         1.0       0.72      0.96      0.82       105\n",
            "\n",
            "    accuracy                           0.71       150\n",
            "   macro avg       0.66      0.55      0.52       150\n",
            "weighted avg       0.69      0.71      0.64       150\n",
            "\n",
            "epoch - 119/150 train_loss - 0.432 acc - 0.698 roc - 0.617 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 33]\n",
            " [ 3 84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.13      0.22        38\n",
            "         1.0       0.72      0.97      0.82        87\n",
            "\n",
            "    accuracy                           0.71       125\n",
            "   macro avg       0.67      0.55      0.52       125\n",
            "weighted avg       0.69      0.71      0.64       125\n",
            "\n",
            "epoch - 120/150 train_loss - 0.429 acc - 0.700 roc - 0.619 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 24]\n",
            " [ 5 93]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.17      0.26        29\n",
            "         1.0       0.79      0.95      0.87        98\n",
            "\n",
            "    accuracy                           0.77       127\n",
            "   macro avg       0.65      0.56      0.56       127\n",
            "weighted avg       0.73      0.77      0.73       127\n",
            "\n",
            "epoch - 121/150 train_loss - 0.429 acc - 0.697 roc - 0.620 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  7  35]\n",
            " [  5 111]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      0.17      0.26        42\n",
            "         1.0       0.76      0.96      0.85       116\n",
            "\n",
            "    accuracy                           0.75       158\n",
            "   macro avg       0.67      0.56      0.55       158\n",
            "weighted avg       0.71      0.75      0.69       158\n",
            "\n",
            "epoch - 122/150 train_loss - 0.432 acc - 0.699 roc - 0.619 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 34]\n",
            " [ 1 85]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.11      0.19        38\n",
            "         1.0       0.71      0.99      0.83        86\n",
            "\n",
            "    accuracy                           0.72       124\n",
            "   macro avg       0.76      0.55      0.51       124\n",
            "weighted avg       0.74      0.72      0.63       124\n",
            "\n",
            "epoch - 123/150 train_loss - 0.429 acc - 0.701 roc - 0.621 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 25]\n",
            " [ 5 84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.07      0.12        27\n",
            "         1.0       0.77      0.94      0.85        89\n",
            "\n",
            "    accuracy                           0.74       116\n",
            "   macro avg       0.53      0.51      0.48       116\n",
            "weighted avg       0.66      0.74      0.68       116\n",
            "\n",
            "epoch - 124/150 train_loss - 0.427 acc - 0.701 roc - 0.621 prc_auc - 0.771 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 27]\n",
            " [ 8 92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.04      0.05        28\n",
            "         1.0       0.77      0.92      0.84       100\n",
            "\n",
            "    accuracy                           0.73       128\n",
            "   macro avg       0.44      0.48      0.45       128\n",
            "weighted avg       0.63      0.73      0.67       128\n",
            "\n",
            "epoch - 125/150 train_loss - 0.428 acc - 0.703 roc - 0.621 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  6.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 25]\n",
            " [ 5 93]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06        26\n",
            "         1.0       0.79      0.95      0.86        98\n",
            "\n",
            "    accuracy                           0.76       124\n",
            "   macro avg       0.48      0.49      0.46       124\n",
            "weighted avg       0.66      0.76      0.69       124\n",
            "\n",
            "epoch - 126/150 train_loss - 0.428 acc - 0.698 roc - 0.620 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 47]\n",
            " [ 7 88]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.42      0.10      0.16        52\n",
            "         1.0       0.65      0.93      0.77        95\n",
            "\n",
            "    accuracy                           0.63       147\n",
            "   macro avg       0.53      0.51      0.46       147\n",
            "weighted avg       0.57      0.63      0.55       147\n",
            "\n",
            "epoch - 127/150 train_loss - 0.434 acc - 0.696 roc - 0.618 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 20]\n",
            " [ 4 41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.23      0.33        26\n",
            "         1.0       0.67      0.91      0.77        45\n",
            "\n",
            "    accuracy                           0.66        71\n",
            "   macro avg       0.64      0.57      0.55        71\n",
            "weighted avg       0.65      0.66      0.61        71\n",
            "\n",
            "epoch - 128/150 train_loss - 0.425 acc - 0.698 roc - 0.619 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 20]\n",
            " [ 3 69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.09      0.15        22\n",
            "         1.0       0.78      0.96      0.86        72\n",
            "\n",
            "    accuracy                           0.76        94\n",
            "   macro avg       0.59      0.52      0.50        94\n",
            "weighted avg       0.69      0.76      0.69        94\n",
            "\n",
            "epoch - 129/150 train_loss - 0.426 acc - 0.702 roc - 0.619 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1 27]\n",
            " [ 5 77]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06        28\n",
            "         1.0       0.74      0.94      0.83        82\n",
            "\n",
            "    accuracy                           0.71       110\n",
            "   macro avg       0.45      0.49      0.44       110\n",
            "weighted avg       0.59      0.71      0.63       110\n",
            "\n",
            "epoch - 130/150 train_loss - 0.427 acc - 0.697 roc - 0.622 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 43]\n",
            " [ 4 99]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.10      0.18        48\n",
            "         1.0       0.70      0.96      0.81       103\n",
            "\n",
            "    accuracy                           0.69       151\n",
            "   macro avg       0.63      0.53      0.49       151\n",
            "weighted avg       0.65      0.69      0.61       151\n",
            "\n",
            "epoch - 131/150 train_loss - 0.432 acc - 0.700 roc - 0.622 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 37]\n",
            " [ 6 90]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.10      0.16        41\n",
            "         1.0       0.71      0.94      0.81        96\n",
            "\n",
            "    accuracy                           0.69       137\n",
            "   macro avg       0.55      0.52      0.48       137\n",
            "weighted avg       0.62      0.69      0.61       137\n",
            "\n",
            "epoch - 132/150 train_loss - 0.431 acc - 0.698 roc - 0.620 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 35]\n",
            " [ 4 87]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.22      0.34        45\n",
            "         1.0       0.71      0.96      0.82        91\n",
            "\n",
            "    accuracy                           0.71       136\n",
            "   macro avg       0.71      0.59      0.58       136\n",
            "weighted avg       0.71      0.71      0.66       136\n",
            "\n",
            "epoch - 133/150 train_loss - 0.431 acc - 0.697 roc - 0.621 prc_auc - 0.771 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 38]\n",
            " [ 6 96]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.21      0.31        48\n",
            "         1.0       0.72      0.94      0.81       102\n",
            "\n",
            "    accuracy                           0.71       150\n",
            "   macro avg       0.67      0.57      0.56       150\n",
            "weighted avg       0.69      0.71      0.65       150\n",
            "\n",
            "epoch - 134/150 train_loss - 0.431 acc - 0.700 roc - 0.622 prc_auc - 0.772 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 31]\n",
            " [ 3 85]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.16      0.26        37\n",
            "         1.0       0.73      0.97      0.83        88\n",
            "\n",
            "    accuracy                           0.73       125\n",
            "   macro avg       0.70      0.56      0.55       125\n",
            "weighted avg       0.71      0.73      0.66       125\n",
            "\n",
            "epoch - 135/150 train_loss - 0.429 acc - 0.703 roc - 0.621 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 42]\n",
            " [ 3 81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.11      0.18        47\n",
            "         1.0       0.66      0.96      0.78        84\n",
            "\n",
            "    accuracy                           0.66       131\n",
            "   macro avg       0.64      0.54      0.48       131\n",
            "weighted avg       0.65      0.66      0.57       131\n",
            "\n",
            "epoch - 136/150 train_loss - 0.430 acc - 0.702 roc - 0.621 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 30]\n",
            " [ 2 94]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.09      0.16        33\n",
            "         1.0       0.76      0.98      0.85        96\n",
            "\n",
            "    accuracy                           0.75       129\n",
            "   macro avg       0.68      0.54      0.51       129\n",
            "weighted avg       0.72      0.75      0.68       129\n",
            "\n",
            "epoch - 137/150 train_loss - 0.429 acc - 0.698 roc - 0.620 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 30]\n",
            " [ 2 83]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.12      0.20        34\n",
            "         1.0       0.73      0.98      0.84        85\n",
            "\n",
            "    accuracy                           0.73       119\n",
            "   macro avg       0.70      0.55      0.52       119\n",
            "weighted avg       0.72      0.73      0.66       119\n",
            "\n",
            "epoch - 138/150 train_loss - 0.428 acc - 0.695 roc - 0.622 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 28]\n",
            " [ 0 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.15      0.26        33\n",
            "         1.0       0.72      1.00      0.84        71\n",
            "\n",
            "    accuracy                           0.73       104\n",
            "   macro avg       0.86      0.58      0.55       104\n",
            "weighted avg       0.81      0.73      0.65       104\n",
            "\n",
            "epoch - 139/150 train_loss - 0.427 acc - 0.702 roc - 0.621 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 27]\n",
            " [ 3 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      0.07      0.12        29\n",
            "         1.0       0.77      0.97      0.86        92\n",
            "\n",
            "    accuracy                           0.75       121\n",
            "   macro avg       0.58      0.52      0.49       121\n",
            "weighted avg       0.68      0.75      0.68       121\n",
            "\n",
            "epoch - 140/150 train_loss - 0.427 acc - 0.703 roc - 0.621 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 18]\n",
            " [ 2 61]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.18      0.29        22\n",
            "         1.0       0.77      0.97      0.86        63\n",
            "\n",
            "    accuracy                           0.76        85\n",
            "   macro avg       0.72      0.58      0.57        85\n",
            "weighted avg       0.74      0.76      0.71        85\n",
            "\n",
            "epoch - 141/150 train_loss - 0.424 acc - 0.702 roc - 0.623 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6  38]\n",
            " [  7 104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.46      0.14      0.21        44\n",
            "         1.0       0.73      0.94      0.82       111\n",
            "\n",
            "    accuracy                           0.71       155\n",
            "   macro avg       0.60      0.54      0.52       155\n",
            "weighted avg       0.66      0.71      0.65       155\n",
            "\n",
            "epoch - 142/150 train_loss - 0.432 acc - 0.698 roc - 0.621 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 34]\n",
            " [ 5 91]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.15      0.24        40\n",
            "         1.0       0.73      0.95      0.82        96\n",
            "\n",
            "    accuracy                           0.71       136\n",
            "   macro avg       0.64      0.55      0.53       136\n",
            "weighted avg       0.67      0.71      0.65       136\n",
            "\n",
            "epoch - 143/150 train_loss - 0.431 acc - 0.698 roc - 0.622 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6  41]\n",
            " [  1 103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.13      0.22        47\n",
            "         1.0       0.72      0.99      0.83       104\n",
            "\n",
            "    accuracy                           0.72       151\n",
            "   macro avg       0.79      0.56      0.53       151\n",
            "weighted avg       0.76      0.72      0.64       151\n",
            "\n",
            "epoch - 144/150 train_loss - 0.431 acc - 0.699 roc - 0.623 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6 42]\n",
            " [ 7 49]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.46      0.12      0.20        48\n",
            "         1.0       0.54      0.88      0.67        56\n",
            "\n",
            "    accuracy                           0.53       104\n",
            "   macro avg       0.50      0.50      0.43       104\n",
            "weighted avg       0.50      0.53      0.45       104\n",
            "\n",
            "epoch - 145/150 train_loss - 0.429 acc - 0.697 roc - 0.622 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 20]\n",
            " [ 6 97]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.13      0.19        23\n",
            "         1.0       0.83      0.94      0.88       103\n",
            "\n",
            "    accuracy                           0.79       126\n",
            "   macro avg       0.58      0.54      0.53       126\n",
            "weighted avg       0.74      0.79      0.76       126\n",
            "\n",
            "epoch - 146/150 train_loss - 0.427 acc - 0.695 roc - 0.622 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 31]\n",
            " [ 3 83]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.09      0.15        34\n",
            "         1.0       0.73      0.97      0.83        86\n",
            "\n",
            "    accuracy                           0.72       120\n",
            "   macro avg       0.61      0.53      0.49       120\n",
            "weighted avg       0.66      0.72      0.64       120\n",
            "\n",
            "epoch - 147/150 train_loss - 0.429 acc - 0.699 roc - 0.619 prc_auc - 0.767 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4 29]\n",
            " [ 5 71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.44      0.12      0.19        33\n",
            "         1.0       0.71      0.93      0.81        76\n",
            "\n",
            "    accuracy                           0.69       109\n",
            "   macro avg       0.58      0.53      0.50       109\n",
            "weighted avg       0.63      0.69      0.62       109\n",
            "\n",
            "epoch - 148/150 train_loss - 0.428 acc - 0.696 roc - 0.621 prc_auc - 0.768 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 23]\n",
            " [ 7 78]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.42      0.18      0.25        28\n",
            "         1.0       0.77      0.92      0.84        85\n",
            "\n",
            "    accuracy                           0.73       113\n",
            "   macro avg       0.59      0.55      0.54       113\n",
            "weighted avg       0.68      0.73      0.69       113\n",
            "\n",
            "epoch - 149/150 train_loss - 0.428 acc - 0.701 roc - 0.622 prc_auc - 0.769 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 13/13 [00:01<00:00,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11 55]\n",
            " [ 9 99]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.55      0.17      0.26        66\n",
            "         1.0       0.64      0.92      0.76       108\n",
            "\n",
            "    accuracy                           0.63       174\n",
            "   macro avg       0.60      0.54      0.51       174\n",
            "weighted avg       0.61      0.63      0.57       174\n",
            "\n",
            "epoch - 150/150 train_loss - 0.437 acc - 0.699 roc - 0.621 prc_auc - 0.770 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_g429MO0hR8"
      },
      "source": [
        "#Test function \n",
        "import psutil\n",
        "def test_epoch(model, test_iterator, criterion, device=\"cpu\"):\n",
        "  model.load_state_dict(torch.load(\"sakt_task2.pt\"))\n",
        "  model.eval()\n",
        "  #print(\"inside test_epoch !!\") \n",
        "  test_loss = []\n",
        "  num_corrects = 0\n",
        "  num_total = 0\n",
        "  labels = []\n",
        "  outs = []\n",
        "  preds = []\n",
        "\n",
        "  prev_test_df = None\n",
        "  tbar = tqdm(test_iterator)\n",
        "  for item in tbar:\n",
        "          x = item[0].to(device).long()\n",
        "          target_id = item[1].to(device).long()\n",
        "          label = item[2].to(device).float()\n",
        "          target_mask = (target_id != 0)\n",
        "\n",
        "          with torch.no_grad():\n",
        "            output, att_weight = model(x, target_id)\n",
        "          \n",
        "          \n",
        "          output = torch.masked_select(output, target_mask)\n",
        "          label = torch.masked_select(label, target_mask)\n",
        "\n",
        "          loss = criterion(output, label)\n",
        "          test_loss.append(loss.item())\n",
        "\n",
        "          pred = (torch.sigmoid(output) >= 0.5).long()\n",
        "          num_corrects += (pred == label).sum().item()\n",
        "          num_total += len(label)\n",
        "          print('num_cor:', num_corrects)\n",
        "          print(\"tot:\",num_total)\n",
        "\n",
        "          labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
        "          outs.extend(output.view(-1).data.cpu().numpy())\n",
        "          preds.extend(pred.squeeze(-1).data.cpu().numpy())\n",
        "\n",
        "  \n",
        "  acc = num_corrects / num_total\n",
        "  roc = roc_auc_score(labels, outs)\n",
        "  precision, recall, _ = precision_recall_curve(labels,outs)\n",
        "  auc_score = auc(recall, precision)\n",
        "  loss = np.average(test_loss)\n",
        "  \n",
        "  print(metrics.confusion_matrix(label,pred))\n",
        "  print(metrics.classification_report(label,pred))\n",
        "\n",
        "  return loss, acc, roc, auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caMRwa1V0hR8"
      },
      "source": [
        "#make test epoch =1 \n",
        "epoch_test = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFfK30_l0hR8",
        "outputId": "7825eb6e-af03-44f0-ca13-7ff7042f0798"
      },
      "source": [
        "#Test on 5049\n",
        "for epoch in range(epoch_test):\n",
        "  test_loss_2, test_acc_2, test_roc_2, prc_auc_2 = test_epoch(model, test_dataloader_1, criterion, device)\n",
        "  print(\"Testing on 5049!!!\")\n",
        "  print(\"epoch - {}/{} test - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f}\".format(epoch+1,epoch_test, test_loss_2, test_acc_2, test_roc_2, prc_auc_2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cor: 279\n",
            "tot: 490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 17 179]\n",
            " [ 32 262]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.35      0.09      0.14       196\n",
            "         1.0       0.59      0.89      0.71       294\n",
            "\n",
            "    accuracy                           0.57       490\n",
            "   macro avg       0.47      0.49      0.43       490\n",
            "weighted avg       0.50      0.57      0.48       490\n",
            "\n",
            "Testing on 5049!!!\n",
            "epoch - 1/1 test - 0.721 acc - 0.569 roc - 0.508 prc_auc - 0.609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NARPgmZB0hR8",
        "outputId": "d4dd2ec1-f00d-409f-edc2-a76f76875d54"
      },
      "source": [
        "#Test on 5117\n",
        "for epoch in range(epoch_test):\n",
        "  test_loss_3, test_acc_3, test_roc_3, prc_auc_3 = test_epoch(model, test_dataloader_3, criterion, device)\n",
        "  print(\"Testing on 5117!!!!\")\n",
        "  print(\"epoch - {}/{} test - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f}\".format(epoch+1,epoch_test, test_loss_3, test_acc_3, test_roc_3, prc_auc_3))\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cor: 280\n",
            "tot: 501\n",
            "num_cor: 465\n",
            "tot: 863\n",
            "num_cor: 533\n",
            "tot: 974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 3/3 [00:01<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3 39]\n",
            " [ 4 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.07      0.12        42\n",
            "         1.0       0.62      0.94      0.75        69\n",
            "\n",
            "    accuracy                           0.61       111\n",
            "   macro avg       0.53      0.51      0.44       111\n",
            "weighted avg       0.55      0.61      0.51       111\n",
            "\n",
            "Testing on 5117!!!!\n",
            "epoch - 1/1 test - 0.744 acc - 0.547 roc - 0.493 prc_auc - 0.562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moq_2RDe07BH",
        "outputId": "cc38075e-c21b-44d6-a492-e1157de83598"
      },
      "source": [
        "#Test on 1998\n",
        "for epoch in range(epoch_test):\n",
        "  test_loss_1, test_acc_1, test_roc_1, prc_auc_1 = test_epoch(model, test_dataloader_2, criterion, device)\n",
        "  print(\"Testing on 1998!!!\")\n",
        "  print(\"epoch - {}/{} test - {:.3f} acc - {:.3f} roc - {:.3f} prc_auc - {:.3f}\".format(epoch+1,epoch_test, test_loss_1, test_acc_1, test_roc_1, prc_auc_1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            " 50%|█████     | 1/2 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_cor: 313\n",
            "tot: 577\n",
            "num_cor: 486\n",
            "tot: 870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 2/2 [00:00<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 15 107]\n",
            " [ 13 158]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.54      0.12      0.20       122\n",
            "         1.0       0.60      0.92      0.72       171\n",
            "\n",
            "    accuracy                           0.59       293\n",
            "   macro avg       0.57      0.52      0.46       293\n",
            "weighted avg       0.57      0.59      0.51       293\n",
            "\n",
            "Testing on 1998!!!\n",
            "epoch - 1/1 test - 0.745 acc - 0.559 roc - 0.502 prc_auc - 0.567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrjFegG-533r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}